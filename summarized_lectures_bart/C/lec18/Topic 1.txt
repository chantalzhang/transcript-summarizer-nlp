David Ifeoluwa Adelani: How do you decide on what would be your candidates? we have some work that have been developed also at University of Montreal and one of the authors of the attention mechanism is still around. We have transformers and landing models, and we'll talk a little bit about prompting. a sentence. until you train the model, they don't mean they donâ€™t capture any information. But this tutorial was very, very helpful. , because you need to be able to encode the word very , and it's either from a separate model, word to back, or the model starts with one hot encoding and learns its own. keys and values are just lined.