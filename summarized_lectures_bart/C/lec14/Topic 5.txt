Jackie Cheung, Professor: But good evening. Disambiguation, is the task of figuring out which word sense is expressed in a particular context. I'm going to go through some algorithms again, not state of the art algorithms. But the reason that I'm presenting them is that they give you the flavor of how you can use knowledge about the problem and your intuitions and build them into computational algorithms. Algorithm was developed in the early nineties by Jarowski. Heuristic is to pick one other word that will correlate and co-occur with that sense with very, very high probability. In modern times, though we solve harder problems , and not just the binary word sense disambiguation. The general idea here is that you understand a term by the distribution of words that appear near that term. You can compute some that . and the most common function that people computes to compare the meanings of 2 words is by computing their cosine similarity. If you see a word that occurs a lot with in or at or something, it's a time, word or location. The problem is that word. Vectors have no objective inherent value that we can evaluate if you had 2 vectors for the word linguistics, is point 4.3 negative point 2 better? All we can do is evaluate the similarity of vectors to each other by similarity. And then you can do a correlation. You can compute a correlation between them to check whether it's the case that the higher the similarity, according to your word vectors, the high the similarity.