In logistic regression, you want to look for a certain weight that allows you to model your input X to give you Y. In the feedforward neural network, I've been talking about weight matrices or your weights. It's a learning model which automatically learns nonlinear functions from input to output. The more data we have, neural network has not disappeared because it is able to model any function. SVM can also work for nonlinear data if you use kernel functions. You need a non linear function that can separate your data. Size of your output depends on the size of your entire vocabulary, the number of types that you have. In the case of language model, your input vocabulary size is equal to your output vocabulary size. The loss function is used to know how far away are you from the words from the correct answer. One of the algorithms that's used till today is back propagation and one of different artists talk they have tried to replace it but they have not found a good alternative to. Do nowadays based on neural networks, you're going to start with a pre trained model. For each class you compute the F1 score and then you have equal weights for both of them. Another difficult thing is that neural networks tends to work very , but it's difficult to interpret. There are many open questions on how to use linguistic structure.