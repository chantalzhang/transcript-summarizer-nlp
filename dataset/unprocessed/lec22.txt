Jackie Cheung, Professor: Alright, Hi! Everybody welcome back. Just to make sure. I think we're people online can hear us. Yes, settings up all right. So today we're going. We're going to talk about natural language generation. Here is the plan for today. So we are going to look at how natural language generation has been approached with different methodologies and different approaches in the literature in the past. And we are going to look at, maybe techniques that are not currently, you know, the trendiest or the most popular. but it's good to learn about them to expand your toolkit. because I guess my goal in this course is that you don't go away thinking that Nlp is just about hacking things with like prompts and Llms, that would be like really sad. So instead, we're going to look at a broad range of approaches. And we're going to look at rule-based systems. We're going to look at shared machine learning systems. And also we're going to look at an approach to to thinking about problems which I think used to be really popular, and it still has its merits. And we can talk about that which is a more declarative approach to optimization. Okay, so then, here's the outline. So one way that we can categorize different Nlg approaches and like the field, is to think about the kind of generation you're doing like, what is the the format of the source material from which you're doing generation. And so I'm going to divide that into something I call data to text generation versus text to text generation. And we'll look at each of those. Okay, here's a reminder. Last class. We were looking at automatic summarization focusing on extractive summarization. And we contrasted extractive summarization, which is where you take snippets of the source text and concatenate them together versus abstractive summarization, which is where you compose novel text not found in the source. And so we focus on extraction because it was easier to think about. And you don't have to do. We can focus on these interesting issues to do with modeling, content, and modeling the relationship of words with respect to each other, and that how that helps us inform what is important. But then, if we want to do abstraction, then we have to do. Natural language generation and abstraction has many use cases. For example, one key one is that it lets you aggregate information from multiple inputs. So again, think about the case of, say, product reviews. Maybe you have a thousand product reviews on a popular product on Amazon. and it doesn't really make sense, it makes less sense to do extraction. Sure, you can extract specific top reviews and put those comments together. But if you want to describe the overall distribution of opinions, for example, of that product, and synthesize and the thoughts that people have on specific aspects, then you're going to have to do some kind of abstraction and abstractive summarization. And so that's why we need to talk about natural language generation overall. We can also compare and contrast Nlu and Nlg. Again, I think this was like a slide. This is like a similar to a slide from the very 1st lecture. Right? So in the 1st lecture we define natural language understanding where the issue is, you have ambiguity, and you want to do disambiguation. And maybe the now we know that maybe sometimes. there's under under specification, and that, like the meaning representation should be under specified with respect to multiple possible interpretations of the input. So there's all that good stuff. whereas in natural language generation the concerns are a bit different, because it's about selecting appropriate content which we covered last class, and also selecting the appropriate form in which to express that content. So then we can divide up Nlg into data to text versus text to text, depending on the source, the kind of input. one kind of natural language generation which is always available and always there and maybe requires very minimal amounts of Nlp is just canned text. Hey, if you play a video game up until very recent times. Almost all of the text is scripted right? You reach a certain point in the game, and then a message pops up, and then and then you have like, and there you go. That's that's natural language generation, right? It's it's not very interesting from our point of view, but it is a kind kind of natural language generation. But then then we can start to get into use cases that are maybe a little bit more flexible and more adaptive. Here is another one here I searched up the driving directions from Mcgill to Mila. The Research Institute in in the little Italy neighborhood. and there's natural language generation here as well. Maybe you don't think about it as such, but it's there. because, you can see, I'll take this street and 2 words, or until Pine Avenue, and then follow Pine Avenue until some other place, and so on, and so forth. And if you use your phone's GPS system, then this is also like it will like spit out. It will say, these driving directions to you as you reach the appropriate location. This is also a type of natural language generation. So if you think about it, how this works is that there are templates that are formulaic patterns that you fill in and you get the to to get the final sentence right? So, for example, here it's like, take. And then there's a a slot here, so take and then street name to street name. That's kind of the template, right? That's the generation template. And then next you have follow street name to street name. and so on, and so forth. and maybe at some point, it'll say, turn left at street, name, or turn right at street name. So this is very temp, templatic and formulaic. And arguably, that's a good thing. Okay, this is actually, I would say that, like for something like a a GPS system or some other very routine formulaic things. You do not want creativity. You do not want diversity. you want things that are highly structured and expected of a certain form. Okay, so that helps us with, like our mental processing. So imagine you're driving. And your GPS system like is telling you. Oh, here's a joke, or here's a poem for you to figure out the directions that you need to take next that does. That doesn't make any sense right? So, depending on the application and depending on the the usage, you might just want to handwrite some rules and handwrite these templates and then fill those templates in with the appropriate information. And then there you go. So actually, if you go into industry, here are more stories from my students. So my students, my grad students are wonderful. And they do all this cool work. And then sometimes, I teach them unpopular things. And they're like, why are we learning this? And then I have one student who, when he was here, he was very pro neural networks, deep learning, all that stuff, all the old work is useless. And then he went into industry, and then he found that a lot of the work is about like writing rules and writing out templates and try to fix things at the last step so that they can release a product. And I got the last laugh. So he came back to me after a few years. And it was like, Oh, yeah, a lot of industry. Nlp is still based on rule writing rules and like thinking about grammars and stuff. Is that gonna be true in the future? I can't make any predictions 5 or 10 years from now. But at least right now you still need to know this stuff you still need to know, like about templates and rules, and so forth. Yeah. And then so just a bit of terminology for you don't have to remember this, I guess, but like it might help you to if I say it to you at least once. So in terms of the templates. the abstract kind of thing that you need to fill in. So when I say like, take street name to street, name the street name that's called a slot. Okay? So usually in a template, you have these slots where you need to put stuff in the slot. and then, appropriately, the thing you put in is called the slot filler. Okay. So in this example, if the template, if the overall structure of the template is a take the Slot Street name to the Slot Street name. The slot fillers are Rue University and Avenue des Penaux. Okay? Alright, but I guess, like we're all here for the more, I guess. Interesting, exciting kinds of Nlg. where you need to do you might want to think at a more high level about all of the steps in the architecture of an Nlg system, and then think about which ones you want to architect more, and which ones like. maybe you implement with some machine learning system or a neural network or something or a large language model. So we can talk at a high level about these steps. And and yeah, and then in in practice, how you actually design it for a particular system. You might like, some of these steps might be combined together as part of some module, and some of them might be separated out, depending on the specific ways. You decide to engineer your system so abstractly. System. Abstractly speaking, then, here are the steps in a potential energy system. You need to do content selection. You need to do document structuring. And then there's something called micro planning. And finally, something called surface realization. Okay, so content, selection is about deciding what to say. And if you want to take a very principled approach to this, then you should think about what is the communicative goal of the energy system. and what is the relevant knowledge about the world that will inform how we do content selection. So we talked quite a bit about this last class, right? So this step is often application specific. So last class, we talked about multi document summarization. And how do we approach content selection there? Well, we talked about how there might just be some topics that people find inherently interesting and important, but we also talked about signals of importance in text. So does anybody remember. I think I I mentioned at least 3 possible sources of importance in Texas. Anyone remember those, any one of them? This was just Monday. I'll give you one of them. One of them was centrality, so repetition of a word or concept within source documents. But but I think I mentioned at least 2 other ones. So we we were talking about like news summarization and looking at the opening paragraphs. Yeah. oh. yes, exactly. The location. And that's the location is a specific specific instantiation of this broader theme of discourse structure. So using the discourse structure of a document to find out where the important things are. And what was the last thing we talked about? Does anyone remember. Yeah, background knowledge. Yes, you might have looked it up. But I'm okay with that. Yeah. So so okay, so that goes to show that content selection and and determining what's important content. A lot of that really depends on the specific application. And then some of the general trends in the context of summarization still apply to this step. Okay, so next is document structuring. So this is different from like using the discourse structure to find what's important. Now, it's the opposite. It's more like, how do you structure the outputs of the natural language generation system so that it's the most effective at accomplishing the the communicative goal that you have in mind. So this is kind of going in the reverse in the opposite direction. So in order to decide how to structure the contents of the output. Then you might have to consider some of these factors like the importance of the concepts, because this is the OP. There's like the same argument in the opposite direction, just as like in naturally occurring text. important information tends to be found in certain locations. When you're doing generation, you want to respect those. You may want to respect those conventions and and formats, so that other people reading that document would be able to do the same same thing. and then you might want to generate discourse relations and think about the coherence of the passage that you're generating generating overall. So there's some work at in at the intersection of, say, like psychology, of reading and Nlp and computer science that looks into things like this. So one specific instance of this is something called argumentation theory, which provides some guidelines on how to arrange information. I guess some of this you also find in like writing advice, right for students. So, for example, you can talk about, or you can structure your documents so that you present the main claims first, st and then you can try to arrange and discuss the supporting evidence, and then present and debate opposing evidence, and so on, and so forth. So there are some guidelines here for that as well that you can try to make use of. The 3rd step is to select the specific lexical items that you might want to use to to generate the final output. Suppose now, you have a data to text generation setting where the input is say, the results of some weather forecasting system here are represented in some like a made up a formal. a structure like there may be tomorrow. There's gonna be a blizzard with a high of minus 5 and a low of minus 10 and 30 kilometer per hour winds, and the location is Montreal. Well, you have to select the specific words in the language you're trying to generate this into, to represent those concepts. And then next, as another part of micro planning is to decide how all of these words fit together in clauses and sentences, and this is called sentence planning or aggregation. For example, the 1st sentence, in your output might present the location and time that the weather forecast pertains. and then the second Mike presents the details of the forecasts also. Part of micro planning is to generate referring expressions. So remember, this term comes from. We talked about this last week when we talked about co-reference resolution. So again, like all of those things we talked about on the side of a natural language understanding. Now we have to do the opposite, the reverse when we're doing natural language generation. So if you have an entity. Then, like the the Prime Minister, then depending on like maybe the 1st time you introduce the entity in your document, you present the full name or something. I think this might be what you find on Wikipedia or something. And then, in other context, maybe you just need the 1st and last name, and in other contacts you might want to refer to that entity with their title, etc. Etc. And then finally, in later mentions, maybe it's like the pronoun. and then the last step in this abstract description of an Nlg system would be surface realization, which is to fully convert all of those the specified discourse plans, and the outputs and decisions of the micro planner into the output form which takes the form of these sentences that you see or or you can run a text to speech or something. And you have, like, audio output, etc, etc. So there are different possible levels of input specifications. So it could be some highly detailed semantic structure where all of these decisions are already made, like with lexical items and tense and aspect and mood of the verbs and referring expressions. All the stuff we mentioned. or it could be shallower in that the inputs to the surface realization step could be like a dependency tree. So there are different options. But again, these all tend to be contact, specific and application specific. So the thing with the Nlg with the literature on Nlg is that up until large language models the field was very diverse and not unified, because the in the form of the input was so diverse. Some people working on Nlg were interested in like generation from structured databases, but each structured database has a different format. Right? They it all have. They have all different sorts of fields and different types of data and values. and then others define Nlg by as generation from some structured linguistic representation of the types that we've seen in class. like with from parse trees of some kind, or from some semantically annotated structure meaning representation. And there's no uniformity there and then for the text to text people working on summarization and translation, the input is itself text. So the input types were all different from each other, all different. And so the field was not unified, and that that made it like difficult to work in this area for a long time. So nevertheless, there have been a few standard tools and task definitions in Nlg. so one of them is called referring expression generation, which is you come up with like a scene like you can imagine, like coming up with, like a picture with a bunch of different objects, with different properties. And then the task is to like generate a linguistic expression that picks out a subset of those objects. So here it could be. Suppose our scene was just what you see in the classroom right now, and the task is to generate that thing. Well, you have various options, you can just call it. Maybe you can call it the blackboard. But then there are multiple blackboards in the room, so maybe that's not a good choice. You could call it maybe the freestanding blackboard, or the blackboard with wheels or the blackboard on the left. So then, that's kind of the task. Okay? Yeah. Or if you say, like the green thing, that's also not very discriminative. So yeah. okay, and then surface realization. Then, there's some standardization there. So there are some tasks about generation from dependency parses to like, say, output sentences or something. But let's look at one from the early literature called FUF. Surge from the nineties. And so this goes to show the the state of the field back, then. which is they assume a highly detailed semantic structure. and then they apply a cascade of deterministic rules to convert that structure into a string. So this type of structure you see here on the right is called an attribute value matrix. If you twist your mind a bit. This is actually a tree structure. So the top of the tree is kind of on the the left, the outside. and then the tree has, like a tight edges, like one called cat, one called process one called partick here, and then the the stuff on the right of that. Those are the the nodes. And so every time you have, like another square bracket pair, that's kind of like a subtree. And and this is actually a representation of the semantics of a sentence to be generated. The cat here stands for category. so, and on the outside. Here this is meant to be a clause, and then within the on the inside there are, like smaller and smaller units with their own category. And then there's like a category, for like noun phrase, and so forth. and the output sentence that this structure is meant to correspond with is she hands the draft to the editor. So then the idea behind this generation task is that you assume that, like, you're given this type of highly detailed semantic structure. and you want to generate the output sentence. So in that system at a high level. What it does is, it maps it 1st maps these thematic structures or semantic roles into syntactic roles. So a semantic rule will be something like this is the agent of this predicate. and then the syntactic role would be. This is this should be expressed as the subject in the sentence. and then that handles syntactic alternations like, are you using the active form or the passive form, or some dative alternation? For the semantic representations. They're usually under specified in some way. So for all of the missing information, you fill in some default features with agreement, features, and so forth. and then you make sure that the subject and the verb agree in number, because, remember, we have to do that in English. and then it handles closed class words like, if you have this thing like a personal pronoun, that's like a feminine gender in the 3rd person. Singular, then it should be a she. and then you order the components with respect to to each other, fill in inflections. Blah, blah, linearize the tree into the final string. So maybe hopefully, you get the idea. The idea is that you start off with this complex structure, and then through a series of deterministic transformations, you gradually make decisions to like. figure out to turn the semantic representation into some kind of syntactic form which allows you to then convert that syntactic form with the syntax tree into like a linear sequence of tokens. And each of these these steps involves rules. So it was quite tricky to like create a system like this, because you have to hand. Engineer all of these rules, and you have to figure out the order in which they apply and check it against these structures. And you have to be an expert on the input structure. So the advantage of this type of system is that you have a lot of control over what happens. And it's all very precise. and if you're able to understand the whole process, you can understand exactly what's going on and what's happening and intervene that way. But of course there are Major Downsides, and that's why it's not so popular. So one Major Downside is. It's very complex, right? You have to be an expert on this meeting representation and on the rules of the language that you're engineering this for. So it's easy to make a mistake in engineering this. And also you have to like like, how realistic is it to assume that you actually have a semantic structure like this meaning representation like this in the application that you're concerned with. So that's that's a major reason why this approach did not take off. It's it's not so easy to get these structures. And in many applications. It doesn't make sense like it's a lot of work even to convert whatever input you happen to have into this structure. So at the opposite end of the spectrum, I would say, would be something like a neural Nlg model. And so here you just train a conditional language model. Right? So maybe this is a lot more familiar to to us in in, I guess the recent literature. So this could be a sequence to sequence model. Okay, so you have your source text like, if you're doing summarization or translation. and then you have all of the tokens you've generated so far. and then you use that to predict the the next token and maybe around 10 years ago this was implemented, as, say, an Lstm model that's like, maybe you initialize it with some initial word embeddings. But then it's fine tuned on the specific problem and task you're interested in. But then, these days it's probably a pre-trained language model with, based on a transformer architecture. And your source text might also contain instructions like prompts, and then you have all the tokens you generated so far, and you continue to generate. Yeah, sorry. This is probably a super silly question. Oh, regenerative models that my understanding was that they join learned a joint probability distribution. But then here we're learning a conditional probability distribution over generating tokens. So I'm trying to reconcile. That's a great question. So in the course we've defined a generative model as a model that gives you a joint probability distribution over everything of interest, over like your inputs and your labels. And then here we're talking about a conditional language model, where it looks like you have a conditional probability distribution. And how do you reconcile these 2. Yeah, there, that's an excellent question. There are 2 ways you can reconcile it. I think so. One way is that to say that there are 2 different senses of the word generative. There's 1 sense which is like purely about the type of machine learning model. And one sense which is about, do you actually generate some language output, so you can reconcile it that way by not reconciling it. I guess the second way of reconciling it is that if you have a model that can generate some outputs. Texts. Usually it does turn out that the you can write it as a in the form of a generative model with the joint distribution. So sometimes it's just in the model itself. It's explicit. And you can. You can just rewrite it and have that form. and sometimes you have to do a little bit of work, because it could be that the the fact that it can generate output means that you can derive the implicit, generative, joint, generative model that is implied by that generation process. Yes. Also the fact that it's written here as a conditional like, it's just how you use the model like the, it's just how you. So if you have the joint probability distribution. you can always like, write out this conditional form from the joint distribution. Right? So it's so so this alone isn't enough to tell you whether the model is generative or not generative. And that's a good question. Yeah. So okay, so let's also talk a little bit about. So what are the positives and negatives of things just like thinking about things this way. So the 2 approaches we've seen so far is one is highly structured, detailed, rule-based. and all of those steps in this in the Nlg architecture of like content selection, and then maybe not content selection. But after content selection like with like the document structuring and micro planning surface realization. They're all clearly separated step and distinct steps in this rule, based approach. In this second approach of like a neural nlg. everything just gets stuck into this conditional language model right? There's no separate modeling of each of those steps, at least in the most extreme form of that. You just assume that the pre trained language model, for example, can figure all of that out. So what are some pros and cons of of the second approach? Yeah, I see a con that maybe this can generate the non automatically. It's the type of redirects in terms of. yeah. So that's that's that's a good point. Yeah. So this approach. there's no guarantee that it'll generate something that's either semantically coherent or syntactically well formed. Yeah, it's just empirical that it happens to often work well for many of the tasks that we try. Yeah, yep. it be air propagation, if there's like one. Yeah. If there's 1 poorly generated token, will it affect future? Yes, yeah, that's a well-known problem as well. Yeah. how about positives? These are all negatives. But what about positives? Yeah. train. This model is very accessible. So you can do it with a lot of data. Yeah. So that's a positive which is with the the neural approach is very accessible. Right? yeah, everyone can just use a pre trained language model these days, maybe fine tuning. It is not so accessible, because, like. you actually need compute resources and all that. But assuming you have that, then, at least from a technical perspective, it's more accessible because you don't really need to know the the details of how the rule based structure works. You can just feed it some data and like, get it to run and and adapt. So it may be different levels of accessibility requiring different things. Yeah, you don't need to handcraft anything. That's a big thing, right? Yeah. I I'd say another. This one is probably arguable in both directions. But another difference between the 2 is that in the rule based formulation it's in the ideal case is task independent. Once you have a set of rules to translate the meaning representation to the language outputs, then it should work regardless of what generation task you are pursuing. But this is cheating a bit, because then there's a step of translating from the task specific inputs to the meaning representation. And that part is doesn't come for free right. But if you ignore that, then it's a task independent where it was the neural energy approach. If you're doing any kind of fine tuning or adaptation. Then you have to do that for every task. It's task dependent. Okay? Great. Okay? So so then you can also explore something in between the 2 extremes you can. You can have some kind of neural data to text generation as well. Where the idea is. You decide which steps of the analogy pipeline should be in their own modules with a separate planning step, for example. and then come up with a way to embed the input data structures into a format that can be ingested by the neural model. and then add mechanisms in the decoder that are appropriate for that specific generation task like a an attention or copy mechanism, or things like that, you know, fine tuning, and or like few shot learning whatever. And so this can you can have a combination approach as well. Okay, so let's take a look at that. So, for example, here, let's consider the task. This is a data to text generation task. which is a generation of Wikipedia biographies. So the task is to generate the 1st sentence of the Wikipedia biography article from its info box. So yes, this is artificial and contrived. The idea here is just to like, illustrate the point that the input here is a structured formulation of something. It's structured data. And then the output is a natural language sentence. And so then what you could do is you could formulate the inputs. th, this, this is just like a pretty ui. But this is really like something from like a database, right? Like it's it's a pretty. It's formatted in a pretty way. But then you can reformat into reformat, that input into a sequence of tokens that you pass into a sequence to sequence model. And so in this work, this is how they chose to do it. So each word is associated with a word embedding and an embedding. That depends on the word's presence in the info box table. So this is called an info box on the left here. and so then it's represented in this way, like the field, name the index from the start, and then the index from the end. So if this is your input table it gets formulated, reformatted in this way, okay, so it's like, yeah. So here it's like name 1, 2. So name is the field name, because the field is here. and then 1, 2 is like the token position, and so forth or we can look at like 18 April 1352. That's formatted as like birthday. That's the field name. And then the the span like it's it goes from like a 1, 3 and so forth. And then the output candidates is that you generate something similar. And then you can then apply neuro language model training to this as a sequence of sequence task and generate the outputs. I think these so this work was like already, a bit old is already a bit old, like 8 years ago these days you could even do something even more lightweight, and you can just like pass in the entire like. You can really just like, pass this in into like some form of like open bracket born, and then 21 November, 1914. Close bracket. Maybe you have, like born time and then born location, open bracket, Newington, Yorkshire, and whatever. So at a high level, then, just like somehow converts your structured input into a format that you believe contains the relevant information for the neural language model to process and then on the output side, then just get it to generate text. Okay? So so then, so far, we've covered data to text generation. We can also talk about text to text generation, such as summarization where the input is other texts. And then here, the thing to keep in mind is that when you're doing text to text generation because, you're trying to generate some new text. That means there may be. There must be something about the input that we'd like to change and depending on what? Exactly you're changing. That can be called something different. For example, if you're changing the language, then it's a machine translation task. If you're changing the length, then it's a summarization task. If you're changing the complexity of the language, then it's some kind of text simplification task, or something that I'll introduce called sentence fusion. Or if you're changing the style of it, then you're changing, then it's then it's called the A style transfer problem. So yeah, so again, of course, you can just always choose to just throw everything into like a neural language, model a pre-trained model and see what you get. And it may be successful or not. But today I'd like to talk about a particular approach to a particular problem, which I think is a bit interesting, because I can then introduce another technical approach that you can add to your toolkit. And so this this technique is called integer linear programming. And it's really one instance of a broader class of methods and a more general approach, which is to to think about things declaratively. I guess, out of curiosity. How many people have heard of linear programming. Okay, yeah. So a fair number of you great. So that's great. So it's used in Nlp as well, or it can be used in Nlp as well. Okay, so let me 1st introduce a sentence fusion task. This is a task that I've worked on myself during my Phd. Here the task is to combine information from multiple sentences in order to generate an output sentence. And then there are different reasons. You want to do this one, Major. One would be that you want to present a union of the information in the input sentences. So in this example, I have Bohr studied at the University of Copenhagen and got his Phd. There. After graduating, he studied physics and mathematics at the University of Copenhagen. and then in the outputs you can combine parts of the 2 sentences. and what you get is something like, after graduating Bohr studied physics and mathematics at the University of Copenhagen, and got his Phd. There, and the different colors here represents where you got the information from from the 2 input sentences. Okay, so what's interesting about this is that if you think about this problem there are many possible. There are many constraints about the form of the output sentence that you should generate. So there are syntactic constraints. You want the output sentence to be well formed and grammatically correct. There are also semantic constraints in that. You want to ensure. The output sentence is still faithful to the the inputs material. And so yeah, so there's a lot of constraints here. So the idea, the general approach that one line of work has taken is that you represent each of the individual sentences by some structured representation like their dependency parse tree. And then you can create a sentence graph sentence graph by merging the input sentences, dependency trees at the nodes with the same words. So, for example. both sentences before, if you have like 2 sentences like he studied sciences with pleasure, or he studied math and physics with Bohr. Then you can merge those 2 nodes so that it's a single node for studied, and then all of the dependency, relations like subject or or prepositional phrases or object, and so forth. They all exist in that sentence, graph as such. So this, this part makes sense. It's like you have, like each of the parses. And then you're merging them together. And then you get this graph structure. Okay? So then, assuming this made sense, then the next part is like, you, then need to create an optimization problem to extract a new sentence from your larger graph structure. So the idea here is that you select a subset of nodes in the sentence graph that will form a new dependency tree from which a new sentence can be generated here. The issue is that there are many things that you want from the selections, and there are also many constraints. So, 1st of all, one constraint might be that the nodes must form a tree. This is how you ensure syntactic correctness. but you also want to make sure that the selected nodes contain important words, and the selected nodes should make sense with respect to each other, while also, respecting maybe some output length. You don't want a sentence that's too long. So what we we would really like is to have a method that allows us to write down all of these hard constraints and soft constraints. and then to perform the selection with respect to these constraints. And and this is why we would approach this with a type of solution such as linear programming. The idea here is that so you write down. Okay, so you have this optimization problem with all of these constraints. And you write down an optimization problem where you explicitly write out all of these constraints. And then this becomes an optimization problem that has a certain form that you can then pass on to a solver that does that figures out the solution for you. So again, this is, this represents a very different approach to thinking about AI problems. Here's another question, how many people learned prologue? 2. Okay, yeah, that's more than 0. So this rep, so back in like the late eighties and early nineties that the wave of AI back then and the hype back then, was based on prologue. It was based on this idea that we can have general purpose algorithms that solve any problem as long as you can write down your problem in a form that the solver recognizes. Okay? So in the case of prologue, it might be something like in a simplified or restricted kind of 1st order logic. where you write down every all your constraints and everything you know about the problem, and then you prologue finds a solution for you here. This is a similar idea. So this idea, this this approach, is called a declarative way of thinking about problems like, say, declarative programming or declarative method to solving problems. which is that you don't tell the model how to solve the problem. and you don't give it examples and ask it to like, figure out the the function. It's not about that. It's about just writing down all of the constraints and everything you know about the problem into a form such that you then ask a general solver to figure it out. Okay. So in this particular setting in this particular generation setting, how that's gonna work. is that okay? So we have this graph. And we want to select nodes within this graph which correspond to words that will appear in the output sentence. So that's 1st we need to define the nodes. So then the nodes we can call it like Xl. Hw. so for each edge in the sentence, graph from word h to word, w with label L. Oh, so actually sorry! This this node actually corresponds not to a word, but like an edge relation between where it's. And so this will say that it has to be 0, or one where one is. We select this edge in the sentence graph and 0 means we don't select this edge. So that's just the the interpretation. This is how we're gonna interpret the meaning of that particular variable. And yeah, so this is one variable in our optimization problem. And and then we optimize an objective where? Okay? So here, this is either 0 or one. So this is for all of the edges. You sum over all the edges, and then you have a grammaticality score which tells you how often this head word is generated generates a dependent with this label. and then an important score, which is like how important is the word W in this context. and then everything else you can write out as constraints. In the optimization problem. So then, in in this type of approach. All of the optimization problem looks like this. So you're either maximizing or minimizing something. It doesn't really matter, because you can always just take the negation to flip the min to the Max and whatever. Okay? So we're maximizing this objective function. which is about like, Okay, which edges do you choose to select. and then how good is each of those edge! And then the constraints! The 1st constraint, it turns out. ensures that each word has at most one head which you need because you want this, the overall selection to correspond to a tree. yeah. And also you need the second to ensure that the selected nodes actually form a connected tree. So you don't just select like individual nodes. Yeah. So the 1st constraint ensures that each word has at most one head, and the second ensures that it's connected. Here's a question we can actually write another constraints to constrain the number of words in the output as well. That's it. Should be pretty simple to do. What do you think? What? What would that look like? Yeah. Sorry I had a question. Yeah. if the order of the words is determined by the yeah. So the outputs of the so, okay, so this formulation. yeah, I think you you've spotted something which is good. This formulation does not specify the order of the words directly. it only specifies the the tree that you select in the sentence graph. So you need a separate step to linearize it, to linearize the tree into the sequence of words. But that's relatively easy to do from the dependency graph. Because then you have like. So after this, you have a tree structure, and then you can just do some kind of simple rescoring with a language model, even with like a very bad language model to linearize it, and you'll get something reasonable. And so the constraint of selecting things that are interconnected tree doesn't limit the output, and like, remove good potential output sentences. So the constraint that you have to select a tree it very well could it could be reduce the quality of these selected outputs. Yeah, it could like, at least according to these scores. that that's like the point of the. So yeah. So it's because you believe that there are these other concerns with that, like you, you want the output to be a well formed tree. That's more important. So. yeah. yeah. So it turns out that you can write out a constraint to we. Make sure you don't. Oh, yeah. maybe indirectly, by counting the number of edges, I'm thinking, just taking the sum of all. Yes, yeah, that's actually right. Yeah. So because this tree, I know I didn't give you very many examples. So this is all very abstract. But this tree, like each selected edge, corresponds to a word, because it's a dependency tree. So yeah, that's exactly right. You need to sum up over all of your x's and make sure the sum of all of them is less than your budget, which is a constant in the optimization problem. Okay? So okay, I think maybe one thing that's more interesting to talk about is like, how can you get this approach to work with like a neural model, is it still? Is it possible? What do you think? Yep. there'd be some way of passing the inputs in where the the like, the output of the model is whether or not to select this edge and then training for that objective? So can can you say that? More like? So what is the order in which you do things? Do you 1st try solve this optimization problem and then pass the output to a neural model. Is that what you're saying? Okay. I guess the input 1st 3 as something that will be passed into the neural model, and the output of the neural model would be whether or not to select the edge and the model, I guess by training for that objective would probably automatically learn the constraints I see. So I think you're saying to bypass the this optimization thing. So take the inspiration from this, that, like there are constraints. and then feed it into a neural model, and then ask the neural model to do its thing and predict some outputs, and then hopefully, through training, it will learn to respect the constraints. Okay? Great, yeah. That's definitely a good approach to try. I guess, like the downside is, you have no guarantee the constraints would be respected. But in practice it might work better. It might work very well. Yeah. I guess you could also do the opposite, which is like you have a neural model, and if you have access to the internals of the neural model, maybe you can derive like scores, or you can take the logits or the posterior distributions from the neural model. and use that as some kind of like goodness score. and then you feed that in as coefficients to some formulation where you have a setup like here, where you then solve this constraint optimization problem. Yeah. So there are things you can try and experiment with here. So also I kind of glossed over the fact that why is this called an integer linear program? It's because all of the variables in this setting. They're integers. In fact, here they're binary. They're 0 or ones. Zeros are ones. And So if you've done linear programming, you probably have learned that in linear programming. So 1st of all, it's called linear because all of the constraints and the optimization objective, they're linear functions over the variables. And that matters, and also the fact that they are real valued matters in terms of making sure it's like efficient to solve. So for real valued linear programming. There exists polynomial time algorithms for that although the most efficient ones are are are not. They're actually in the worst case, complexity is like worse than that. But anyway, but once you get to like the integer case, it turns out that it makes the math a lot lot harder because you cannot do like. If it's not continuous, you cannot like do some kind of like local search about a good solution. and and then it turns out there. Then it becomes a Np-hard problem. But still the solvers are really really good these days, so you can have very good ilp solvers and also like stat solvers. If you've heard of that problem where everything is expressed as like and and logic is like true or false statements connected by logical connectives. So, even though in the worst case it supposedly has, like very poor complexity, results. In practice, you can still solve reasonable sized problems with, especially with like industrial strength, implementations of these solvers that are highly optimized and very, very fast. And so that is its own field. Its own literature. like all of this, like constraint. optimization, convex optimization stuff is its own field. and we can leverage those tools and those findings to apply it to natural language in certain natural language generation tasks or other Nlp tasks if we'd like. yeah. So just to summarize, there are declarative. This, the the general idea I want to convey here is that there's a whole other approach to solving problems which is not currently that popular but has existed and was influential, was the the dominant paradigm for a while. Which is this idea of doing things in a declarative way. where you specify these diverse objectives and constraints of your problem. and then you have general purpose off the shelf solvers that you can run to to solve those optimization problems. And you can interpret the output back into your application contact, setting for your task. And this could be applicable even in other domains. It's not just for Nlp. So if you're working on like other kinds of data where you don't have a large pre-trained model. That's just doing a lot of things for you. Then then you can consider approaches like this as well. It's also good. If you need like guarantees that you're respecting certain constraints. Right? So here you can really make things into a hard constraint like you must satisfy this. Otherwise you just, or you refuse to output something. So that's also another reason to do this. Okay, so I'll end with a few more trends in the energy literature in the past few years. and these also introduce interesting additional techniques which are maybe a bit more familiar. They're closer to like the neural settings. So one trend is to think about correctness again. this is a problem that I've worked on in my lab. So correctness and factuality sometimes these days. It's called the hallucination problem, although, to be clear, this terminology implies that language. Models have mental states which we don't really know if they do. But anyway, that's what it's called these days. And so here, one pro. So, okay, one problem we talked about just now is that if you do everything in a neural way. You have no guarantee that the outputs will respect semantic correctness or some other constraint that you might have like a safety constraint or something, and this actually happens in practice. I think you've probably all seen examples of this in like of like hallucinations and errors of large language models. So yeah, we looked into this in my lab as well before it was cool. So here we have, like some, the original output of like an abstractive, summarized neuro abstractive summarization system which identified the wrong victim of a terrorist attack. And this is like a this could be a really bad thing, right? Like a big deal. If you have an automated news summarizer, and it gives, like the wrong basic information about an event. That's a news event that can be very terrible. And so we we train a system that it doesn't fully fix the problem, but it partially fixes the problem, and that it's a post editing model to detect these factual inconsistencies and then to correct them. And we did that through artificially perturbing news articles to come up with like an automatic set of training data with factual inconsistencies and then training a model on that artificial data. And then you can apply it to some to to the outputs of like existing summarization models. And here's the form of that. It's like, predict, the corrected summary based on the potentially incorrect or or corrupted inputs plus the source documents and and how this is implemented, I'm sure by now you can like, imagine this for yourself. This could be an Lstm model. It could be a transformer model and some kind of neural model. As long as it's you can cast this as a sequence to sequence problem. Another trend which is still ongoing, because it's not a solved problem by any means is to do controllable text generation. which is to ensure that the output has a certain style or formality, or some kind of certain semantic content, or avoid saying something bad. So this was a while ago now, but Microsoft released a chatbot called Tay. and they just released it into the wild on the Internet. I guess these days maybe that would be considered very naive. But you know, they tried back then, and then they released it on Twitter. And they also got the model. They had this vision that people would interact with it, and the model would get gradually get better and better through its interactions from users on the Internet. And of course, people are not nice, necessarily. And then they within 24 h they've managed to get the Chatbot to further fine tune and and adapt, and to say all sorts of horrible things, with lots of like racist and misogynistic content, and so forth. And so it it took. It was like just like a matter of like one day before Microsoft had to take down this Chatbot. And so that shows that yeah, maybe we need to have controllability of our AI systems. And we can't just release them into the wild and have them adapt to that. By the way, they're like this, this sounds. It's funny, and it is funny, but it's still a concern, right? Like, it's just that this these days is happening at a larger scale, and maybe with a slower timeframe, and that people could be writing things on the Internet and and that things that could itself be automatically generated in some way to try to influence the overall contents of the Internet. So that if you train a large language model on the contents of the Internet, then it'll ingest all this data, and it will affect the quality and the behaviors of the large language model. Right? So it's still a concern. and a big part of like training of large language models these days is to figure out how to find good content source, appropriate contents, and perhaps to filter out the inappropriate content that exists on the Internet for training and then also through later through in throughout the development pipeline. Maybe you also have additional techniques and tools that you apply to try to even after you've trained the first, st underlying model, like the pre-trained model. Then you might want to do some adaptation to change the behaviors of the model after training. And so there are ways to do that. So one simple way in the that people have tried in the past is to add something called a control token. The idea here is that you just prepend the special token that indicates the type of content you want to generate. So suppose you have a corpus of text labeled with a property you care about like maybe polite versus impolite like, could you please do something versus? Just do this now you could prepend special tokens like polite or impolite in front of the sequences, and then train a language model with that with those annotations. and then at test time, you can control the output indirectly by prepending the token corresponding to the target property as well. And you can do this is a very flexible paradigm. You can do this with all sorts of properties. You can put in other things like desired words or contents, or you can put out. People have also tried putting like a plan of what you want to generate overall into the the prefix, the prompt, essentially of what you're gonna of the language model and then start the generation process condition on that. And yeah, so that's the current approach which is really popular. So rather than single tokens, it started off being single tokens with special meanings. Now, people are just putting in whatever, so it could be like some instructions. It could be some kind of overall larger plan for what you're going to generate. You put it in the prompt and then condition on that generates another approach that people have tried is to do unlikelihood training. which is to tell them decoder what not to generate. Again, assuming that you're able to derive this set of negative contrast words. So this is interesting because it's kind of the opposite of like this standard approach to neural training. So the standard approach to neural training. So this is the objective function of unlikelihood training, and the standard approach only has the second term here. The last term here, which is, predict the next word given all of the previous contexts. Right? That's the that's the standard log likelihood objective. Maybe it's expressed in a slightly different form, in terms of like some kind of a cross entropy loss or whatever. But this is essentially what it is. And then, in unlikelihood training, you also have an additional term. So here it's the opposite sign is one minus something which is like the C is the contrast words. It's like the set of words that you don't want the model to generate next. and then you throw this into your objective, and then you have some coefficient to weight it a certain way, and then off you go. So it turns out this unlikelihood training can be a little bit tricky to get it to work well, and it kind of makes sense, because, like telling the model what not to generate at the token level isn't exactly what we want, right? So really, what we want is when we want to tell the model what not to generate at some semantic level. It's just very hard to specify that. And like, turn that into like a a form that the language model understands. So you can do this, but the results may be mixed. Yeah. Question. oh, yeah, what's the difference between this and contrastive learning? That's a great point. So the difference is that in contrastive learning your contrastive set, the negative set. The interpretation of the negative set is that it's just the things that are not the correct answer. So in contrastive learning you have, this is the correct answer. This is everything else. And then we're going to maybe sample from the everything else to come up with a contrast set to separate the 2 here with unlikelihood training. It's the idea is similar, but the difference is that here the contrast set, the negative set are things you. You want the model to actively, not generate. It's not just things that you you think. Oh, the model shouldn't generate because it's not the correct answer. These are things that the model should actively not generate. So then, how you draw this set of like Ct is different. It's not everything else. It's like this. The set Ct here is like specifically in the negative things. So there's a stronger pressure here with this approach to push these things down. That's the difference. Yeah. is, is there a possibility additional numbers to get the calls? And now they can. Okay. okay, so I'll try to see if I understand the question. So the question is like, so there's this work in adversarial learning, and then you're interested in figuring out if there are ways for the model to itself, automatically identify things it should not generate. For example, by using sentiment scores to figure out there's some outlier in sentiment or polarity, or in sentiment, polarity or something else. Yeah, that's an interesting approach. I think, in terms of the general idea of using the models, outputs. and the characteristics of it. To determine whether it has generated something very strange is a good one. I think there's work on that in specific application context. Yeah. So I think that's a good idea. Is it a widespread approach? So there's 1 line of work which is kind of related to that, I would say, at a high level which is like this, chain of thoughts, work where you have a model, generate outputs, and then you condition on the model generator output to generate something else. And so this is more general in that the model can choose to continue what it's generating in the same directions. And maybe it also allows it to inspect and choose, like to correct something and fix something. But yeah, that's what I can think of right now in terms of a general approach. Yeah, that's not a question of adversarial environment. Yeah, in the previous slide, when you're conditioning the model with some sort of token or some sort of prompting context. Doesn't that mean the model is like quite responsive to certain tokens. And therefore you can like search and generate adversarial tokens that impact the models. Okay, so the question is, if the model is conditioning on a token to generate its outputs. Doesn't that mean it's conditioning on it's paying too much attention to that token, and it might influence the generation in some way. Or oh, I see that. Can you generate an adversarial token that would impact the model in some way. Yeah. So there's a line of work on that as well. They call themselves like like they call it jailbreaking. which is so usually the setup is you have a large language model. Pre-trained language model is trained on some data. and maybe some of it contains sensitive information, and maybe you have some mitigation techniques to like through adaptation, model adaptation with like reinforcement, learning or something to get it to not reveal sensitive information. And this line of work in jailbreaking. The main assumption is that since the pre trained language model has seen the sensitive information in training, it's there somewhere in the model parameters. And if you search for the right sequence of like, maybe fake tokens artificial tokens, or like just something on the on the inputs to prepend, you can get the model to reveal the the information that it's seen that it's not supposed to. Yeah. So there's a line of work there. Yeah. yeah, alright. So yeah, so. And then I guess the other major trend that I haven't. I didn't talk about in the slides is like reinforcement learning. And so the other major trend right now is you try to fix these issues with human feedback where you sample a collection of model outputs, and you get people to decide which one they prefer, and which one is better, and that becomes a reward signal, and that reward signal can be used within this other machine, learning paradigm that we haven't talked about called reinforcement, learning to try to affect the model's behaviors and its outputs, so that the model tends to generate things that give it a higher reward. So that's another way to try to control the generation. Yeah, in this trend. Yeah, there's a question. Yeah, yeah. you can reduce the reward constructed loss for the model that can be used to backrot it to update the parameters. So in reinforcement, learning. The reward signal is used within some objective function and with back propagation in order to change the model parameters. Yeah, at a high level, it's the same. The difference is that in supervised learning you have a loss that is defined in a very structured way, that each sample is associated with a label, a label or a correct label or not. whereas in reinforcement learning it's just some scalar. It's just some scalar of like good versus bad, like a positive signal versus a negative signal, and that gets propagated down to like the the sequence of decisions that the language model has to make as it's doing. Generation. Partner, cool. This is good. You got it. Yeah. So reinforcement learning methods typically are harder to get working and to train. Yeah, because it makes looser assumptions about like the the structure of what's happening. That's right. Okay, all right. I think that's all I want to say. So thank you very much. I'll see you next week. So next week there are 2 lectures. One lecture will be on evaluation. So I'll talk about a little bit more about evaluation of Nlp systems. and I'll also advertise the course I'm teaching next term a seminar course on evaluation, and then the other lecture will be a guest lecture by one of my postdocs, or Ernst on a topic that still to be determined probably to do with natural language generation. So that's what's happening next week. Alright, thank you. Hey? Good morning. Was 3 to 5 min.
