Jackie Cheung, Professor: Yes, okay, I'm recording now. So you haven't missed out much yet. So yeah. So we're in the setting of syntax-driven semantic composition. And last class, we started talking about the specifics of how this is done. We talked about nouns mostly proper nouns, and we talked about intransitive verbs and the other major high level concept from last class. Is that how this works is that each lexical item. So each word at the leaf of the tree is associated with some fragment of meaning representation in the logic that we care about. and that when you do a syntactic composition by applying a rule in your context-free grammar. You also do function application in lambda calculus to build up a bigger piece of the meaning representation for the whole constituents. And so there's this kind of like these 2 perspectives. Right? The syntax part is like you combine things to make a bigger syntactic chunk. And semantically, you're also combining things to build a bigger meaning chunk of meaning representation, and then once he gets to the top level of the S level, then you filled out everything that you need to fill out on the semantic side in order to build up a logical sentence in the logical formalism we're working with. And in our case it's 1st order logic. So that's kind of a reminder of what we talked about in this class. So today, we're going to talk about, we're going to expand our grammar a little bit to account for several other phenomena. though by no means is this exhaustive. So we're gonna talk about more kinds of verbs, say, say, transitive verbs. And then we're also going to talk about quantifiers. So we're gonna look at how in logic you have these universal and existential quantifiers, and how we can use them to model quantifiers and natural language. And then something called definite descriptions. Okay, so yeah, just as a quick reminder, lambda calculus is there as this separate thing to help us build, meaning the the meaning representations piece by piece. So the Lambdas are there to help you figure out or to help you express that you're still missing information. And then, when you do more syntactic composition, then you combine more pieces of meaning representation together, and then lambda calculus will help you figure out exactly how you should combine the pieces of meaning representation. And here's the syntax driven semantic composition kind of a rule that we have right? So each context-free grammar rule is accompanied by some expression that tells you how to combine the meaning representations of the pieces. Okay, so last class, we talked about proper nouns, and this is the general form of them. It's some lambda expression with a constant and okay and common nouns will also be some lambda expression, but this time with a predicate. So this is a predicate that eventually checks whether something is a student or not for the noun student. And then we also talked about intransitive verbs. So intransitive verbs only takes the subject as an as an argument. and so there are. There are no direct objects. and I recall that what we said was that with intransitive verbs, we with verbs in general. one standard way to express, that is to say that there is a event variable. There's some event that takes pre takes place, and it has a certain type which is like the types that that corresponds to the verb itself. So it's a rules events, and then you can express that the the event variable. E is associated with some something which is the ruler? Yes. Can you explain a bit more? The events concept like, is it like an action, or is it the representation of the verb like that 1st one was, I understand, the second one, and the 3rd one, when there will be but like in ruler. there's some. There is a ruler right? Something. But the rules would be in in the middle of that I don't really understand, sure. So let let me explain. The question is like, can I explain a little bit more of this event? Variable thing? Yeah, that that it's a bit difficult to wrap your head around. So okay, so you remember we're building this logical representation in order to say, access some database, or make some inferences to say like, did something happen? Or did something not happen, and who was involved or whatever right. So that's the point of all. This is to build some meaning representation in order to be able to do some inferences. So with nouns and noun like things, it's kind of more obvious that you're creating these entities, and then you can reason about them and their relations to each other. But what about the verbs, and which often denote events? So. in order to be able to reason about something, you have to have some entity that exists that you can manipulate right like in logic. You you always have like. If you have. This is true, then that is true, but you need that this part. So in this framework, a common thing people do is that they reify it. What that means is that that they create a discourse entity that corresponds to that event. Okay. So now there is like for this event of like something rules. There is. Now this abstract idea that it's like a it's an entity. Now and then it exists. and you can talk about it, and you can talk about its properties. You can talk about when it happened, and or will it happen? And so on, and so forth. But so so to you, need to create this event variable so that there can be a discourse entity associated with it, so you can reason with it. So that's the that's the intuition here. So when you say there exists E, it means that there's some you're saying that there exists some discourse entity. So there always needs to be like event management where you just put it. Once inside the yeah. So there always needs to be some event variable every time you introduce a new events like ever essentially. And then and then this rules E part. it's a predicate, but it's actually here is function is to add a proper is to say, what's the property of this event variable. We're talking about the entity associated with this event variable, anyway. And it's that it's it's of this type. And the ruler part is saying that it's associated with this other entity, which is the entity that rules. So that's the the basic intuition. Yeah. So why are we doing things that way? Because, previously, you can imagine that a simpler version of this is just to have, like a a predicate like a multi place predicate. That's this is like the simpler alternative which is just that there's a rules X where that corresponds to the events. but by reifying it it makes things a lot more flexible. because then you can have optional elements, like locations and times and and passive structures, and you can just all account for them in the same way by talking about properties of event variables. and you can also add information to the event variable about like a tense and modality like when it happened, or will something likely happen? And things like that. Or even if you just have, like multiple events of the same type, then with the event variable version, it's much easier to deal with that. So so that's why we do this kind of complex thing of like of this is called reification, right? Like making something like tangible as an entity. Yeah. yeah. But this is called Neo Davidsonian event semantics. Okay? So the the formulas will get complicated. But the concept is the same. So don't get freaked out by all of these symbols. Okay, as long as you understand the high level concepts. there's a mechanical process to derive the things with a lambda calculus and function application. But the high level concept is exactly the same. So what about transitive verbs? So we've talked about intransitive verbs. So now let's talk about transitive verbs. So and and a transitive verb might be something like enjoys. Okay, so Jackie enjoys comp. 5, 50. So it's transitive because there's a direct object, and there's a subject. So how do we derive the semantics of that? So first, st we have to have a semantic attachment to the lexical rule. So that means enjoys verb rewrites to enjoys, needs to be associated with something. And that's this, like long and seemingly complicated piece of thing that is in lambda calculus, with parts of 1st order, logic in it. and it looks scary. But again, conceptually, it's exactly the same. And the way you derive this particular form is just. You have to work through it and figure out that this is the form you need in order for everything to work out and be filled in the right place essentially. And and you won't have to do anything this complex on the midterm. So it's okay. Don't worry about it. But conceptually, it's the same. So the additional rules that we need is that we need to have rules for the direct object to to to for the semantic attachment associated with like the direct object, rule right? Because for the direct object, you have something like Vp rewrites to Vnp. You remember this like with transitive verbs. So you need a semantic attachment associated with that which is that we have the. You take the semantics of the verb. and you apply it to the semantics of the direct object noun phrase. That's what this says. And then the sentence rewrites to Npvp. Rule is still there, and it's still the same. Okay? So we can work through the derivation. You can do this at home to like again, to like work through each of the steps, and it looks complicated. And it's annoying. But conceptually it's not complicated so conceptually. Let's remember what happens. So first, st if you want, you can draw the entire syntax tree. And this is what the entire syntax tree looks like. Okay, so Jackie is a proper noun, and it's a noun phrase, and then verb of enjoys. And then there's comp. 5, 50, which is a proper noun with its noun phrase, and then it combines to a verb phrase, and it combines to the sentence. After that. The next step is to write down the semantic attachments for all of the lexical rules. So for proper noun rewrites to Jackie it looks like this lambda XX applied to Jackie or enjoys. We have this monstrosity we just introduced in the last slide, and Comp. 5 50. You have lambda XX applied to Comp. 5, 50. And after that it's like just going bottom up in the tree and doing function application with the rules of lambda calculus. Yes. and like the order of the variables. Okay? So the question is, does it matter? The different parts of the conjuncts are written? So this part doesn't matter. So with conjunct, with, like the logical and in logical order. If there is a bunch of them together, it doesn't matter what order you write them in. so that you can prove that pretty easily with like, say, I don't know logic tables, or whatever. But the order of the Lambdas here. That does matter. because the order of the Lambdas here that tells you when you do function application what gets plugged in to which variable there. So that does matter, and that you cannot exchange. And no, you do not have to memorize this very midterm. yes, so sorry. I understand the variable V and X, but I don't understand the variable total. Yeah. So. okay, so how about? So you don't understand the variable? W, so let's let's go through the derivation. And then we'll see how it simplifies. Yeah. So yeah, okay, so here we have Conf 5 50. So it gets passed up from the lexical level to this noun phrase level. and it's just the same thing. If you look at the semantic attachment for that rule, you just copy it directly over. No change. And now for Vp rewrites to Vnp. so remember, from the previous slide. The rule is that you take the verb semantics and the noun semantic noun phrase semantics, and you combine them together where the noun phrase semantics is the arguments. Okay, so what that means is that you just copy the entire rule over here. And then the arguments is this thing. and do I do the simplification? Yes, I do the simplification here. So that's this thing. and you can simplify you. Take this lambda XX. To 5, 50 com. 5, 50, and then you plug it in where the W is. and what you end up with is lambda Z. And then this thing applied to this thing. and then you simplify. You. Take this thing as the arguments. and then you put it there where the Y is. and it's it's a whole mess, but then it works out, because then this whole thing is now the the functor, and then Comp. 5, 50 is the arguments. and then you put the Comp. 5, 50, and you plug it in where the X is, and eventually the the constant of comp. 5, 50 ends up in the right place and ends up in the place for the enjoy. So the thing that is enjoyed, and that's what we were hoping for. And all of these steps is applications of lambda calculus. So you really have to practice that to not make a mistake. But if you if you do that, then you'll derive this. and this will be the simplified form of the verb phrase semantics. So it's still missing something which makes sense, because we still don't know what who the enjoyer is. Yeah. Question, how do we go from lambda x dot x 5, 50 in the 1st line into lambda y dot y, is it because we're like switching in X dot x for y, or is that a typo? Yes. So it's not a typo. Okay. So here lambda XX com. 5, 50 gets plugged into where W. Is right, because the the 1st lambda here is lambda W. And the argument is this entire function. then how does it get turned into? Why, though right before oh, it's just so that you can always rename things. I didn't want to put X here because it might get confused with this X. So I just renamed it? Why, just so that it's I guess. Technically there, yeah, technically, you're right. There's a there's a separate step where you do the renaming. But you're yeah, you're you're allowed to do that. All bound variables can be renamed. Yes. and the and they're they're okay. So this looks complicated. It's because, like there's a there's a whole series of reasoning steps you can derive to show that this is the way that you need to make to make all the representations look more similar to each other in form and to have function application workout across multiple syntactic constructions. So there could have been a simpler form that works with this specific sentence. But if you want the same approach to work across multiple semantic phenomena, then you need it to be a little bit more complicated. But you don't have to worry about that. The the idea is, you understand, the concept of each lexical rule comes with a semantic attachment. and then each production also comes with a semantic attachment, and you use those to like work out what the meaning representation is for each constituent. Yeah. 5, 50 is substituted for X, the way I'm reading it, I thought it would be substituted breeze. So okay, so you mean, why this chunk ends up here? Why? Comp, 5, 50 ends up in the position of enjoy. X. Okay, so from this step to this step. yeah, okay, so from this step. okay, this entire thing. this entire thing gets plugged in to where y is. So it's this entire thing. so this whole thing gets plugged into where Y is so then, when you do the rewriting, so you still have lambda Z, and then this whole thing becomes the why. and then Comp. 5, 50 is now the argument. Yeah. But same thing like, aren't we supposed to go left to right? So why is it being substituted for right and like, why aren't we looking for it as well? This we're going. We're going left to right, but here it's lambda Z, and then 2 things within it. It's not like there's 1 chunk, a second chunk, and a 3rd chunk. There are only 2 chunks. There's like one chunk here. and then there's a second chunk for this whole thing. Okay? And then and then the last step to get to the sentence level is the same. So okay, so for the subject, you pass things up. and then the subjects, semantics is Lambda XX. Applied to the constant Jackie. And then it's the argument is the verb phrase semantics which we just arrived, and then you can simplify. You can plug it in and simplify it here. And in the end you get what we want, which is that we've created this enjoying events variable, this event variable, that corresponds to a type of enjoying events where the enjoyer is this constant that points to Jackie and the enjoyee is this constant that points to something like something that represents Comp. 5, 50. Yeah. So if there were 2 verbs in the sentence, would we expect it to be 2 event variables? That's right. So the question is, if there are 2 verbs in the sentence, do we expect there to be 2 event variables. So yeah, that's what you would expect. Okay. so now we've done proper nouns. We've done intransitive verbs and transitive verbs. So what's next? So next, let's do quantifiers. So it turns out that language is full of quantifiers. And so the ones that most clearly map onto logical quantifiers are these words like all and every which map to universal quantifiers. For example, our students, like Comp. 5, 50 would be for all. X. Student X implies, like x. Comp. 550, I guess technically here to be consistent, I should really do. There exists an event, E such that E is in liking event, and the liker of E, and the liker of E is student. No sorry is X, and the like key of E is comp. 550. But here, I just for the sake of clarity, I just switch back to like the simpler predicates way of expressing events. But either works. Okay. But okay? Because right now, what we're focusing on is the bonification part. Okay? So all students like Comp, 5, 50, it's for all. X student X implies something. And then there are also existential quantifiers. So when we do model indefinite articles and also quantifiers like sum is that some student, a student, likes comp. 550 is expressed by an existential quantifier. There exists in x. Such that X is a student, and then X likes comp. 550. However, you want to represent that so just as a reminder. the universal quantifier is almost always accompanied by this implication. logical implication, whereas the existential one is accompanied by the conjunction. Okay? Otherwise, that doesn't work. If you have so can. Can. Do you remember, have you? Have you seen this? I'm hoping you've seen this kind of yeah. Cause cause what happens if you have for all X student X and X likes com, 5, 50, what would that mean? Yeah. that's right. Cause if it's a conjunct. What it means is that it's asserting that everything is a student, and everything likes Comp. 5, 50. Whereas here what we want is that we want only the students to like Comp. 5, 50, not the not the instructors, and not the tas, and not like anything that's not a person, for example. So here this is a condition right? So to express condition. you use the implication. Error. What about like? There exists an X. Such student X implies X likes. Conf 5, 50. Why is that wrong? Yeah. You're saying that there exists a student, and there's something that makes Comp. 5 50. But we're no longer checking that that X is stupid. that's that's I think that's almost that's almost it. It's the same. It's the correct flavor. I think the specifics I'd like to. Yeah. of course. No, no, that's the correct meaning, right? So the correct meaning is, as long as there's a student who likes. Conf 5, 50, this thing should evaluate to true. Yeah. yeah, yeah, that's yeah. So if this was an implication arrow, as long as you have anything that is not a student. It evaluates the whole thing evaluates to true. So the implication is just very weird. And it's just not right. There. Yeah, what about for the universal one? If you include parentheses like for all x. and then open the parentheses that X is a student. And they like convoluted 50 where the X is the same as the one outside, like you would enclose the inner part in brackets, forcing that X to be the same one as the student and them liking. So the question so, okay, so are you talking about all students or some student. all students. So for all students. If you add extra parentheses and you replace this with an end, it it still doesn't work. It's still the same problem. Yeah. yeah. So I, yeah, you can work through this. So the the basic idea here is that for universal, it's usually a condition. So it's a universal only for like, according to some condition which here is like all the students, that's the condition for existential. You need both to apply. So there's some something that is both a student. And they like, Comp, 5, 50. Okay? So for our purposes, okay, I'm gonna skip to the lexical rules and then come back to talk about definiteness. yeah. So this is what the the form of the rule would look like you have. So this can be every. And this can be all, it's the same thing. So you have a determiner and then rewrites to the lexical item every or all. And then it's gonna take this general form where you're looking for 2 things, lambda, P. Lambda, Q. Which corresponds to the 2 parts of the implication, and then you introduce the universal quantifier here. and it'll look very similar for the existential. It'll just be debt rewrites to sum. And then lambda, p. Lambda. Q. There exists next such that P. Of x and Q of X, and then you can check that within the derivation in a tree, which we'll we'll see in an example soon. Okay, but let's talk about the other major thing which it turns out, you can model with quantifiers. And this is quite interesting linguistically, which is definiteness, like the. So we've modeled indefinites right with existentials. And now let's model. Let's talk about definiteness as well like that. The definite case as well. So luckily, in English and in French. We it's it's I don't have to like. Justify what definiteness is to you, because, like, they clearly exist as words like B or A, it turns out that many languages don't have these things like they don't mark definiteness like this. So this is also historically interesting. So maybe if the linguists were Chinese, they would not have focused on this so much, because in Chinese you don't mark definiteness, you do mark definiteness, but using a bunch of other means, and not with like these words, you can see, like B or A, okay. So and many other languages also do not mark definiteness with articles. and, in fact, like, if you're a second language speaker of English, maybe when you learn English, if you came from learning a language that doesn't mark definiteness with articles. It might have been tricky, right? I don't know. anyway. So how do we express the student in 1st order? Logic. hey? This is the question. So I'll present to you an early theory for this which works within our framework. which is, it's from Russell in 19 0, 5. Whoa! We're learning something from like the last millennium. Okay, so it's the Russell's theory of definite descriptions. So, according to him. when you say the student, as in the the student took comp. 5, 50. You're really asserting 3 things. First, st you're asserting that there is an entity who is the student. and then you're asserting that there is at most one thing being referred to who is a student. And you're also asserting that the student participates in some predicate which here would be took comp. 5, 50. This is according to Bertone Russell. Okay, so in this analysis, then in you can express all of this in 1st order logic. And let's do that? okay, yes, you have a question. So on one of the metrics, there's an example where it's like the apple is in the yard. Yeah. So the apple would have. This would have the 3 properties enforced, but the yard wouldn't, because it's not followed by a predicate. Right? So the question is, if you have, the apple is in the yard, what happens? So all 3 things still apply for the yard. It applies to the apple and applies to the yard. Yeah. because the yard is still participating in the predicate. It's just participating in a different position. It's not participating in the in like the semantic, I guess. Subject like position. It's just it's participating in like the like, more like the place position. But it's still participating in that predicate. So you have to assert uniqueness for both of them. Yeah. okay, so okay, so why these 3 properties? So and also in particular, why property one, if you consider something like the King of Francis Bald. then? then this is weird, right? So if you say the King of France is bald, if you know anything about French politics. France currently has no king. So if you say the King of France is bald, according to this analysis, that sentence should evaluate to false. and it evaluates to false because there is no King of France. This is actually controversial. Other people are saying, Don't don't think that it's you should say that the King of Francis Bald is false. They should just say that it it. It's just. It's neither true or false for other reasons. But we can talk. You can come to ask me about this in office hours. Yeah. You can also imagine defining a new constant for King of France, just like for proper nouns. and then the 1st order, meaning representation. 1st order, logic, meaning representation, might be asserting something like bald King of France. But this doesn't work because King of France has to point to something. And so then this already presupposes that it points to something which is the King of France. Yeah. So then, rather than doing this, according to Bertrand Russell, then you should just the King of Francis Bald asserts that there is an entity that is the King of France. In the 1st place. Okay? So then, so yeah, so we need to translate these 3 properties. There's an entity that's a student. There's at most one thing that is a student, and the student participates in this predicate. And so the way that you do this is with this relatively complex formula in 1st order, logic. So there exists in X, such that X is a student, that's property one. And it's a unique student. So for all y student Y implies y equals x, that's property. 2, and took X, comp. 550. Again I reverted back to the simple form of like the event. Semantics. So X took Comp. 550. And that's how you model the meaning of the student took Comp 550. Yes, question. That's a great question. So the question is when we say that there is at most one thing being referred to. Are we talking about like everywhere in the entire domain. Or are we talking about within the context of where that sentence is uttered? So. yeah, technically, this is like in terms of how we've defined logic so far. It's like in the entire domain of discourse. But that's why it's called the domain of discourse, because within the context of a particular sentence, you can define that domain of discourse, not as the whole world, but as like the world of like the shared conversational state between the speaker and the listener. and then with so within that narrowly scoped domain of discourse, then there should only be one student is what this is saying. Yeah. Yeah. So I think, like dealing with definiteness and so forth. is really interesting to me linguistically, but also like, this is one thing. I I claim that like language models maybe don't do so well with quantifiers and things like this. And one so one argument is that they don't really do reasoning and logic so well and so they often don't do so well when it comes to like thinking about how many entities and how many things there are in a particular context, because they don't build these logical representations. I would say that they probably do quite well in stringing together sentences that seem to use quantifiers correctly, in a grammatically fluent way. But if you ask them to reason about things, and if you ask them to like reason about oh, I said, like, there's a student. And the student has like these properties and got these grades. They might not reason so well because they don't connect the information expressed about the student back to like when it's introduced. So they don't keep, do like a perfect job and keeping track of how many entities have been introduced in our. And we are talking about and associating the right pieces of information with them. So arguably, that's because they don't like think about things logically. explicitly right. They it's all through word co-occurrences. yeah. So I think you can probably design a bunch of tests to trick chat, gpt into getting things wrong when it comes with reasoning with quantifiers. Yeah. Second room. like, we can't see it in isolation, right? So the second rule. And so it so yeah, it it is defined with respect to the 1st rule, because, like there's at most one thing being referred to. That's a student like you have to say that everything that's a student is the same as X. So yeah, and that. So this second part is in the scope of the 1st quantifier. Okay? Yeah. And also, if you want to ask me about this. So this was the analysis presented by Bertrand Russell in 19 0 5, there are now different analyses of these things. So if you're interested you can come and ask me about an office hours, and I'd be happy to chat about what are some other approaches to handling quantifiers and definiteness. Okay. But anyway. for our purposes, then we want to integrate all of this into our general paradigm of syntax driven semantic composition, so we already did it with the rule. Every we can do the same thing with all of the other quantifiers like A and B, okay, so we can do. Every student's. Every student likes. Comp, 5, 50 with the same rules as before. Like, yeah. So so with the likes and Npvp and Vnp, and so forth. And again, in the rules, I introduced explicit event variables. So this is what this would look like. Okay, so let's do every student. So for every student, this is the part that we haven't seen before. Right? So every is the this rule. Lambda, p. Lambda. Q. For all XP. Of x implies Q of x, and then, student, you can get from the previous slide. It's lambda. X, student X. So then the noun phrase semantics is, you just do function application on the 2 of them. And so then this function of lambda X student X gets put in where the P. Is. So I also renamed the X to the Y before doing that. So we have lambda. Q. For all x lambda y state of y student of y applied to X implies Q of x. and then you further simplify, and you take the X and you plug it in where the Y is. So you have lambda. Q for all. X student X implies. Q of x. So this is the this is what we want, because it's plugging things, plugging the student predicate in into the correct location. And then there's going to be a Q of X that is still to come, which is where we plug in the part about like likes. Comp, 5, 50. And yeah. And then you can, you can do this for the rest of the sentence and work through all of those function applications very carefully. and to to show that you come up with the correct semantic representation for the whole sentence. Okay, but we can do this part together. So what are the lexical rules with semantic attachments for a and for D, okay, so for I'll give you the the syntactic part of this. Okay, so this is the syntactic part. So what would be the semantic attachment for this and also for yeah, what would this look like? Yes. M. Dot lambda queue dot the exist symbol. F. Got it? Yes. Lambda, P. Lambda. Q. And then what was there exists. X, dot. P for open. Yeah. that's nice. Q. Yes, that's right. And what about for the yeah? almost not quite so the beginning. It'll the beginning will look the same. Okay, so let me do the M, that key and the queue first.st Yeah. yes, that's right. So basically, you have to take this whole thing from before. and you need all the 3 parts right? So there'll be. There exists an X such that p of x, and okay. So all of that. So exists. An x such that p of x. and for all. why. e of y wait. Yeah. Implies y equals x yeah, P of y implies that y equals x and the predicates so. and you might want to like, close this off in a parentheses. And Q of X. So that's the 3 parts. And sometimes because this comes up so often, this uniqueness. Sometimes people simplify this with like some. something like exist with a exclamation mark. So then, that's the simplification for this whole thing. It means that there's a there exists a unique X such that yeah. like this room. How did we come up with this rule? So we came up with it because Bertran Russell said so like intuitively. And then we need to write it what he said. So in logic. So he said that like it's exists a unique thing. So to exist, a unique thing. First, st it has to exist. So that's that's this part. And if it's unique, that means everything else that has that predicate must be that thing. That's the second conjunction. And yes, in the back. So for the P. And Q, we want something that takes more than one argument. How do we deal with that? It actually still works with this exact same form. Because how that would be expressed would be like the P. And the queue themselves would introduce those other things. So you don't have to worry about that. So if you have, like a transitive verb, intransitive verb, whatever it doesn't matter, they both apply. They both will be stuffed into the queue itself, and they'll be introduced by the other parts of the queue. and then the X will just be talking about the current noun phrase. so it'll still work. Yes. a becomes P. And Q. Sure. So the A becomes. Pnq, so the A is the existential. According to this type of analysis there exists something, and when, whenever you have, there exists, it's usually paired with a conjunction. because you're usually asserting that there exists some X that has multiple properties. and if you want to get to a deeper level of explanation, then you should write out the truth tables for conjunction, and then check that this maps to your intuitive understanding of what it means to say that there exists a student who has this property? Okay? Other questions. Okay. okay, so what about adjectives. Let's try to do adjectives as well. Okay, so let let me say that this is what we're aiming for. Okay, so what we're aiming for is that we have lambda X student X's student. If we want to say that there are smart students, then maybe they are lambda X, smart X and student X, that's the form that we want to get for a smart student. So now the the question is, what is gonna be the rule for smart, the adjective smart. Okay? So syntactically. syntactically, it will be something like adjective rewrites to smart. Okay, this is the syntactic. So now my question is, what is the semantic attachment for that. And we figure this out assuming that there's some other rule that combines nouns with adjectives. something like a The. You take the adjective semantics, and you apply it to the noun semantics. Anyone wanna guess or try? Yep. We have to like. say, lamb, something like lambda X, and then specify that there is the existence of some X satisfy us. Oh, maybe we also need yeah, something like that. Yeah, that seems promising. Go ahead just to say that there exists something that can be smart. Yeah. So land why is it not absolutely yep. And yep. sorry. Yes. yeah. I think that works. So then you can check. So if you pass in. say, a lambda X student of X to P, then it gets plugged in there. wait. Something is. okay, let's check, because I'm not sure if this we might be slightly off. So if we do this. then we have this applied to that, I'm going to rename this Y, and then, if we simplify that. then you get this. Oh, I think it works. because then this X now gets plugged into where the Y is. Yeah, it works. Yes, great. Any questions. Okay. so you might want to ask, do all adjectives work like this are all adjectives, adjectives about adding conditions to like additional conditions, like additional predicates or properties. Right like it seems to make sense right, like a student can be smart, or they can be tall, or they can be short, or they can be young and old doesn't matter like. And maybe you think that all adjectives might be like adding these conditions that you can express as predicates with a conjunction. But it turns out that this doesn't work for all adjectives. It works for, like the majority class of adjectives. But there are other adjectives like fake, or former, or false, or like things like that. Also like dead, maybe that where, like, you cannot model them with like a conjunction like that. So that's an another interesting thing to think about. Okay. so oh, yeah, sorry. Would it be okay to explain why for that for faith? Why investigator? Sure. So why doesn't this approach work for a fake? Can other people see the issue. So suppose you model fake as like fake X and Student X, why doesn't that work? Yes. Would order matter like a smart big student versus a fake smart student. So the order doesn't matter. a fake smarts. Okay, it might matter. Actually, I have to think about that. So normally, the order the adjective order matters syntactically in that there's a rule in English, for, like the order of adjectives. but semantically, it should not matter, for if all the adjectives are like the majority class of like these are called subsective adjectives. But like the I'm claiming that fake works in a different way. But it's a different reason. Yeah. Oh, okay, yeah. it's okay. Go ahead. What else? you're getting. You're on the right track. So I'm saying that fake X and Student X is not the correct way to model the semantics of a fake student. And you're on the right track. That, like something about fake X is really weird. There was some hand in the back. Yeah, in the back office. Fake by itself doesn't mean anything. Its definition relies one student as well, exactly. You can't really. So, okay, so there are 2 senses of fake. You can say someone is very fake in the sense that they're not sincere. I don't mean that sense. I mean the sense of like a fake student like it might be like someone pretending to be a student. Okay, but they're not actually a student. So you can't really check whether something is fake or not in that sense. on its own. You can only check it with respect to the property of the thing. You're they're faking. So it's not like, they're okay. So with smart and student, the idea is that there are a set of things in the world that are smart. And there's a set of things in the world that are students, and a smart student is like at the intersection of them. Even that is kind of arguable, by the way. But anyway, but for fake, this is clearly not the right way to model it, because it's not like there's a set of fake things in the world. You can. Only when you're talking, saying, talking about a fake student. it's it's a real person. The person is not fake. but it's that they're faking with respect to the specific property of studenthood studentness. And so for that reason, semantically, you cannot take this approach of modeling as a conjunction of multiple predicates. Yeah. So it'll be something like, they say they're a student. But they're not actually a student, right? They say they're a student. But they're not actually a student. Yeah. yes, I guess in this case, would we use not relevant specific, like base adjective. So how would you model instead? right. But a fake student is also not just anything that is not a student. Right? So you need to rethink this whole enterprise. So you to model the meaning of something like fake student with like non. These are called non subjective adjectives. You have to like, define it in terms of like, you have a function that maps between students from students to fake students. Basically. So you have to like, rethink this whole thing. Or if you talk about like Presidents and former Presidents, it's like, maybe that's also another case that you can more clearly see. So former Presidents are not all of the entities which are not currently Presidents right? There are lots of things that are neither Presidents nor for former Presidents, so instead, you have to like. remap that function of Presidents to another function which is like the function for former Presidents. Okay. yeah, there are lots of this is one reason why I really like language and linguistics. There are lots of like phenomena that if you think about it a little bit more, you realize that they're actually, really complex. But we just just don't think about it. We just can process language, because because we've learned it somehow. Okay. so I want to talk about another common property of natural language, involving modification that is interesting, and it involves quantifiers. which is a scope, ambiguity. So what are the possible readings for the sentence, every student took a course. Can you help me with this one? Yeah. So it's either every student student. So any course we have one course on there program, or they, every student took one specific course. That's right. can do you all get both readings is either every student took some course, a different course, or it can be. Every student took the same course. So how do we represent that using 1st order logic? So the way you can think about it is, you can think about it as the quantifiers can be rearranged and they can follow. They they can outscope one another, and they. This gives rise to different readings. So the 1st reading is for every students there exists a course such that they took it so here the universal quantifier outscopes the existential quantifier. And for in this reading it can be a different course each time, because you create this existential Y for every student X, so it can be a different course. The second reading. Every student took a course. It would be the opposite. It would be the existential quantifier outscopes the universal quantifier. So there exists, of course, y such that every student takes it. So here we would get a conundrum with our current approach. So our current approach with the lexical rules and semantic attachments so far would not get us both of these readings right. If you think about it, it will only get us the 1st reading. So in the 1st reading. the syntactic structure matches the semantic structure. because the syntactic structure has, like every students, being in the subject position, being on the outside. whereas the the existential quantifier is in the object position, it's on the inside. And so if you, if you dutifully work through all of the syntactic compositions with the semantic attachments. With the rules we described, you will get only the 1st reading, and you would not get the second reading. So that's a problem with. that's a problem with our current approach. So we would like to have a way to derive both of these readings from the syntax. Okay? So this is an illustration of this general idea, which is that we need a representation that is under specified with respect to some properties that we cannot no, until we have more contacts or more information. So we want an underspecified representation that is compatible with both readings. or in general with all possible readings. and ideally, we would like that without having to explicitly enumerate all of them. So there are many cases where you might want this like. You might just genuinely have some missing information like the tense or something, or you just choose not to encode some information in your meaning representation. So you'd like to have a way to do this. So you have a meaning representation that is under specified with respect to things you don't know yet. Okay, so I'll introduce approach called Cooper Storage. The general idea is that everything that you don't know yet you store it away. Like you. You have like a lambda abstraction over it, and then you store the relevant information away so that you wait until you have, like some more information later on. and when once you do have that extra information, then you can take things out of storage and like, put them in the right place and gets the correct interpretation after all. So, for example, in our case. maybe you saw the expression, every student took a course. and it's within some like syllabus describing courses and students overall. And then, once you've read the entire syllabus, you can figure out intuitively, you can figure out like which was the intended interpretation. After you've read the whole syllabus, and then you can go back to retrieve and derive the corrects disambiguated meaning representation. From the underspecified representation. Okay, so how does that work. So we have. Every student took a course. And what's going to happen is that we're going to express it using something like this. So here we have our event variable, and we have a taker and take key. And we're gonna say that s 1 and S 2 are, gonna be these like special here. They're free variables, right? And they're associated with some entry in the storage which represents like things that like we're not sure what order to do things in. But we know the specific relations that matter. So here we're saying that s. 1 here is associated with for all students, because it's the students who are taking the courses. So because it's every student took a course. And the Takei, that's a thing being taken. It's the existential. There exists a Y course Y, and that's associated with S. 2 with the second entry in your storage. So this is going to be the underspecified representation associated with the sentence. and then, when you have the extra information, you can take things out of storage, and then recombine like recombine them with the meaning representations to get the correct sentence level representation. Yeah, right? When we said the aim was to have this underspecified representation that embodies all readings without explicitly enumerating them, it meant like, we will have 1st order logic for every possibility. But we won't capture like every possible explicit sentence. So when I say, what does it mean to have some representation compatible with all possible readings without explicitly enumerating them. So this, this is the an example of that. So this fits that definition, because I'll show that you can derive both possible meaning representations from this storage from this underspecified representation. But this one. It's not enumerating just saying this and this, and this is possible. It's just saying that here's here, there's some taker and some takey, and then there's some things in storage which corresponds to the whether it's the student doing the taking or the course, doing the taking, and so forth. So that's what I mean. So this is compatible with all possible readings. But it's not just listing them up. Yeah. And so the index variables here, the index indices here are important because they point to the things in the storage. Okay? So when you do how know which order which reading you want. you want to be able to recover them. And in cooper storage how this works is. So first, st you select the order in which to incorporate the quantifiers. and then for each quantifier you introduce a lambda abstraction over the appropriate index variable. And then you do beta reduction. So a function application to simplify. So what does that mean? Okay, so suppose that we want to 1st incorporate entry one and then entry 2. So you pick an ordering. Then what you do is you retrieve thing from you, retrieve things from storage. So then you have your You have the piece from storage. and then you have the meaning representation where you've added this lambda. s. 1. So now now s. 1 is a bound, variable now. and now you can simplify. and if we do the simplification. then you can put the the taker and the correct place. So if you do the simplification, this lambda. Q. There. it's this whole thing. And then so it becomes for all. X. Student X implies the events and the and the X gets put into the correct place with the taker. and then you do the same trick where you you take entry 2 out of storage, and then you introduce a lambda abstraction over s. 2 to make it a bound variable. So then you can then do the simplification. and you end up with one of the 2 readings. which is the existential outscoping the universal. If you want the other reading. it's the same idea, except that you extract 2 first, st and then you do the one. So you extract the the second the second entry from your storage first, st and then you introduce Lambda, s. 2 1st and simplify, and then you do it with the universal second, and then you have the universal, then outscoping the existential. So that's the process. You can also write it formally within this idea of syntax driven semantic composition by changing slightly the format of the semantic attachments, so that you talk about whether you're introducing. You're adding an entry into your storage or you're retrieving. And then well, you can't retrieve when you're doing the composition, because during the composition part, you're just building up your undespecified representation. So now you need to specify when you're composing a quantifier with a noun, you're now modifying the inside part of a storage and then now the Np introduces a new index variable which is wrapped in some lambda expression. Okay, so this is what it would look like. So now, when you have a course. so course still looks like what it does from before a still looks like what it did from before. and when you compose them syntactically. this is what happens semantically, is that you want to introduce a new lambda UU. Of s. 1 which is associated with some entry in your storage of and inside. Here is where you do the composition that we had from before, but before it was outside. Now it's inside the storage. and this lambda UU. Of s. 1 lets you to continue to derive the rest of the meaning representation on the outside of the noun phrase. okay, so I will, and I'll post this the the answer to this on Ed. But you can derive this yourself, work through and derive the representation. The under specified representation for every student took a course with these rules, and with the this rule for the transitive verb. and you can check and make sure that it all works out for to get the under specified representation, and afterwards I encourage you to also like, do the derivation, for, like both sides of this, so do the one, and then 2, and following this example, and then do the other one of 2, and then one to get the other reading. Of this. Okay, so if there are no more questions, we'll end there, and I'll see you at the midterm or in office hours.
