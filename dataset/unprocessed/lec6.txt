David Ifeoluwa Adelani: Maybe that's cool. I don't care. Hey? Alright welcome to Hi! Hi, everyone! Can you hear me? Okay? Welcome to lecture Lecture 6. So today we'll be talking about smoothing. I think someone asked a question last time about this, and then I think I can explain in details about what is called smoothing. where you try to redistribute the some probabilities to unknown tokens. So this is what we want to cover, because if you're able to estimate probabilities for your language model for every combination you have in your training set. There are some times that you are. You might have different combinations in your test sets. and you have not estimated that probability. So the question is. what can you do? So that means the id scenario will be damaged, you must be able to estimate the probability so that the probability is not 0. If you remember, in the naive days we make a lot of assumption on independence assumption. So if you always make your probability to be equal 0, then it's going to ruin your estimate every time. So the idea is, is there a way you can reserve some of the probability mass such that you'll be able to reallocate some of this, probably to us. to talkings all and grams that you don't know their probability when they count is 0. Alright. So let me try to. I am trying to. Okay. So last time we okay in this lecture we're going to. I I mean, I think I will just do a review of how we evaluate language models. and then I will talk about how you apply smoothing for onsane data. So just a reminder. the passport language model is to predict the next world. Given some context. So, for example, Mary had a little could be lump or accident. And then last time. just a revision. We explain that we always make the assumption of conditional independence and the conditional independence is that the probability of the world? Given the context? You don't have to say it depends on all every context from, let's say W. 1 to WN. Minus one. You can make it depend on just the last token or the last previous 2 tokens. and if you make it to depend on the last token, you have a background model where you can compute what is the probability of the next token you want to predict which is Wn. Given the context C, and that will be probability of N. Given the prob. Sorry that will be probability of Wn. Given Wn. Minus one. and for the diagram model, that will be probability of W hand given Wn. Minus one and WN. Minus 2. Okay. Just to rephrase. how do you compute the unigram distribution for a particular world? If you want to compute probability of cats. how would you compute it? So that would be count of every time cat appears divided by count of all the words in your couples. Right? And then for Bigram it will be if you want to compare the probability of cuts given the last token that it has seen, that is d. It will be the count of the cat, divided by Count of the. And I think we also went to an example in the last class to clarify this. So for Tridram, how are you going to calculate this? Who can answer that. How can you calculate the probability of cats given feeding? Yes. of impacts over top of EPA. Yes, exactly so. It will be the the count of you the cats divided by the count of feeding. So we said that everything we are calculating is what is called the maximum likelihood estimate but today we're going to see how we can derive also a general MLE. For a. for a particular purpose. If we know the probability distribution. we can have an exact calculation of what will be the Mlb. Of the Theta. Okay, so and last time we also talked about how you can evaluate. For example, you could use things like cross entropy or publicity. and I'm going to give you a small exercise. Or now you can compute publicity, for I'll Instagram motion. Alright. So, except you have question, I will just keep over this. So last time we also talked about how you could compute that using the ideas from information theory. and we said, information of a particular random, variable X is equal to the log of one over p. Of X. And if you take the expectation of the information you have what is called the entropy. Which is the expectation of of your random variable, or the expectation of the information of X, and we can connect this entropy to also compute not only entropy for a particular distribution. but we can also compute the entropy of a cross, we can compute the cross entropy where we can compare 2 distributions. Where P is the true distribution? And Q is the modal distribution. and by definition. This is the definition of how to compute our cross entropy. Which is H. Of PQ. Equals this equals the sum over. PI. Log of QI. If you are aware of care, divergence! How many people know care? Divergence? Okay. there is a way you can connect cha divergence also to cross entropy. because what cross entropies are trying to do is actually to compare to distribution our care. Divergence is also doing that right. So the care divergence. If you have time, you can try to work out the formulation of what is the connection from care, divergence to cross entropy as an exercise. Okay. so how do you estimate cross entropy? If you don't know the true distribution? And this is a scenario, we are always in We often do not know the true distribution of the test set, so we assume our model is good enough, and then we try to estimate, just based on our model, which is our cube? Do you have questions? This is where we stopped the last time. Any question? Yes. I have a question about the cross. Entropy gives us a number in bits. Yes, which means that perplexity gives us the number of possible numbers you can represent with those bits, because it's 2 to the power. I didn't understand why, that's a useful like, what's the connection between that and why? It's a good measure. Yeah, okay, that's that's a good question. So if you have a good model that can represent your test set very well. the perplexity will be lower. right. So if you have a bad model that cannot represent it. Very well. your publicity will be higher. So it's a way to measure. So basically, how how can you measure how good is your language model. So for naive based classifier a measure will be things like f. 1 score or accuracy right for a language model. our metric is oftentimes the publicity. and this publicity is a bit tricky, because publicity depends on your purpose. Right? So you cannot say, because I have a good publicity of 15 on brown Corpus is also related to the publicity of 15 on English Wikipedia. Oftentimes, if you can achieve a place of 15 on English Wikipedia, you might have a better model than having perplexity of 15 using a brown compass. Why? Because the English Wikipedia is larger, and if you can have a smaller estimates. That means the model is better. Okay? So yeah, this is the warm up exercise. Just to revise words we did last time. How do you evaluate? The publicity of this language models. Model one. What will be the publicity? Okay. what do you want to estimate? Give you this example. Imagine you have, like a sentence, A, BCBB, and then you have the probability of A, you have probability of B, you have probability of C, so what is the purpose to give it this formula? And this is the cross you 1st you have to compute. What is the cross entropy when you have the motor distribution queue. So how would you compute the modal, the probability of the model distribution? Yes. Can I get the final formula for complexity? Of course the final formula is here right? No like this. 2 to the power of minus one over 3, because the size of the corpus is 3. ABC, No, that's not the size of a couple is 5, the size of the coppus. So the number of types is 3, 5. Okay? So the the 1st thing you I I need. First, st you have to assume something. What is the 1st thing you have to assume? How would you compute Q. Of w 1 to WN, basically, you want to say, what is the Q of the test set? What is the test set? Q of a, BCBB, right? So what is the what? What would be your 1st assumption? Yes, so conditional independence. And what's what? What is that for? Unigram language model. What is conditional independence for Unida language model? Yes. yes, and that is what. So what will be Q of w. 1 to WN. Upload the bargains or something. Yeah. that's correct. So for your test sets QQ of a, BCBB. So how would you compute that? Yeah. No, that will be probability of what? A BC, yeah. So it's the probability of a times probability of B times. Probability of C times. Probability of B times probability of B is that clear? And if you multiply that. you will then normalize right by minus one over hand, right? And then you insert that into the publicity formula, which will be 2 raised about what you get. Is that correct? So for Model 2, it will be very similar. The only difference is that you have what different values of the probability of a BC good. So this is the answer, basically to rest of our minus one over 5, because N is the size of the compost. Yes. yes, that's the asset. Away from the you know information you have here. You assume that you already know. or the probability for the uniform distribution you have computed it. Yes. Okay. So this is assumed that you already computed what is the probability? Of A, BC, because we don't have the training data in this example. So you cannot calculate this yourself. We assume that, given a training data. and you have already estimated unigron probabilities. as P is probability of a equals. 0 point 3 probability of B equals 0 point 4 probability of C equals 0 point 3. So if you have computed this, I mean, if you are very fast in computing this. you can you tell me which is a better model for the test set. If you have a very fast in computation. Yes. Have you completed it? Yeah. what is the number? If you have computer. which is a better model. And why is it the model with the higher publicity, or the model with the lower perplexity? What! The model, of course, the model will lower the cost. hey? So here we will. Okay. Why. I mean, why is this called? Now we want to examine what is called why, why do we call you know, we talk about M. And a last time. And then why is it called maximum likelihood estimation? So here we're kind of going to generalize it. Given assuming a distribution, for example, like a Bernoulli distribution or multinomial distribution. And then we provide like a generalized formula, and then you have an understanding of why we are doing this so in the maximum likelihood our aim is to find the model parameters. So all the set of model parameters we need is theta that can maximize the likelihood. and that's the probability of generating. Your training, purpose, probability of X. So the idea is that we want to find the optimal parameter. Theta. That's the probability of X with respect to this data is maximized. I believe this is very accurate, right? So this is what we want to do. And we make the following assumption. what are random variables that are drawn from a category called probability distribution? I don't know. I think this is clear, because, you know. everything's got scorecard distribution. We are in a district space. We know the size of our worth, and for different tasks. You have a few number of classes that needs to be predicted. and for a given context they are additional independence and identically distributed. So for a categorical, random, variable. So categorical catalog variable is defined as this. You have one at one of K discrete outcomes. If you flip a coin, you can either be the head or what, or the tail. and if you roll a die it can be 1, 2, 3, 4, 5, 6. So if you roll a coin. Sorry if you flip a coin once you are going to have a Bernoulli distribution right so, and there are 2 possible outcomes. The outcome can be the head or the toe, and if you can get the probability of one of that. you can get a probability of the rest right. So, if you know the probability of the head, then probability of the tail will be one minus probability of at is that clear? And if you do that with conditional probability. with independence. Assumption. That means, if you multiply. what is the probability of producing ad times, what is the probability of producing till that would be this and that will be theta raised by N minus one, and then one minus Theta N. 0. Oh, so. and of course we can extend this From Bernoulli distribution of K equals to to something like a multinomial distribution where you have more than 2 outcomes, and of course, more than 2 roles of the experiment. Okay. So here, how do we compute the mle? The 1st idea is that you once you know the probability distribution. you can take derivative and equity to 0, and if you equate it to 0, then you can find your optimal parameter. If you are even familiar with this, maybe for machine learning or so. You know that this is very simple idea. So how do we derive mle? For Bernoulli are free for me to stop me. If you don't understand. We make an assumption that which is a very simple assumption. If the probability is monotonically increasing. the logarithm is also monotonically increasing. Right? So if you maximize the probability. you can also maximize the log rhythm, you will still be able to find your optimal product. So technically, nothing changes. It's just easier if you take the log. So if you take the log of the Bernoulli distribution, what are you going to have you have n 1? Log of theta plus and or log of one minus theta. I believe this is planned right. If you have questions, feel free to stop me. And if you take the derivative of this formulation. what are you going to about? The derivative of log of theta is, what what about theta? Right? I believe this is clear. and then you multiply by n. 1, and then and or multiplied by the derivative of log of one minus theta again will be one over one minus theta. Well, because you have a function inside a function, then you have to multiply it by the derivative of what is inside. and that will be minus one. And after you have done that, you can equate that to 0. And then you can find what is the optimal parameter? But, Sita. do you have question? My name is Claire. Okay, so what if we have K is bigger than 2? That means you need multiple number of parameters, you need to calculate it out 0. So for every probability of every possible outcome. So for the Bernoulli distribution, we have 2 possible outcomes. and for a generalized categorical distribution for K, bigger than 2 we can have are from we can have. We can have theta for all these possible number of outcomes. So here we have Theta 0, theta, one to Theta K minus one. And apart from that, we also have the counts for all this. and by this we can also derive a realized mle or the optimal mle for the data we are looking for for us. To do this we can use what is called Lagrange multiplier. which is, you're saying. dots we want to maximize the theta with respect, subject to the condition that all the probabilities are, if you sum them. is the cost of one. And for Lagrange multiplier! What you do is that what it's subject to? You now have like what do you call it? You have a scalar to multiply water subject. So I don't know. Maybe I lost some people. So basically, you said, you want to maximize data with respect to, let's say log of the of. And then you said you can subject to the condition that the sum of all the events here, what you do. who starts? If you want to take the lobby, you can just say. and so probability of P. Of X amount Zita loss. a large multiplier, if you so basically like. after you have computed the ultimate parameter of theta, it also computes the ultimate parameter for this like a ranch multiplier, which is a landlord. What we suggest is, this will now be. I know, swap. and then this will be. What should we put here before you perform your amendment? All right? So. and this is what I did. Yeah, so basically, what is the probability based on your corpus. Give them theta minus this Lagrange multiplier. With respect to what's the subject inside? What's the subject to? Which is you? You are assuming that all the probabilities will sum up to one right. And now, if you do that, you can take 2 derivative. First, st you take the derivative. With respect to Theta, I, because you want to find one of the teachers at Theta I, and then you also perform derivative with respect to the Lagrange multiplier. and if you perform the derivative. With respect to one theta I you're going to have this formulation, which would be Ni divided by theta i and every other thetas that are not equal to Theta. I. We are going to be 0, right, this guy and you're gonna have the same thing which will be Ni divided by theta I minus lambda. Because if you perform the delivery, we are just gonna have one name. Mine knows the scale up. and if you do the math, this will be Ni. Equals to lambda theta I. So if you do, your derivative with respect to Lambda. everything on the left hand side is 0, and what you're going to have remaining will be the submission over I of Theta High minus one. I believe this is clear, and if you do the math, you see that you're gonna have the summation of theta I equals to one. So if you sum up everything. if you sum up all K equations from step 3, which is the step 3. Here. if you put summation both on the left hand side and the right hand side. You're gonna have what you have on line 5. And here you can also say that if you look at Line 4, which is submission of are all the theta I's equals to one. So what we are going to have here is that you can bring the constant out. and we know that all the summation of Ni. Equals to N. So then, that means your N. Equals. What's lambda? All right. So, and if you now put 3 and 6 and combine them together, you'll be able to find what is the optimal parameter of Ni equals Ni. Divided by a. So we are saying that the optimal parameter of computing Theta is just. You divide accounts by what's the total size of the corpus. So it's a very simple formula. But the problem is that if you do discount like that, you are very prone to what is called overfitting. Why? Because you provide what is the exact formulation. The problem is that if you are going to test it for an unseen data. you are very likely to have a lower performance. Yeah. yes, just to confirm it doesn't matter. The sign in front of the Lagrange multi, right? It can be positive or negative. Yes. like very responsive there with negative, but they both work. Yeah, I think it would work. Yeah. Oh. all right. So the next concept I want to explain is out of vocabulary. and also vocabulary is basically, you have a word that is not present in your vocabulary. So, and for this kind of work you have not estimated any probability in your language model. because this world is appearing for the 1st time. And the question is that what do you do to this this kind of work. How do you compute the probability? Let's assume you want to compute the perplexity. but you don't have the probability for this world. How would you compute the publicity. This is not possible right? And that's why we need to kind of perform what is called smoothing. So to kind of reserve some of the probability to an unseen word that we have not estimated probability for. So imagine you have train your language model on an economic data or economic news. From 18 1987 to 1989. If you want to estimate the probability of Brexit Brexit is a very recent time, right? I don't know when maybe 2,016 around that time, and then you find that that war doesn't exist in your training purpose. So there's no way you can compute probability for this. So it's an example of a out of vocabulary word. So the problem is that how can we deal with this out of vocabulary word that is not in our training data. So what we can do is that we, when you're computing what is the count of every word in your couples? And you want to build a vocabulary. One thing you can do is that you can select a threshold and say anything less than 5. I'm going to treat them as what as unknown. for example. if you look at the zip law that we examine last time we have words like off D have has a lot of occurrence in your couples, and then you're going to have very rare words, even like a 1 like Zip also used to be very rare in your corpus. and you can assign this kind of even though you can estimate the probability. But the probability will also be very close to 0. Right. So let's tell them the size of your vocabulary is 100,000, and the walls, if also just appear once, so that would be one over what 100,000, which is already very close to 0. So the question is, how do you deal with this kind of words? So you can have a threshold and say any word that is less than let's say 10 in my corpus. I would treat them as a node. but you also have to modify the way you do your counting in such a way that you can resolve some probability mass to these unknown ones. so all other words that are infrequent can be replaced by unknown. and then you have another word called unknown, which will be part of your vocabulary. So during testing any words that you don't know will be assigned unknown. But this is possible, because during training you already assign some probability, mass today's unknown. and then you can reuse it at test time. Is that clear? And the idea is that, and that is the idea of smoothing. So during your training corpus. your training purpose does not have all the rewards. And then you have already added a special token called unknown for the unknown words. and the idea is that how do you estimate for these infrequent words, we need to slightly modify this probability distribution, and the idea of smoothing is actually the probability distribution to shift some probability mass to cases that we haven't seen before, or we are unsure of. So the idea of of this would be, we can modify the way we compute our mle where we are trying to maximize the probability. The theta of Emily. that maximize the probability distribution. And here we modify it also by saying, this would just be probability of X with the theta that is smooth times the probability of theta that small. This is like adding a prior distribution. To to your formulation. the simplest smoothing technique is what is called the art theta smoothing. Some people say add alpha, but anyways out the odd delta smoothing on. If you remember, during the unigram distribution. How do you compute the probability? You just say the counts of the world divided by awards the size of your corpus? That is how we computed. Now, if you want to resolve some probability mass to an unknown world, you have to now formulate off what is called data. so data can be, it's it can be a very small parameter. Some people can use one divided by the size of your corpus as data. or one where, by the size of your vocabulary has data. So this is kind of you have to select this. It could be using cross validation. But you have to select your data. And the idea of this art data, small thing will be. instead of just dividing the count of words divided by the size of the corpus. This will be the count of the words plus data divided by the size of your vocabulary times data plus the size of your compass. So wow, you said that it's A, B, BDB. And then, when we want to copy the probability of A, let's say we want complete parameters of A here. That's what it was. Just one more time, right wonderful. Now. It shouldn't be enough for Malaysia to. If you now want to calculate the probability of a. Then, you say, because of the normal times. the number of act, or less, they count is 3 comes from the number of, as you see here. plus delta 0 point 0 0 5. Invited by the size of your Combos. I want you to be and close that side of the good online. Again, it's been one plus 0 point 0 0 5, divided by fine gross 0 point 0 0 5 multiplied by what is the size of a vocabulary this right question. Alright. Is this bad? Okay? Now, if we assume data is if we assume that data here is sorry, no, no data is one, then what you have what is called the Laplace. Discounting. do you have question? And if you do this for all, now you try to do this. If you can do this very fast. and to compute probability of a compute probability of B compute probability of C, you will see that it doesn't sum to one. And then then you understand, the idea of you have reserved some probability for the unknown token. And this is what we are trying to achieve. Do you have questions? Alright, yeah. One. Because you're trying to resolve? Yes. yeah. yeah. It's an upper privatar. So you can look closely. Yeah. alright. Is this the same as Laplace? Smoothie. Laplace discounting is when the letter is one. and that is because I've heard the term Laplace smoothly. Yeah, is Laplace is just. Data is defined to be equal to one that's Laplace moving. So it's just assumed that it's 1. Alright. So I think I already explained this. Yeah, so this is the idea. So the probability of the outcome will not modify as accounts of the outcome. Loss data divided by the size of your training purpose. plus the size of your vocabulary, was supplied by data. So for a background model. that means you 1st have to compute all the counts. what's? And then you have the data. That's why I have the small data. Yeah. So you have. You go add the data in the numerator. And for the denominator you multiply data times the size of the vocabulary. Hmm. so we can attempt this. What would be the mle estimate of probability of Kong. Given donkey? Yes. 0 point 5. Yeah. that's correct. Yeah. Oh, sorry. Let me see. Yeah. Okay, 5 over 10. Yeah. Now, the what is the Laplace estimate of probability of Kong given dunking. Yes, 56 over 11. No. yes. 6 over about 20,000 out of 10, okay. 6, over 20,000, 6 over 20,000. Is it? 20,000 alone? 10,000 on something? It's correct. Okay. so and now you see that the probabilities from half goes to that means you have resolved a lot of probability. So if you do this for many tokens. you always have result probability you can use for non unknown topics. Okay. now, the easiest way you can do is just to do what's called interpolation. So if at the test time, so the way to think about it so that you can understand is that you have already estimated. All your probabilities are the training. Are the test sets. You're trying to see. How can I deal with unknowns. This is the way to think about it. One way to deal with your own is interpolation, so you can interpolate. The probability of your trigon model with the probability of your Biegar model. with the probability of fuel. Uninter model. And this is what we call back off language model. So you go from a a higher order, language model to lower order, language model, to see if we can do compute the estimate or a probability. So this is a very simple way to combine the trigon probability with the background. Probability. So let's say, at a test time. Why try to compute the probability of Wt. Given Wt. Minus one WT. Minus 2. You don't know the probability you can back off to the background. Probability maybe you'll be able to estimate probability at a diagram level. and if you are unable to estimate probability at the diagram level, you can go back to Unigram. Maybe you're very likely to estimate, and if you are not able to do that. then you just assign the unknown a probability which you already resolved. Is that correct? Yeah. yes, I would say, development set. Is it the same as validation set? Yes. okay. An example of a more advanced smoothing technique is what is called good sewing. smoking. and the idea is is a little bit more sophisticated for handling the unseen events. And okay, I think we have time. So if you remember the Zip's law. and the idea is that we should not adjust all the words uniformly. Can we kind of adjust it differently. depending on the frequency of the world. So the way you're going to compute the way you're going to estimate the unknown. So like, okay, the idea is that for infrequent words you want to assign them the probability of unknown. But you don't want to do it differently. So if you have a threshold of 5, that's everything below 5. I'm going to assign them. We don't know. You say that the kind of a no, you will give for the word. I appear once should be different. For the value of unknown you will give to the word that appears twice should be different to the value of your known. You give to a water pay 3 times. and then you kind of have slightly different probability for the unknown values depending on how frequent they are in your covers. Alright, so the frequency of the word or angram is related to its round. which we already see in the Zip's law. an on synongram should behave a lot like. and grabs that only occur once in your corpus an engram that occur a lot should behave like other engrams that occur a lot. So here we can do a ranking and said, the event frequency. It's your count, like the count we have here. and the number of events with that frequency. Let's say it's admin. Okay? And f, 1 will be the No. The number of events. Sorry the number of events with a frequency of one that's f 1 f. 2 will be the number of events with a frequency of 2, so you can have many, many words that have frequency of 2, and at f. 1. You have many words that have equation one. and usually the words that we have frequency of one will be more than the words that we have frequency of 2 will be more than what's the half frequency of 3? So that is the idea. So for some events in bin, so you bin them based on their event frequency. This water will appear once you bin it. This water appears 2 times you've been it. This water appears 3 times to bin it. and then, before you compute your numerator, which is. the carrots. We are here on the bottom. Okay, we have this home address all over the place and post if you want. And the thing is that what we want to modify our goal is to modify our accounts in such a way that we reserve probability right? So the way we compute accounts now is that we say c plus one multiplied by the frequency of the count plus one divided by F of C, and an example is the following, the probability of unknown is f 1 divided by N, which is. are all the number of words with frequency of one divided by the size of your campus. If you want to compute c, 1 star, because you want to modify, as the count of one. and that will be c. 2, which will be c, plus one multiplied by the frequency of C, plus one, which is 1,292, divided by the frequency of C. FF. 1 is 3, 9, 9, 3. And this is a way you're gonna modify the counts for good time to try to address the unknown issues. Excellent sense! Alright for this can you confuse what will be the Guitarin estimate for the following words, any unknown word. soccer, camp and pass. using the using the formula. the last page is there something that F of 0 is n. we don't have F of 0. We have F of one. but for an unknown word that appears 0 times. No, because here you are trying to estimate it at a training phase. so that at a test phase you'll be able to address the issue of unknown. So every word should appear one once, if it's in your training data right? With unknown words, so often unknown words don't have here, but you assume that your no wants to be. When you want to evaluate the model, right? So what's the probability of unknown, which will be f 1. What is f 1 here? 3 over yeah. 3. And then probably say of unknown will be what? 3 over 15? Yes, that's correct. So what's the probability of soccer? So what's the probability of soccer? So because soccer is appearing just once. That will be C plus one. That will be what 2 times frequency of C plus one divided by F of one and F of one f, 3. So what is F of C plus one? What is F of C plus one? Yes. yes. F of C, plus one is 2. Yeah. So what's the probability of soccer? Yes. something about N. 15 and 15 is just the size of your compass. So if you sum up. Everything here should be equal to 50. Yes. for probability of soccer. No. yes. yeah. 8 over 50. But that doesn't seem right. Yes, no, it's not? Yeah. 4, over 45 is correct. Yeah. So how did you get at 4? How did you arrive at 4 or 45? Yes, 4. Battery. Yeah. 4 by 3, divided by 50. That's correct. Is that clear? Are you able to? Yeah. Fc, would be one, because soccer. There's only one man. So because C. Star is C plus one. That will be 2 times 2, because FF of 2 is 2 c, 2 C is one. That's the force count and one plus one is 2. Let's carry 2 times F of 2, which is also true. because you have 2 items that appeared twice. and that's 4, and then you divide it by F of one, and F of one is 3. You have 3 items that appear once and then you now divide that with count, which is 15, and that's how we will get 4 over 45. Is it clear? Yes. also for each, for each purposely of offices, that they had. Actually, the idea is so that they don't that up to one. That's what we're trying to do. I mean, that's the idea of smoking so that you can resolve some probability maximum or not. Okay. So what's the probability of? Come? So if you are able to get for for soccer, I think you'll be able to forget for count. So what's the probability of count? So count appears comp. Appears twice. So c plus one would be 3, right? What is F of 3 F of 3 is one right divided by F of 2. What's F of 2? F of 2 is 2. Yeah. So are you device. So what what are you going to get? Yes. So you're gonna get one over 10. Is that correct? And the last one is probability of pass. So here, what is your? So we want to compute. C. 3. Divided c. 3. Star, divided by N. So here you are going to say, 4 c. Plus 1, 4 times F of 4 FO, 4 is what f of one F of 4 0, and you already know the answer. FFO. 4 is a all right. Do you have question, or everything is yes. yes, that means there's some problem with the original formulation of goods road wish we are good to adjust events in the next slide. Yeah. Bureau. Yes, the probability of passing 0. Yes. deserve it 3 times. Yeah. But it's 2 0, because a good sign. Wasn't that smart enough with this population? Alright. So if you don't know the solution, this is a solution. which is 1st you have the count of counts, so you have the one frequency what I appear once. We have 3 worlds that appear once that's soccer, model and tops. and then ones that appeared 2 times are camp and frog, and then you have water per 3 times. Just one word, which is mass. and for water appear 4 times. We don't have any water appear 4 times, and that's why it's really the probability which is equal to 0 and what that appear 5 times. We only have one word that appear 5 times. and then, if you just insert the values into that formula. and it was the sum of all the pounds. which is 15, and the unknown is just f 1 divided by N. Which is still over 15, and probability of soccer, which which we would be The count of one at position one plus one. which is 2 times F. 2, which is 2, divided by f, 1, which is 3, divided by the count. which is 15, and you have 4. Over 15. Probability of the camp would be C. 2. Star, divided by N. And C 2 will be star will be computed as 3, which is because c, 2 is 2 C is 2 at that stage, so plus one that will be 3 times the frequency of 3. That's 1 divided by F 2. That's 2 divided by A, that's 3 over 2, divided by 15 and one that's 1 over 10. And the last one you have. C plus one. Okay, yeah. you have a question. even though, like a reason. Because. okay, so the F of one. So you assume that anything that appears once you want to assign a very small probability. Imagine this is a very big purpose you have, like any calls on a thousand. And then you say, if it appears, how many words that appears once will be, you just completed us. So basically, you want to assign a very small probability. In that case the value will be small in this example doesn't seem very small. But in a more realistic case, that value would appear once would be small. Yeah, yes. yeah, in this example. But there's some formulation for good terrain that they just stop on this discounting after 5. So anything from 6, or you can define the threshold. Anything at that threshold you you just do the normal mle because you don't need to account for it. Yeah, yeah, less likely to be equal to 0. So let's try it. So so like, why think about it? Okay, what should be the good tourist working for background. So this is how it looks like. So this guy, if you want to compute. you, want to compute Count of Wtr. And Wt. Minus one. If you want to modify the account and have Count Star. So this is the formulation. This will be the count of Wt. Comma Wt. Minus one plus one. Multiply by the frequency of that diagram at position C of that WTWT. Minus one plus one divided by F of C. Of that background. and once you have modified accounts, you can now insert back into your interpolation. Right? So you have what do you call lambda? One multiplied by the probability of the mle, which will be WT. Given Wt. Minus one plus lambda of a bit of Emily at the Union room. So this kind of summarize what we are trying to do that 1st you modify the count the way the count has been calculated. so results of probabilities. And then you can compute the infinite probability. for example, to interpretation while you're backing off from diagram to Unigram. Do you have questions? Okay. so as you have seen in the last example. simple, good turning often fail. And that was your question for higher values of C, because FC plus one is of one equals to 0. So there's a way you can estimate Fc as a function of C, and then you can have a simple linear regression to compute what will be the value of F of C. So if you take a look of the linear relationship between log C and log. F, you can estimate the parameters of A and B, and then use it to compute what will be your new values of F of C, so that with this we'll be able to kind of refine it to be so that we don't have FC plus one always equals to 0. And it's kind of ruin our estimate. Okay? Yes. The last slide. Terms of more that complexity trade off. Generally there is a trade off between how the model expresses expressibility. That is what trends you. You could capture about your data with your model and the amount of training data needed to give you a good estimate of the parameters of the model. So if you use, and a very, very expressive model, for example, the one with high values of n in in angular modeling. It's very easy to overfit. because you all often need to do smoothing and use more data. But, on the other hand. If you use a very small compost, your model is often so awake. and it doesn't generalize, so you can have a fitting, or you can have another fitting. Both are not good. And then you average kind of a trade off. Between what kind of corpus am I going to use to build my language model for this language. Is it a very big one or a very small one? Recent language models. They just throw every possible data to it. And of course, since they are safe. the the more data you have oftentimes the better it is. But for statistical language model. You have to think carefully about this. especially when estimating the probability of or not. Okay, thank you for joining today's class.
