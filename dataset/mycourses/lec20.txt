Jackie Cheung, Professor: Hi, everybody welcome back. okay, good enough. So people can online should be able to hear me. Okay, so welcome back. We're gonna talk about discourse and co-reference resolution. So I think last week you had an enjoyable week talking about machine translation and multilinguality with David right? And now today, we're going to move on to a new topic which is to think about processing language beyond the sentence level. And I'm glad you all decided to show up, because today's lecture also relates to the reading assignment the 4th reading assignment which has been posted so hopefully, this will help with that as well. Okay, so what is discourse? So we're 1st going to talk a little bit about discourse and think about and talk about some basic distinctions in the field of discourse. And now we're going to focus on one particular phenomenon related to discourse, which is co-reference resolution. and I'll explain what that is as well. And then I will discuss and present some basic algorithms related to co-reference resolution. That's the plan. So this might be a surprise given like what we've been talking about in the course so far, but it turns out that natural language doesn't occur as individual sentences or individual utterances like one at a time. Okay, so all of our models like this might be a surprise, because, you know all of the models we have had so far, or many of them. We only look at the sentence level or below. Right? So I guess in text classification. Maybe you like process an entire paragraph, and you extract the features from them and so forth. but like but in many of the other settings, in in like the past few weeks to do with like semantics, for example, we looked at sentence level semantics right? And in machine translation, often in many evaluation setups they assume sentence level machine translation as well. And so they do like sentence to sentence translation and then evaluate that way. But but yeah, it turns out that's like language typically occurs in bigger chunks than that. And so that means. We can also analyze the structure that is there at the level of the the whole discourse. So not just individual sentences, but relationships between sentences and also phenomena that cut across sentences that we want to think about. So then by this force here. Oh, the okay, the screen quality is not good. Oh, well, so by discourse here. I mean, like a passage on some topic. And so we can talk about some basic distinctions like the the difference between a monologue versus a dialogue. So in a monologue, there's a 1 way flow of information and communication like currently what's happening is a monologue, because I'm just saying things at you, and hopefully you're absorbing it. On the other hand, there could also be dialogues which involve multiple participants. And then there are additional interesting phenomena there that we could analyze or to get create a model of like turn taking like, when is it that? You're allowed to cut in and say something. Okay, when is it the end of a turn of one discourse participant, and then another? One will start talking also in in dialogue there are more diverse sets of communicative acts, so there can be more instances of asking and answering questions, making corrections to what other people said, negotiating disagreements, and so forth. So there are additional phenomena there to think about as well. So for our purposes we won't have time to get into all that, but we will try to cover some basic distinctions. So one basic distinction, one basic concept when modeling discourse is this idea of coherence. So what is coherence? Coherence is What makes a discourse a discourse essentially so. The fact that there are relations between different sentences or utterances. In a discourse well, that type, the the relation that that logical relation between them. That's what makes a discourse coherence. So in other words, there's some logical structure in, or in the meaning of a of a whole passage, and and so then And that can be analyzed. So, for example, here is a coherence. 2 sentence passage, indoor climbing is a good form of exercise. It gives you a whole body workout. and that's coherent, because the 2 sentences have something to do with each other. and you can even define a set of relations. They're called discourse relations between clauses and sentences and passages. So here the second sentence is some kind of explanation for the 1st sentence, right? So the 1st sentence claims indoor climbing is a good form of exercise, and the second sentence is an explanation of like, why is it a good form of exercise. And so there exists data sets out there where passages have been broken down into these chunks of discourse called elementary discourse units, and then people have also come up with different schemes to annotate or different kinds of relations between between these edus, between these chunks. So explanation is one of those relations. It can be like cause as well. It can be like temporal. It can just be a list. There are a whole bunch of relations people have come up with. and we can contrast this against. Here is another 2 sentence discourse that is not coherence. Indoor climbing is a good form of exercise. Rabbits are cute and fluffy. There's no clear relationship between the 2 sentences. And so it's not coherent. So one of the ways in which we can computationally estimate whether a passage is coherent or not is to check if there are devices that link, or there are linguistic devices that link together different parts of sentences. And so the use of these linguistic devices to tie together text units is known as cohesion. So it's important to understand that there's a difference between coherence and cohesion. Coherence is defined at the level of, say, meaning at the level of like these logical relationships between sentences or smaller chunks, whereas cohesion is like the observable mechanisms that you can identify that link together these chunks of text. So even within the very simple, like 2 sentence example, here. There are some cohesive devices like here, indoor climbing. And it's that's a that's a there's. There's a link there, right? It refers to indoor climbing. and also, maybe exercise and workout. They're related to each other. Those words are highly related to each other. whereas in the incoherent passage there's nothing really right. There's nothing. There's no clear link that we can observe, even in terms of like the linguistic devices that are used. And the this, this passage is also incoherent. Okay, so here is a passage from a news article that I extracted a few years ago about some Liberal government proposing new regulations to ban the random stopping of citizens by police and whatever. So we can think about what are some cohesive devices, some links between elements of this passage? So anybody notice anything so far. What are some ways in which the sent these 3 sentences contain some kind of links in between them? Yeah. Word overlap. Yeah, that's great. Let's see, like, see here, citizens and citizen. right? Officers and officers. Yeah, that's great. Anything else? Yeah. Fairly similarities in the embeddings between. yep. Can we compare the similarities and embeddings between each sentence? That's a great idea, too. You could do that. Yeah. So that is not directly observable from the words. But you can. Yeah, that's definitely computable. Yeah. they occur together like coherents and cohesion. I think it's like a coherent. The other sentences, then, could be what was mandate. Okay, sir, thank you, guys. That's an interesting question. If you have coherent passages, will you always find cohesive devices between them? I'd say most of the time. Yeah. but it might be that you can very carefully think about it and construct some cases where you can't identify anything obvious. But I'd say that in naturally occurring tests, almost certainly. Yeah, you'll find cohesive links between. But I think the reverse, though, is probably not true. You can have like passages with lots of cohesive links. But then it makes no sense like logically, I'm sure we've all read things like that. And maybe we've all written things like that ourselves. But that's definitely possible. Okay, great. So you've identified some of like the key features that are used in the field to model coherence by using these cohesive devices. So yeah, so one was a lexical cohesion. so related words in a passage. So we talked about words that directly overlap. But you can also just have words that are similar to each other. are are related to each other with, like, say, high cosine similarity. So, for example, citizen and government are arguably part of the same chain, because they're highly related to each other, perhaps, and also regulations and rules, even though they're not directly synonyms. They're highly related, and also ban, and also like stopping and stop and stop and maybe walk as well as like an antonym of stop. Perhaps. But this. These are examples of lexical chains. Another is co-reference chains. And that's what we're going to talk about more today. So lexical chains is just about relatedness. And you can compute that using, like their word vectors, or something co-reference chains, or are about the the direct directly pointing to the same real world entity. So I guess here new regulations and new rules they are. They're co-reference in the sense that the new rules are exactly the new regulations that were mentioned in the previous sentence. And then police and police officers, I guess an officer's here. You can say they're part of the same co-reference chains. I mean, arguably, you could like, you can maybe argue that the 1st occurrence here of police is about the general organization or whatever. And here police officers is about specific individuals. But let's set that aside like you can always argue those nuances, but we can say that they're they're likely to be co-reference. And also here, citizens, citizens, a citizen, and then they that that could be argued to be a a co-reference chain. So they're pointing the same hypothetical citizens. So these are called anaphoric devices. So we'll see this word again later. Anaphora. But Anaphore means something where you have a word, and its interpretation depends on something else in the passage. Okay? So especially, say they here. The interpretation of they depends on like the fact that it co-refers with citizen. Oh, here's another one there's although there. There are also discourse markers that we use to help structure a passage. And so these discourse markers help us explicitly mark what are the discourse relations between different parts of of that discourse. So the ones that I see here are the also, and and so also usually means that, like there is a additional elaboration that is somehow related to what was said before. Right? So officers must also inform a citizen so so like they have it adds one requirement, and then it adds another requirement. and similar with similar to. And there might be some other ones where you're drawing, creating, and drawing a contrast like by contrast, or in contrast, or but or yet okay. So those are some discourse markers that help indicate that there's some contrast, and that what comes after is different from what comes before. Or maybe it's different from expectations. So usually. And a lot of these discourse markers have. They tend to mark whether something that's happening or being described. conforms with like typical expectations about how these situations tend to play out, or whether they are in conflict with typical expectations. Okay, so that was a high, level introduction of discourse and some of the basic notions and discourse. So now we're going to zoom in a bit and focus on one particular phenomenon and issue in discourse, because we can't cover everything. and that has to do with co-reference. So first, st let's take a step back and and think about what the term co-reference means and how it's related to like a reference and so forth. Okay. So remember when we 1st started talking about semantics. we talked about maybe a form versus content or sense versus reference. And this is like getting back to that kind of thing. Okay? So basically, the main idea is, there is some kind of dichotomy or opposition between language like things that you can like. speak or say, or write down and and hear, and like see and read, and so forth. versus like things in the world, or in some hypothetical world that they point to which is at in some kind of more, at some kind of more abstract level. Okay? So the 1st thing the former. it's usually denoted with, like, with like form. It's it's you call that form in our current setting. Specifically, we're gonna talk about referring expressions. So these are things in language that will point to something else. Okay? So in this, in the literature, on core reference resolution, you can call them referring expressions. or they're also called mentions just for short. So there are things in language. And then the thing that it actually points to either like. So so usually, some are some, some kind of like mental or mental abstraction of that thing in the world. That would be the reference. So that would be the content. Okay. so then, there's this, this relation, then, between the referring expressions and the reference and that pointing process, the the thing that links the 2 of them. That is, reference, the phenomenon of reference. So the fact that you have something in language, and it points to something abstract, which is a mental representation of that entity in the world and the link between them. So the link between them is called reference. So far, so good. Okay, so it's really hard to model this. We try to do this a bit with like the module and semantics, right? But it's hard to model this and do this like for impractical settings, because, like. we all probably have different mental representations of things that are going on in the world. So there's it's not like, there's a agreed upon standardized format, for what content should look like and and what like the the and how to structure the reference. So it's quite difficult to do. But we all seem to do it in our minds. But to turn it into a computational problem. One thing that you could do that is still useful. which is not exactly about reference is to think about co-reference. So what is co-reference? Co-reference is when you have multiple mentions or referring expressions that all points to the same thing in the world. Okay, so here in this example, I have that cat or whiskers, or something furry, or it. and they all point to the same cat. They're just referring to the same cat with like different linguistic expressions. And so then these linguistic expressions are said to co-refer. And so that's the phenomenon of co-reference. Okay, so there. So so this is like a practical tasks that you might want to solve in its own right. But also it's convenient, because now we don't have to create an explicit representation of like the content which is really difficult to do right, because now we're just reasoning about different spans and language. And so then, we can solve this co-reference problem. Without needing to posit what the the the mental, these mental abstractions of like entities in the world should look what form they should take. Okay, so yeah, so then there are other related terms. So that cat is Maru, the cat. I hope it's still alive. He's still alive. Okay, so this is a cat. And then it's a anaphor. So okay, so here's a passage. Maru is a male Scottish straight cat in Japan who has become popular on Youtube, his owner is rarely seen in the videos. Blah, blah, blah. Okay? So then, this phenomenon, where one linguistic expressions interpretation depends on another linguistic expression. This is called an anaphore. This is just another term. So here, just to be clear, Maru and his are co-reference, because they point to the same entity in the real world, and his is an anaphore. because the interpretation of his depends on the interpretation of something else in the passage. And so this phenomenon is called Anephra. The fact that linguistic expressions their interpretation depends on other linguistic expressions. And here Maru is called the antecedent. because it's something that happened that came before, and the interpretation of his depends on something that came before. There's also this term of Cataphore, and these are anaphores that point to cats. So, for example, when he's grumpy whiskers refuses to eat. Okay, so here, because he is a cat, whiskers is a cat. So this is called a cataphor. Yes. Is that like real? No, it's not. But the term is real, though. But yeah, I'm glad you caught me. So this I guess you have a module, for like a real world knowledge in your mind. So I'm happy about that. So actually, a cataphor is just a term where there's something that points to an antecedent that follows it. So this is actually a cataphor. It's just the reason is wrong. It's not because Whiskers is a cat. It's because whiskers comes later in the sentence. Okay, all right. But how was my deadpan delivery? I was. I'm working on that good, excellent. alright. So. Here are the types of referring expressions that you might encounter. So you can have, like a proper names or a kind of referring expression like Mcgill University points to something right. It points to either the abstract notion of this entity of a university, or maybe to the physical location whiskers is a name that points to like, maybe some cat. And then Montreal maybe points to the city. And so proper names they're all different kind. They're all these are referring expressions. This is one kind of referring expression. Pronouns are also referring expressions, a lot of the time like, if I say I that points to like the speaker. Right? You can also have possessives. But these are also referring expressions. It's just yeah. So there points to like a group of people. 3rd person noun phrases can be referring expressions so it can be indefinite like some water, a deer. This random dude. and or it can be definite, like the cat or the election. By the way, this is ambiguous in English, so this can either be a demonstrative which is like a which says that you're you're you're actually indicating, like a location relative to the speaker and the listener. Or it can just be like a indefinite article that this random dude is just introducing a new random dude to the discourse context. So it's it's ambiguous. And this notion of pointing to is different from the other notion of pointing to. I've been talking about so far. so I think we have at least 3 notions of pointing to discuss so far in this lecture. The 1st is the relation between a referring expression and its reference. The second is between 2 different mentions in the passage. and then here, when I say point to I I mean some relation between the speaker and the listener when you're presenting an entity. So they're just different way. These are all different from each other. So just, I always like to like motivate things, not just using English examples, but also using other languages that you may speak. There are other phenomena that appear at different levels of frequencies across languages. So one of these is one of this is called 0 Anafera, and this is interesting. So many languages allow you to omit pronouns in certain contexts. and they're often called pro drop languages. Okay, so pro over pronoun and then dropping them. And so this creates an interesting computational task, because that means that like you need to like. So in English, when when you have pronouns, and it's clear, you have to figure out what they point to. That could be a task. But in these languages you have an additional step before that which is to figure out when a pronoun has been dropped. In the 1st place. cause you need to figure that out before you then figure out like what they point to right? So yeah, does anyone speak Spanish here? Surprising? No. Okay. Cool or Italian or Russian, or many other languages? So in this 1st class of prodrop languages. You're allowed to drop the pronoun, but then there's usually morphology to indicate what the dropped pronoun was. So in this example from Spanish. I don't speak Spanish, but oh, that's also the example sentence, so it says, not speak Spanish. No hablo Espanol. So here you know that the pronoun that was dropped, was I? Because it's indicated by morphology on the verb. because aglo here is like 1st person singular for a speak. So Italian also works this way, and Russian and others. But, unfortunately for in terms of examples, English doesn't work this way, and French doesn't work this way. So if you only speak English and or French. You you'll just have to like trust me, I guess. But there are other languages where you drop even more, and you can't really tell from the morphology. So you just have to figure it out based on context. So I think Japanese is like on the more extreme scale of this. So here's sentence in Japanese. There's a sentence in Japanese, and it just means like somebody loves somebody. But in context, usually. I guess it's like I love you, because when you say that to somebody, then obviously based on context, you can interpret and figure out who the subject and objects are. But maybe there are other contexts where It might be different. Like, if you add a question marker like I still didn't know. So maybe you're asking, do you love me? Right? But then you don't have to say the I or the U, you just figure it out using context. Yeah. So Japanese is like this, Korean is like this. Chinese is like this to a lesser extent. Yeah. So you just need context. Yes, what about English? I know you said they don't really belong. But there could be sentences like. and can't do that right sometimes you don't use the eye or can't do like people would be able to interpret that as. yeah, yeah, that's a good point. I think this is what I was trying to get at with the last point here, which is that occasionally this happens in English, too. it's just much less common and much less systematized. But yeah, but we also use context to figure out what was dropped. Yeah. yeah. So the example that was given was like, Oh, I can't do that, or something like that, right? Or here I had attended a dope. Comp. 5, 50 class today. There's more there, there's more I won't be exhaustive in all the different reference and co-reference phenomena. But here's another cool one which is bridging reference. which is that you can refer to entities that are not directly introduced, but that you can figure out based on background knowledge. So I guess it's a similar issue to like the previous phenomenon. So here it's like, you figure out, based on context, what's happening. And here you're also using context and world knowledge to figure out what's happening. So the example is, I like my office. The windows are large, and the table is made of mahogany. Okay, here the bridging reference is between windows and table versus office. So the fact that we understand what an office usually looks like means that we can just say office. And then that implicitly introduces all of these other things like windows and tables, and maybe pens and pencils and chairs, and so forth. So then you can refer to them using a definite article, because usually definite articles is about things that already introducing the discourse. Right? So here, there's no explicit introduction. But we still say it's okay because of our expectations about the world. This one, the second example, is a bit trickier to understand. So here it's you should get a cactus they are easy to care for. So there's actually a bridging reference here as well. because in the 1st case, when you say you should get a cactus, it's introducing, like some cactus that is out there. So maybe it already exists in the world as a cactus that you can go to the store to buy. whereas in the second sentence, when you say they, you're talking about cactus as a class. So technically, that's not the same thing. Okay? So technically, they're not for reference, because the 1st instance is about a specific indefinite. not specific is about some cactus that's indefinite, that's out there. And the second one is about the class. But there's it's clear that the second one is pointing to the class of cactus just because of the way the conversation is flowing. Yes. specific. Sorry. But what what about, for example, in the 1st example, when this is used like to dramatic impact like. I like my office. The 2 chandeliers keep things bright, and it's like, not an expected object. It has dramatic effect. Still freezing room. Okay. So the question is, what if it's not really typical? It's I like my office. The 2 chandeliers are amazing. And then you don't usually have like chandeliers in offices. Yeah. So that's so, although that's slightly against the usual expectations, I think it still counts as bridging reference, and it's still a related phenomenon. So what happens when you say something like that? Is that the you're forcing the listener to accommodate to what you say, so that they can infer that in that office there were 2 chandeliers, because otherwise, like, the passage doesn't make any sense. So yeah, that's a good point. It's like, it's slightly different, because it goes slightly against expectations. But it's still fitting the expectation that offices have lighting fixtures. I guess. So. Yeah. alright. And then there can. And and just also to point out that not all pronouns are referential. So there's something called pleognastic pronouns which are common in English and French. which is where you say something like it is raining or snap out of it. So what is the it here? It's not referring to anything. I mean, you can make up something like it is referring to, like the sky, or whatever, or higher power, or a snap out of it. You're snapping out of what like out of like your. your your mental state, or something. But but usually these are analyzed as not being referential, and in English. I think in French, too, there are constructions where you can use to place focus or emphasis on certain parts of the sentence. You and they usually involve pronouns like it is comp. 5, 50, which is giving me headaches. and it's not clear if it is like referential like, does it refer to comp. 550, or is it just some like generic it? And so there are debates about that in linguistics. Okay. And then moving beyond nouns, things get a lot more difficult once he gets to events. because you can also talk about co-reference of events like here we have Hewlett Packard is negotiating to buy some company. it could use its own stock to finance the purchase. If the deal is completed, it would be HP's biggest acquisition, since it's bought compact. Whatever in 2,002. So here all of these verbs and also nouns. Oh, I guess only the 1st one is a verb, the rest are nouns. These are all referring to the same events of like a a company acquisition. whereas the second bot refers to a difference. Events. So event, co-reference, resolution is also an interesting task that people work on. but it's it's much trickier to define, because it turns out that you can There are lots of like unclear cases, of whether 2 events are actually the same event, even in terms of the analysis, not just in terms of the resolution. And so it's a tricky problem. Yeah. So how do you even define it? One definition is that they happen in the same time at the same place. Yeah. So that's 1 definition. But I won't talk more about this. I think this is just too much detail. So instead, I will focus on the a restricted kind of co-reference resolution for the rest of the lecture, which is phenomenal. And after our resolution. so just what does this mean? That those are some big words so pronominal just means. It relates to pronouns. And Anafra resolution means that you're determining the antecedents of pronouns. Okay? So okay, so the task is given a pronoun figure out what it points points to and previously in the text. And here are some basic algorithms for this using heuristics so that we can figure out what are the relevant linguistic cues and features that we might want to condition on. And I'll only introduce one of them. So Hobbes Algorithm, like the very early work from the 19 seventies. And then we can talk about machine learning approaches that try to implement the same intuition idea. But in a more statistical context. Yeah, with state of the art approaches to this task currently be like foundation wells or large banks. Wells? Fine, too. Okay? So the question is, would state of the art models with the like large language models are fine tuned. Yes, they will. but they they still. But okay, but let's look, look. So let's look back 1st to see what are some of the relevant cues and how they are incorporated or not in more recent systems. Okay, so let's go back to the example from before Maru is a male Scottish straight cat. His owner is rarely seen in the videos. Blah blah. So what are some of the relevant cues? So one relevant cue is number and gender. Okay, so 1st of all, what? What is the task? Okay? So what is pronounal and afro resolution. So here the pronoun that we might be interested in is his. His is a pronoun, and we have to figure out what it points to. So obviously, it points to Maru. But how do we? How do we know that? How do we get the system to know that? Okay, so, for example, why doesn't his point to Youtube. right? Or why doesn't his point to Japan? Well, one import, one relevant queue has to do with like number and gender. So, for example, in English, we have at least 2 to 3, maybe 3 grammatical genders. I'm not sure. So there's like masculine, feminine and like neutral. And maybe there are more and you don't typically refer to countries or to like Youtube with as a math with a masculine pronoun. They're not considered masculine entities. And so that's acute. Maru. Maybe like it's a proper name, and maybe it's like a Japanese name. So then it's hard for us to tell. But maybe, Maru, I don't know. Maybe it's more coded as being associated with like a masculine pronoun versus a feminine one. So that's 1 queue, and but then, at least we know that it matches because Maru is suggest that this is singular and his is also singular. So that's that's a match in terms of number. A second cue that can be useful is recency. Just because of the nature of how communication goes. We tend to refer to things multiple times. Like, if we're going to refer to something multiple times, we tend to do so in bursts, and they tend to all happen close to each other. So it's kind of. and you it would not be usual to like, refer to, present something and then not talk about it for a while, and then like refer to it again suddenly with his. It tends to be very recent. So recency is also a strong cue for predominal co-reference resolution. and finally, it turns out that the the syntactic role, like the syntactic information, is also useful in different ways, and you can use that to help figure out and resolve this problem, and that's a strong signal as well. So let me expand a little bit more on that. It turns out that there are certain kinds of distributions for different kinds of pronouns. for where they're allowed to occur syntactically. So, for example, if we have, the students taught themselves here themselves co-refers with the students. so themselves is the students, whereas, if you say the students taught them here, them cannot co-refer with the students. there has to be some other group of people. And so this is because of how reflexives work. So these are called reflexive pronouns, like when you ever have, like a self there a selves. and there, and there's a certain syntactic relation called C command, such that like, when you have reflexive pronouns, they have to be C. Commanded by their antecedents, whereas, like regular personal pronouns without the cells. cannot be bound in this way. And so there's this is formalized in a theory, in linguistics by Chomsky, called binding theory. And so, then, this is one example of how syntactic heuristics is useful for helping to resolve and rule out certain kinds of resolutions. But there are also other softer general tendencies about you tend to refer to things in like the subject position of the previous sentence, and so forth. Okay, so then, Hobbes algorithm from the seventies is a heuristic algorithm that puts together all of these cues and comes up with a method for co-reference resolution based on that. So this is a traversal algorithm where you do a tree traversal essentially over multiple trees. And what it requires is that it requires constituent parse trees of the sentences in the discourse. and it also requires a morphological analyzer for the number and gender that's expected of entities. And the algorithm itself is like quite complex, with quite a bit of detail at a high level. What it does is that it searches the current sentence where you find the pronoun right to left, starting at the pronoun to try to find an antecedent that matches in terms of number and gender using the syntax tree. and if no antecedent is found. then it searches the previous sentences left to right. In order to find a noun phrase that matches. Yeah. Why does the direction go left to right. Yeah. So the direction matters and right to left and left to right is a simplification. Really, it's about tree traversal. How the tree. The order in which nodes in the in the syntax tree are are searched. but the idea is that in the current sentence. you go right to left. To find like say the the subject of the sentence of the current sentence. But then, if you can't find something that matches. In previous sentences. I mentioned that there are these soft cues about how you tend to refer to the subject of the previous sentence. So that's a pattern that people have found. And so in English the subject comes before the object. and so then left to right works for English. So that's kind of the idea. So it's just based on how also, there's a tendency in language to place known information before new information. So like, there's some kind of topic, comment, structure and pronouns tend to refer to the the current topic because you don't when you so basically, when you have new information, and you have to introduce a new entity. Usually you have to say what the entity is, and so you use some kind of indefinite expression like it's a cake, or a pop quiz, or whatever. Right? So then, that's like a new entity, and you have to say what it is. Whereas if it's an old entity that has been shared across a longer span in the discourse, then that tends to be the topic. And so when you have a pronoun, it's more likely you're pointing to the topic than to like a new entity. It turns out. okay. So here's the algorithm in a bit more detail. I think this is from, like the second edition of the Drafsky textbook. It's not. You don't have to. It's not that useful to go through the details of it, but basically it sets up this way where you draw a syntax tree in a very particular style, with a particular style. and then it sets up so that it respects all the constraints from binding theory. So that if it's reflexive or not reflexive, certain things happen. Yeah. And it does this kind of traversal in this in this in order that we just described. But I I'm not gonna go through each of the steps in detail, because it's not. I think it doesn't really add much to our discussion. Okay, but we can like roughly go through and see how I get a flavor of how this algorithm might work. So here we have 3 sentences. Alice saw a beautiful cupcake in the patisserie window. She showed it to Bob, and she devoured it so how Hobbes algorithm would work. Oh, there's a chat message for real. Yeah. Cataphors are real. Okay? yeah. So Alice saw a beautiful cupcake in the petty screen window. She showed it to Bob. She devoured it. So how? How would this resolution work? Don't you guys know that cats rule the world? Okay, so this could be tricky. But let's see if I can do some kind of parse. Okay, I'll just do a like a very rough parse. That's probably it's not very syntactically correct, but here, like it would be devoured it. It is a noun phrase. and then she is like a noun now, like a noun phrase, and then, like it looks something like that right? And then showed it to Bob. It would be like. this is like roughly the structure. and then the Pacific city window. So a beautiful cupcake. Okay, here we have a ambiguity like does in the patisserie window attached to a beautiful cupcake, or does it attach to saw. So I'm just gonna make it a ternary node. I'm not sure if this is correct. Okay, so this is roughly the structure. And there are also a bunch of noun phrases here. So can you guys identify noun phrases by now, like Alice is a noun phrase, a beautiful cupcake is a noun phrase. a beautiful cupcake in the Patchesserie windows. A noun phrase the Patricia windows a noun phrase she and it and Bob, those are noun phrases. Okay. okay, so then the question is, what are we trying to resolve? So some of the pronouns would be like she. Okay, so let's do she first.st Okay? So in she. So the high level idea of Hobbes algorithm is, first, st you search within the current sentence right to left, but there's nothing to the left of she in the current sentence. So then you would search the next sentence left to right. and you would do some kind of like traversal, and then you would find Alice. and you would see that Alice and she matches in terms of number and gender. And so then in this way the algorithm would resolve, she to Alice. yeah, that's a great question. Do you take the 1st match or the best match? So with Hobbes algorithm, you take the 1st match because they tried to design it so that you encounter the best match first.st But it's obviously not perfect. That's what they attempt. Another one would be, say another pronoun would be it. So. If you go through the algorithm, it will 1st propose she as like a potential antecedents. But then she and it obviously don't match in gender, so would be rejected as a candidate. and afterwards you would go to the previous sentence, and you would search. and it's so. It's left to right in a tree traversal sense. So we'll propose, Alice. But Alice also doesn't match in terms of gender. So then the next noun phrase that we propose would be a beautiful cupcake in the patisserie window. and that one would match its in number and gender. And so then it ends up, being resolved to that node which corresponds to a beautiful cupcake in the patisserie window. Yeah. Understand why it's gonna resolve the whole thing when we have 2 noun phrases that we have a beautiful cupcake and the magistrate window. So why does it choose the whole? Yeah. So the question is, why does it choose the whole noun phrase, and not just a beautiful cupcake, or just the Pit Street window. So it's because I simplified, I said, left to right. But it's like really a a tree traversal. That's a breadth. First, st I guess tree traversal. So so then it would encounter the the noun phrase node first.st Oh, I think I put the arrow with with the wrong stopping point, as I hear. So there's no decomposition. It's done. So it then, according to this algorithm, resolves to a beautiful cupcake in the pedestry window. There. Yeah, there's no decomposition. They point to the it's just from the perspective of, you know, like a machine. Since a beautiful cupcake is a noun phrase, but it's true, and there was a noun phrase, which one is it referring to like? Obviously to me? I know that it's a beautiful cupcake. but you know which exactly is Oh, I think I may. Let's see. So I think I made a miss, did I make a mistake? So here, yeah. Okay. So here there's an there's an np node here. I think maybe my, I wasn't super clear in my parse. So let me try to like fix this. Okay, let me try to make it a bit clearer. Yeah, I think I should really. What a beautiful cupcake. Yeah, I could put it like this. And then so if this was the parse, then it would work. Yeah. So then it would encounter this noun phrase first.st So with this algorithm, then, it would not ever propose a beautiful cupcake or the patisserie window on their own. So then, since it encounters the 1st noun phrase that it does that matches a number and gender. It's done. Yeah. But then you could have a sentence where it's basically one word. And then, like a huge noun phrase. proceedings that could lead to problems later on. Because it just collects basically everything in the second. So yeah, I think what you're suggesting is that there could be some cases where this heuristic fails, and there certainly are. But this is just like the to illustrate the some of how some of those queues are integrated into a simple algorithm. And then, later on, we'll look at machine learning algorithms that might be able to do a better job and resolution. And actually, the other examples are similar. So the next pronoun is she. and it does the same thing. There's nothing in the current sentence before it. So it looks at the previous sentence, and the 1st noun phrase it encounters, which matches is the other. She so then it'll this, she will point to that she which will point to Alice. and finally, we have its and it's the same thing. Oh. in the current sentence, there's nothing. and well, it'll propose she, but it doesn't match. Then they'll propose this, she in the second sentence, and it doesn't match as well. And then the next noun phrase it encounters. Is it so? And it matches it in number and gender. So then this it will point to that. And so for this simple example, this approach works. Oops. Okay? Yes. Question what would the average accuracy of this be? It would not be that great, I think. So first, st you have to define the evaluation metric, and you can do that. There are different ways to do that. But you can expect, like the proportion of times to get this rate to be like maybe 60%, 50, 60%. But this is my rough estimate. People have done actual studies. And you can look up numbers. Okay. alright. So of course, then. these days, people tend to solve co-reference resolution using some statistical approach with a machine learning method. And one common way to decompose the task is to break it down into 2 subproblems. and then solve each of those problems separately before recombining the outputs of each of those modules. So, for example, once a task is to do mention detection, which is just to figure out which spans of text are mentions like are referring expressions, and which are anaphoric. And this could be a separate step, or it could be like one step within an integrated end to end system. And then the second step is to actually create those links to do the actual reference focal reference resolution. So now that we're getting towards the end of the course. I think you should start to have some intuitions about how you might cast this as a machine learning problem and solve them. So any ideas for how you might solve these set these up as like machine learning tasks that you could like train a system to solve. For example, with mention detection. How might you like cast that as a machine learning problem and solve it? So the task of the so, for example, let me just clarify what mentioned detection is in case it's not clear. So here it would be to find all the mentions. So Alice is a mention, a beautiful cupcake in the pit. 3 windows I mentioned. Maybe a beautiful cupcake is also mentioned, and the pit 3 windows a mention she is a mention. It is a mention Bob is mentioned. She is a mention. It is a mention. Okay? So those are the mentions. So any idea how you might do that? Yes, yes, it could be a fine-tuning approach. Can you be more specific? Or you can ask the input sensitive input and then you can add maybe an extra layer on the output. I'm not so sure how to design extra there, but maybe you could like it would output a probability there or something being mentioned or not. Then we could give it a data set where you know mentioned. I've mentioned them find the ways to get better. Yes, so you could. Did did people hear that? So it's like adding an extra layer on a neural network? And that layer has to output a probability? What's that probability of this being a mention. And you can fine tune on a labeled data set. Yeah, that's reasonable. Yeah. 2 ways. We learn with hearse patterns. Okay, I think that would mean that it would have to occur in the same like sentence. And then the other one would be like a co-reference matrix. And then you can go from there and Pmi scoring and all that to see, and then have more embedding stuff. And then course around that like a bigger. Oh, I'm wondering. Okay, so you're mentioning hearse patterns and some kind of co-reference matrix. Separate. Okay? Oh, co-occurrence matrix. Okay? Okay? I think those could be relevant cues. I think I'm not sure exactly how to cast mention detection, as those so hearst patterns are usually about detecting relations between 2 noun phrases. But here we are trying to figure out which spans of text are mentions in the 1st place. But aren't you trying to get like? Which is a mention, and which one is a referring expression. So instead of like hyper and hypo, they could be them soon. I see. So you're saying that Hearst patterns might give you like patterns that help you figure out co-reference links. Yeah, I think that's that makes sense. I think that would be more for the whole problem. So it would be, it would not be for mentioned detection, it might be for the second step. Okay, cool. Yes. Is it possible to define a loss function specific to those things like immunization for reference. Is that possible? Yeah. yes. Is it possible to define a loss function for these things? Yes, absolutely. In fact, you have to, in order to be able to train some neural network to get better at this task. So the so the question is like, how will you define it? Yeah. Yes. But would any sequence? Tagging models? Yes, that's great. So, yes, so would any sequence modeling framework work for this task. Yes, because if you think about it, you can cast. If you ignore the hierarchical structure of mentions. If you just cast it as like a chunking problem. Then it becomes a lot like ner in that you're chunking the words in your text into chunks that correspond to mentions. Yes, so you could do like Bio tagging scheme and then run any sequence model train on some labeled data to do mention detection. Yeah, yes, 1, 2. Yep. I'm sorry, really work to use like a generative model, like a decoder where the input would be sequenced and the output would be like it generates all dimensions and stops. Yes, so the in fact. So your your suggestion is like, just get a generative Llm. To like. Give it a sentence and tell it to spit out all the mentions. In fact, that's something that people have done in the past year. So yeah, too bad you didn't think of that last year. You could have written a paper on it. Yeah. like, just the bootstrapping method that we learned with the supervised algorithm, I know you generate a lot of data. Yeah, which you could put it, you know, with like a label, and then run the bootstrapping. Yeah, could you do a bootstrapping based approach? I can imagine that you could do do it that way. Yeah. yeah. cool. Great. So so you can see that like, I'm I'm glad to get all these responses, because you can see that, like the tools that we've discussed, they can apply to a new setting. And hopefully, now you're beginning to build some intuitions about which approaches to try when encountering a new problem in Nlp. And then for the co-reference resolution step. You can imagine going through a similar exercise. Maybe you have 2. okay. So now it's okay. So after mentioned detection, you have a passage. You've broken it down into a sequence of mentions. And then the co-reference resolution step could be to predict for which pairs of mentions. For so for a given pair of mentions whether they're likely to be correctant or not. Okay? And then you can pass in features that you think might be relevance. You can pass in like your just the words in the context. So you can pass in the predicted gender, a number or anything else. And the and the syntactic structure surrounding those mentions and so forth. Okay, great. So basically, the machine learning literature is implementing that. Okay, it's like, there have been a bunch of people who've tried different approaches and depending on like the time era. They tried whatever was available to them at that time in the machine learning landscape of the of the era. So, for example, in the early 2 thousands soon at all to find some features for noun phrase, co-reference, resolution. And and and then it's kind of like what you might expect based on our discussions. Okay? So some of the features are like, Let's see. And so so it's like, some of them is like, is this a pronoun or not. Okay, so yes or no. Some of them are like, after discarding the determiners, the string denoting does the string match. So basically this, since this is for noun phrases in general, and not just pronouns. If you have, like 2 nouns that have, like the same words that use the same words. Then there, it's pretty likely that they're co-reference. There's like the predicted number and gender. Are they both proper nouns? There's some syntactic constructions. There's something called positives, or whatever. They also attempt to use the structure of Wordnet, which we discussed, we discussed. and, like the they used, they encoded recency as well. They looked at the distance in terms of the number of sentences between them. So these are the kinds of things that you might expect. So if you have dimensions. Then you can run this for reference. Resolution. And they get like some reasonable score. They get like around 60 to 70 in terms of f, 1 more recently, in 2013, Durett and Klein trained a initial neural model or sorry, a log linear model, but they have, like 3 million features, and they use word level features, and they use some simple recency, heuristics and syntax. So that work actually found that the predicted gender and number features worked very well. For in their model. So a lot of the heavy lifting is done by the predictor of number and gender. and then moving on to the neural approaches. In 2017, Lee et Al. Proposed this end-to-end system and that implements the ideas that you guys had as well. So they basically learn train 2 functions. So one function scores whether a certain span, so a span here is defined as like a sequence of contiguous words. So whether a certain span is a mention or not, and they have, like one sub network in their neural network structure that predicts that. And then they have another function, another sub network they train that checks, whether span I and span J. Co-refer. So whether span J is the antecedent of span I. So this could become very computationally expensive, because if you think about it so if you have like if you have a sequence of n words. how many possible spans are there, there's a quadratic number of possible spans, right? Because you have to. So a span. You have to pick in a starting word position, and you have to pick an ending word position. And so that means there's a quadratic number of them. So just the fact that of that makes that even just computing the 1st function exhaustively is very expensive. but, like the the saving grace here is that most mentions are short, right? So you can make some assumptions and and only compute that function, for, like, say, spans of up to a certain size. or where maybe you do some initial syntactic parsing, and you restrict possible spans to, according to the syntax tree, or something like that. And so then you can have some heuristics to prune some of these options. So you don't have to compute everything. And similarly, you there, once you have this. Okay? So if there are quadratic number of spans, then the possible number of span pairs is like to the power of 4, I guess, because it's n squared times. N squared. And so then again, you have to make some assumptions. So you only consider a small number of possible pairs of spans as being potentially co-reference. Yeah, you mentioned 2 sub networks almost as if, like, there are 2 parts of the network with 2 different outputs. And I'm wondering if they're like trained separately with separate loss function, or if they're unified into like one training process with one. Right? Okay, so the question is, are these sub networks? Are they trained separately with different loss functions? Or are they all unified? So the way that is set up in this model. It's like there's a shared set of parameters that encode some sequence. And then they have basically different output heads. So there's 1 kind of output head which is for mention, scoring. So for here there are different possible mentions, like General electric for this 1st head for for this 1st outputs and then electric, said, these, this other outputs, and so forth. and then each of those you can score that, and then you can try. And it. It gives you a score, for whether it's a mention or not, and you can do that, do supervised learning on this. And so there's a loss function there, and it influences the the the parameters of the encoder. And this is slightly older work. So they use an Lstm encoder and then the co-reference resolution part. They they uses some some shared parameters. So then here is jointly trained, but it's the at the output step. It's like there's a separate output network for the co-reference score. So then they have the span representations which is like shared. So up to here it's shared up to the span representation. And then after that, they're the sub networks. They just they head towards different loss function computing computations. So then, this one goes to like the objective for the mention scoring. And then here it goes to this separate thing which is like scoring the co-reference score. So this is how this network works. And this gets like a much better performance. So this ete model is quite highly performing so more recently than the more recent developments, as you would expect is to do something similar, but with like a transformer style, with like a pre trained large language model with like transformers. And here, in the recent literature there are 2 general kinds of models. The 1st one essentially follows in the footsteps of ete. Basically, if you replace, like the Lstm part with like a transfer pre trained transformer. Then that's 1 kind of model, and those are the encoder models. Those are encoder models because they encode the sequence, and then and then it frames like the the other, the steps in the co-reference resolution. As like classification problems. So it's a classification to decide. Is this a mention, and to decide if these pairs of mentions are co-referent or not so intuitively at a high level, it's the same idea. Then the second class of new models that have been proposed is what was like mentioned earlier. So these are decoder models that frames co-reference resolution as a sequence to sequence task. So, okay, this was supposed to come later. So okay, so just as a comparison. So one of my Phd students, Ian Parada compared encoder and decoder models. and we find that encoder models tend to be more efficient and perform better. If if you control for the size of the large language model that you use, like the pre-trained language model that you use essentially. And if you do like the proper parameter. optimization, hyperparameter optimization of all that. But let's talk about the decoder models as well, because I think if they still have premise, they're interesting. So here's a model from last year like Link, append. Okay? So essentially, what they do is they they implement the proposal that we had from the class earlier, which is, you pass it a passage and then extracts a bunch of mentions, and it also extracts what these mentions point to previously in the context. and then the possible actions that it predicts are either a link or an append, or like, or we're done processing the sentence. So what does that mean? Okay, so let's take a look at the 1st action, which is append. Okay? And let's take a look at the overall setup. So the overall setup is like. 1st you put in a sentence and then maybe the model predicts that here there's nothing. I don't see anything that Co refers to anything else previously. So it predicts shift, which means, let's process the next sentence. and then you get the next sentence. and then here you already start to create a cluster. So here it says that this I at token position 17 co-refers with this I at position at position 2. And so this is actually a link action. But anyway, this creates a cluster. And so then here with the 3rd sentence. then you pass in this updated context with 3 sentences. sorry with 2 sentences. Blah, blah, blah. yeah, with 3 sentences. So now you pass in these 3 sentences, and you ask the model to extract all the clusters, the new clusters that it finds, and and so forth. So in the in its prediction. It predicts that you here of Speaker B. Co. Refers with the cluster with index, one which is, like the I from Speaker A, and so this append action is what you extract from that 1st initial prediction. Next, the next 2 predictions by the model are link actions which create new clusters by clumping 2 spans together. So then the model thinks that the apartment co-refers with your house, and it's a new cluster that it creates. So that's a link. And then, in the 3rd case, we have, like the one right next to the apartment which co-refers with that fresh French restaurant by your house, and it creates, and it uses another link action to create another new cluster. and then it predicts the end of the sentence. So after processing this. then, you, you again pass in you, you update your your what you've created so far in your in your context. And now you have like 3 clusters. Right? You have the I cluster and the U. Cluster with my cluster number one cluster number 2 for your house and the apartment and cluster number 3 for that fresh French restaurant by your house versus the one right next to the apartment. and you incrementally process this until you reach the end of the discourse. So this is how they set up the set it up as a sequence to sequence task. Yeah. Oh, and shift means you're done processing the sentence all right. So that pretty much gets us to the current state of the art in core reference resolution. Any questions? Yeah, it reminded me of. I think our 1st reading assignment. We saw a model, that kind of predicted actions to do name and entity recognition with exact data structures. So I'm wondering is that the same as like using a decoder to to generate? Are they 2 different approaches? Yeah, that's a great point. So how is this related to some of the previous work. We've seen the class about predicting like some actions for like parsing. And it's yeah. It's inspired by the same idea. So it is. Yeah, they directly link this to that work, that type of work as well. So they think of this. You can think of this as something like a transition based parser where you're predicting actions which create new substructures in the inputs. And so then the their particular way of creating this creating substructure is to either create a new cluster with link. or to add something new into a pre-existing cluster with append. And would it be done with the decoder? Yeah, so this would be done with a decoder. So so here the input is, the encoder part. You pass it in, and that's your prompt. And then here the decoder it outputs the predictions. Yeah. yeah. And so the numbers here are higher in modern per reference resolution systems. So you can look at some of these papers, I would say, like, maybe it's like again, I didn't define the accuracy, the evaluation metric formally, but they're usually in like the eighties, or like around 90 or something like that. Alright, that's it for this class. unless you have more questions. Well.
