[
    "Jackie Cheung, Professor: , Hi! we're people online can hear us. Yes, settings up all . We're going to talk about natural language generation. Here is the plan for today. we are going to look at how natural language generation has been approached with different methodologies and different approaches in the literature in the past. And we are going to look at,  techniques that are not currently, , the trendiest or the most popular. but it's good to learn about them to expand your toolkit. because  my goal in this course is that you don't go away thinking that Nlp is just about hacking things with  prompts and Llms, that would be  really sad. instead, we're going to look at a broad range of approaches.",
    "And we're going to look at rule-based systems. We're going to look at shared machine learning systems. And also we're going to look at an approach to thinking about problems which  used to be really popular, and it still has its merits. And we can talk about that which is a more declarative approach to optimization. ,  then, here's the outline. one way that we can categorize different Nlg approaches and  the field, is to think about the  generation you're doing , what is the format of the source material from which you're doing generation. And  I'm going to divide that into something I call data to text generation versus text to text generation. And we'll look at each of those. We were looking at automatic summarization focusing on extractive summarization. And we contrasted extractive summarization, which is where you take snippets of the source text and concatenate them together versus abstractive summarization, which is where you compose novel text not found in the source.",
    "And  we focus on extraction because it was easier to think about. And you don't have to do. We can focus on these interesting issues to do with modeling, content, and modeling the relationship of words with respect to each other, and that how that helps us inform what is important. But then, if we want to do abstraction, then we have to do. Natural language generation and abstraction has many use cases. , one key one is that it lets you aggregate information from multiple inputs. again, think about the case of, say, product reviews. you have a thousand product reviews on a popular product on Amazon. and it doesn't really make sense, it makes less sense to do extraction. Sure, you can extract specific top reviews and put those comments together.",
    "But if you want to describe the overall distribution of opinions, , of that product, and synthesize and the thoughts that people have on specific aspects, then you're going to have to do some  abstraction and abstractive summarization. And  that's why we need to talk about natural language generation overall. We can also compare and contrast Nlu and Nlg. Again,  this was  a slide. This is  a similar to a slide from the very 1st lecture. in the 1st lecture we define natural language understanding where the issue is, you have ambiguity, and you want to do disambiguation. And  the  we know that  sometimes. there's under specification, and that,  the meaning representation should be under specified with respect to multiple possible interpretations of the input. there's all that good stuff. whereas in natural language generation the concerns are a bit different, because it's about selecting appropriate content which we covered last class, and also selecting the appropriate form in which to express that content.",
    "then we can divide up Nlg into data to text versus text to text, depending on the source, the  input. one  natural language generation which is always available and always there and  requires very minimal amounts of Nlp is just canned text. Hey, if you play a video game up until very recent times. Almost all of the text is scripted ? You reach a certain point in the game, and then a message pops up, and then and then you have , and there you go. That's that's natural language generation, ? It's it's not very interesting from our point of view, but it is a kind  natural language generation. But then we can start to get into use cases that are  a little bit more flexible and more adaptive. Here is another one here I searched up the driving directions from Mcgill to Mila. The Research Institute in the little Italy neighborhood.",
    "and there's natural language generation here as . you don't think about it as such, but it's there. because, , I'll take this street and 2 words, or until Pine Avenue, and then follow Pine Avenue until some other place, and  on, and  forth. And if you use your phone's GPS system, then this is also  it will  spit out. It will say, these driving directions to you as you reach the appropriate location. This is also a type of natural language generation. if you think about it, how this works is that there are templates that are formulaic patterns that you fill in and you get the to get the final sentence ? , , here it's , take. And then there's a slot here,  take and then street name to street name. And then  you have follow street name to street name.",
    "and  at some point, it'll say, turn left at street, name, or turn  at street name. this is very temp, templatic and formulaic. And arguably, that's a good thing. , this is , I would say that,  for something  a GPS system or some other very routine formulaic things. You do not want creativity. You do not want diversity. you want things that are highly structured and expected of a certain form. ,  that helps us with,  our mental processing. And your GPS system  is telling you. Oh, here's a joke, or here's a poem for you to figure out the directions that you need to take  that does.",
    "That doesn't make any sense ? , depending on the application and depending on the usage, you might just want to handwrite some rules and handwrite these templates and then fill those templates in with the appropriate information. And then there you go. , if you go into industry, here are more stories from my students. my students, my grad students are wonderful. And they do all this cool work. And then sometimes, I teach them unpopular things. And they're , why are we learning this? And then I have one student who, when he was here, he was very pro neural networks, deep learning, all that stuff, all the old work is useless. And then he went into industry, and then he found that a lot of the work is about  writing rules and writing out templates and try to fix things at the last step  that they can release a product.",
    "And I got the last laugh. he came back to me after a few years. And it was , Oh, , a lot of industry. Nlp is still based on rule writing rules and  thinking about grammars and stuff. Is that gonna be true in the future? I can't make any predictions 5 or 10 years from . But at least   you still need to know this stuff you still need to know,  about templates and rules, and  forth. And then  just a bit of terminology for you don't have to remember this, , but  it might help you to if I say it to you at least once. in terms of the templates. the abstract  thing that you need to fill in.",
    "when I say , take street name to street, name the street name that's called a slot. usually in a template, you have these slots where you need to put stuff in the slot. and then, appropriately, the thing you put in is called the slot filler. in this example, if the template, if the overall structure of the template is a take the Slot Street name to the Slot Street name. The slot fillers are Rue University and Avenue des Penaux. , but ,  we're all here for the more, . Interesting, exciting kinds of Nlg. where you need to do you might want to think at a more high level about all of the steps in the architecture of an Nlg system, and then think about which ones you want to architect more, and which ones . you implement with some machine learning system or a neural network or something or a large language model. we can talk at a high level about these steps.",
    "And and , and then in practice, how you  design it for a particular system. You might , some of these steps might be combined together as part of some module, and some of them might be separated out, depending on the specific ways. You decide to engineer your system  abstractly. Abstractly speaking, then, here are the steps in a potential energy system. You need to do content selection. You need to do document structuring. And then there's something called micro planning. And finally, something called surface realization. ,  content, selection is about deciding what to say. And if you want to take a very principled approach to this, then you should think about what is the communicative goal of the energy system.",
    "and what is the relevant knowledge about the world that will inform how we do content selection. we talked quite a bit about this last class, ? this step is often application specific. last class, we talked about multi document summarization. And how do we approach content selection there? , we talked about how there might just be some topics that people find inherently interesting and important, but we also talked about signals of importance in text. I mentioned at least 3 possible sources of importance in Texas. Anyone remember those, any one of them? I'll give you one of them. One of them was centrality,  repetition of a word or concept within source documents.",
    "But but  I mentioned at least 2 other ones. we were talking about  news summarization and looking at the opening paragraphs. And that's the location is a specific instantiation of this broader theme of discourse structure. using the discourse structure of a document to find out where the important things are. And what was the last thing we talked about? ,  that goes to show that content selection and determining what's important content. A lot of that really depends on the specific application. And then some of the general trends in the context of summarization still apply to this step. this is different from  using the discourse structure to find what's important. It's more , how do you structure the outputs of the natural language generation system  that it's the most effective at accomplishing the communicative goal that you have in mind.",
    "this is  going in the reverse in the opposite direction. in order to decide how to structure the contents of the output. Then  to consider some of these factors  the importance of the concepts, because this is the OP. There's  the same argument in the opposite direction, just as  in naturally occurring text. important information tends to be found in certain locations. When you're doing generation, you want to respect those. You may want to respect those conventions and formats,  that other people reading that document would be able to do the same thing. and then you might want to generate discourse relations and think about the coherence of the passage that you're generating overall. there's some work at in at the intersection of, say,  psychology, of reading and Nlp and computer science that looks into things  this. one specific instance of this is something called argumentation theory, which provides some guidelines on how to arrange information.",
    "some of this you also find in  writing advice,  for students. , , you can talk about, or you can structure your documents  that you present the main claims first, st and then you can try to arrange and discuss the supporting evidence, and then present and debate opposing evidence, and  on, and  forth. there are some guidelines here for that as  that you can try to make use of. The 3rd step is to select the specific lexical items that you might want to use to generate the final output. Suppose , you have a data to text generation setting where the input is say, the results of some weather forecasting system here are represented in some  a made up a formal. a structure  there may be tomorrow. There's gonna be a blizzard with a high of minus 5 and a low of minus 10 and 30 kilometer per hour winds, and the location is Montreal. , you have to select the specific words in the language you're trying to generate this into, to represent those concepts. And then , as another part of micro planning is to decide how all of these words fit together in clauses and sentences, and this is called sentence planning or aggregation. , the 1st sentence, in your output might present the location and time that the weather forecast pertains.",
    "and then the second Mike presents the details of the forecasts also. Part of micro planning is to generate referring expressions. remember, this term comes from. We talked about this last week when we talked about co-reference resolution. again,  all of those things we talked about on the side of a natural language understanding. we have to do the opposite, the reverse when we're doing natural language generation. if you have an entity. Then,  the Prime Minister, then depending on   the 1st time you introduce the entity in your document, you present the full name or something. this might be what you find on Wikipedia or something. And then, in other context,  you just need the 1st and last name, and in other contacts you might want to refer to that entity with their title, etc.",
    "And then finally, in later mentions,  it's  the pronoun. and then the last step in this abstract description of an Nlg system would be surface realization, which is to fully convert all of those the specified discourse plans, and the outputs and decisions of the micro planner into the output form which takes the form of these sentences that you see or you can run a text to speech or something. And you have, , audio output, etc, etc. there are different possible levels of input specifications. it could be some highly detailed semantic structure where all of these decisions are already made,  with lexical items and tense and aspect and mood of the verbs and referring expressions. All the stuff we mentioned. or it could be shallower in that the inputs to the surface realization step could be  a dependency tree. But again, these all tend to be contact, specific and application specific. the thing with the Nlg with the literature on Nlg is that up until large language models the field was very diverse and not unified, because the in the form of the input was  diverse. Some people working on Nlg were interested in  generation from structured databases, but each structured database has a different format.",
    "They have all different sorts of fields and different types of data and values. and then others define Nlg by as generation from some structured linguistic representation of the types that we've seen in class. with from parse trees of some kind, or from some semantically annotated structure meaning representation. And there's no uniformity there and then for the text to text people working on summarization and translation, the input is itself text. the input types were all different from each other, all different. And  the field was not unified, and that made it  difficult to work in this area for a long time. nevertheless, there have been a few standard tools and task definitions in Nlg. one of them is called referring expression generation, which is you come up with  a scene  you can imagine,  coming up with,  a picture with a bunch of different objects, with different properties. And then the task is to  generate a linguistic expression that picks out a subset of those objects. Suppose our scene was just what you see in the classroom  , and the task is to generate that thing.",
    ", you have various options, you can just call it. you can call it the blackboard. But then there are multiple blackboards in the room,   that's not a good choice. You could call it  the freestanding blackboard, or the blackboard with wheels or the blackboard on the left. Or if you say,  the green thing, that's also not very discriminative. , and then surface realization. Then, there's some standardization there. there are some tasks about generation from dependency parses to , say, output sentences or something. But  one from the early literature called FUF. And  this goes to show the state of the field back, then.",
    "which is they assume a highly detailed semantic structure. and then they apply a cascade of deterministic rules to convert that structure into a string. this type of structure you see here on the  is called an attribute value matrix. If you twist your mind a bit. This is  a tree structure. the top of the tree is  on the left, the outside. and then the tree has,  a tight edges,  one called cat, one called process one called partick here, and then the stuff on the  of that. And  every time you have,  another square bracket pair, that's   a subtree. And and this is  a representation of the semantics of a sentence to be generated. The cat here stands for category.",
    ", and on the outside. Here this is meant to be a clause, and then within the on the inside there are,  smaller and smaller units with their own category. And then there's  a category, for  noun phrase, and  forth. and the output sentence that this structure is meant to correspond with is she hands the draft to the editor. then the idea behind this generation task is that you assume that, , you're given this type of highly detailed semantic structure. and you want to generate the output sentence. in that system at a high level. What it does is, it maps it 1st maps these thematic structures or semantic roles into syntactic roles. a semantic rule will be something  this is the agent of this predicate. and then the syntactic role would be.",
    "This is this should be expressed as the subject in the sentence. and then that handles syntactic alternations , are you using the active form or the passive form, or some dative alternation? They're usually under specified . for all of the missing information, you fill in some default features with agreement, features, and  forth. and then you make sure that the subject and the verb agree in number, because, remember, we have to do that in English. and then it handles closed class words , if you have this thing  a personal pronoun, that's  a feminine gender in the 3rd person. Singular, then it should be a she. and then you order the components with respect to each other, fill in inflections. Blah, blah, linearize the tree into the final string. hopefully, you get the idea.",
    "that you start off with this complex structure, and then through a series of deterministic transformations, you gradually make decisions to . figure out to turn the semantic representation into some  syntactic form which allows you to then convert that syntactic form with the syntax tree into  a linear sequence of tokens. And each of these steps involves rules. it was quite tricky to  create a system  this, because you have to hand. Engineer all of these rules, and you have to figure out the order in which they apply and check it against these structures. And you have to be an expert on the input structure. the advantage of this type of system is that you have a lot of control over what happens. And it's all very precise. and if you're able to understand the whole process, you can understand exactly what's going on and what's happening and intervene that way. But of course there are Major Downsides, and that's why it's not  popular.",
    "You have to be an expert on this meeting representation and on the rules of the language that you're engineering this for. it's easy to make a mistake in engineering this. And also you have to  , how realistic is it to assume that you  have a semantic structure  this meaning representation  this in the application that you're concerned with. that's that's a major reason why this approach did not take off. It's it's not  easy to get these structures. It doesn't make sense  it's a lot of work even to convert whatever input you happen to have into this structure. at the opposite end of the spectrum, I would say, would be something  a neural Nlg model. And  here you just train a conditional language model. this is a lot more familiar to us in,  the recent literature. this could be a sequence to sequence model.",
    ",  you have your source text , if you're doing summarization or translation. and then you have all of the tokens you've generated  far. and then you use that to predict the  token and  around 10 years ago this was implemented, as, say, an Lstm model that's ,  you initialize it with some initial word embeddings. But then it's fine tuned on the specific problem and task you're interested in. But then, these days it's  a pre-trained language model with, based on a transformer architecture. And your source text might also contain instructions  prompts, and then you have all the tokens you generated  far, and you continue to generate. This is  a super silly question. Oh, regenerative models that my understanding was that they join learned a joint probability distribution. But then here we're learning a conditional probability distribution over generating tokens. in the course we've defined a generative model as a model that gives you a joint probability distribution over everything of interest, over  your inputs and your labels.",
    "And then here we're talking about a conditional language model, where it looks  you have a conditional probability distribution. And how do you reconcile these 2. , there, that's an excellent question. There are 2 ways you can reconcile it. One way is that to say that there are 2 different senses of the word generative. There's 1 sense which is  purely about the type of machine learning model. And one sense which is about, do you  generate some language output,  you can reconcile it that way by not reconciling it. the second way of reconciling it is that if you have a model that can generate some outputs. Usually it does turn out that the you can write it as a in the form of a generative model with the joint distribution. sometimes it's just in the model itself. You can just rewrite it and have that form.",
    "and sometimes you have to do a little bit of work, because it could be that the fact that it can generate output means that you can derive the implicit, generative, joint, generative model that is implied by that generation process. Also the fact that it's written here as a conditional , it's just how you use the model  the, it's just how you. if you have the joint probability distribution. you can always , write out this conditional form from the joint distribution. it's   this alone isn't enough to tell you whether the model is generative or not generative. And that's a good question. ,  let's also talk a little bit about. what are the positives and negatives of things just  thinking about things this way. the 2 approaches we've seen  far is one is highly structured, detailed, rule-based. and all of those steps in this in the Nlg architecture of  content selection, and then  not content selection.",
    "But after content selection  with  the document structuring and micro planning surface realization. They're all clearly separated step and distinct steps in this rule, based approach. In this second approach of  a neural nlg. everything just gets stuck into this conditional language model ? There's no separate modeling of each of those steps, at least in the most extreme form of that. You just assume that the pre trained language model, , can figure all of that out. what are some pros and cons of the second approach? , I see a con that  this can generate the non automatically. It's the type of redirects in terms of. that's that's that's a good point.",
    "there's no guarantee that it'll generate something that's either semantically coherent or syntactically  formed. , it's just empirical that it happens to often work  for many of the tasks that we try. it be air propagation, if there's  one. If there's 1 poorly generated token, will it affect future? Yes, , that's a -known problem as . This model is very accessible. you can do it with a lot of data. that's a positive which is with the neural approach is very accessible. , everyone can just use a pre trained language model these days,  fine tuning. It is not  accessible, because, .",
    "you  need compute resources and all that. But assuming you have that, then, at least from a technical perspective, it's more accessible because you don't really need to know the details of how the rule based structure works. You can just feed it some data and , get it to run and adapt. it may be different levels of accessibility requiring different things. , you don't need to handcraft anything. That's a big thing, ? This one is  arguable in both directions. But another difference between the 2 is that in the rule based formulation it's in the ideal case is task independent. Once you have a set of rules to translate the meaning representation to the language outputs, then it should work regardless of what generation task you are pursuing. But this is cheating a bit, because then there's a step of translating from the task specific inputs to the meaning representation.",
    "And that part is doesn't come for free . But if you ignore that, then it's a task independent where it was the neural energy approach. If you're doing any  fine tuning or adaptation. Then you have to do that for every task. then you can also explore something in between the 2 extremes you can. You can have some  neural data to text generation as . You decide which steps of the analogy pipeline should be in their own modules with a separate planning step, . and then come up with a way to embed the input data structures into a format that can be ingested by the neural model. and then add mechanisms in the decoder that are appropriate for that specific generation task  a an attention or copy mechanism, or things  that, , fine tuning, and or  few shot learning whatever. And  this can you can have a combination approach as .",
    ",  let's take a look at that. , , here, let's consider the task. This is a data to text generation task. which is a generation of Wikipedia biographies. the task is to generate the 1st sentence of the Wikipedia biography article from its info box. yes, this is artificial and contrived. The idea here is just to , illustrate the point that the input here is a structured formulation of something. And then the output is a natural language sentence. And  then what you could do is you could formulate the inputs. th, this, this is just  a pretty ui.",
    "But this is really  something from  a database, ? It's formatted in a pretty way. But then you can reformat into reformat, that input into a sequence of tokens that you pass into a sequence to sequence model. And  in this work, this is how they chose to do it. each word is associated with a word embedding and an embedding. That depends on the word's presence in the info box table. this is called an info box on the left here. and  then it's represented in this way,  the field, name the index from the start, and then the index from the end. if this is your input table it gets formulated, reformatted in this way, ,  it's , . here it's  name 1, 2.  name is the field name, because the field is here.",
    "and then 1, 2 is  the token position, and  forth or we can look at  18 April 1352. And then the span  it's it goes from  a 1, 3 and  forth. And then the output candidates is that you generate something similar. And then you can then apply neuro language model training to this as a sequence of sequence task and generate the outputs. these  this work was  already, a bit old is already a bit old,  8 years ago these days you could even do something even more lightweight, and you can just  pass in the entire . You can really just , pass this in into  some form of  open bracket born, and then 21 November, 1914. you have,  born time and then born location, open bracket, Newington, Yorkshire, and whatever. at a high level, then, just  somehow converts your structured input into a format that you believe contains the relevant information for the neural language model to process and then on the output side, then just get it to generate text. then,  far, we've covered data to text generation. We can also talk about text to text generation, such as summarization where the input is other texts.",
    "And then here, the thing to keep in mind is that when you're doing text to text generation because, you're trying to generate some new text. That means there may be. There must be something about the input that we'd  to change and depending on what? That can be called something different. , if you're changing the language, then it's a machine translation task. If you're changing the length, then it's a summarization task. If you're changing the complexity of the language, then it's some  text simplification task, or something that I'll introduce called sentence fusion. Or if you're changing the style of it, then you're changing, then it's then it's called the A style transfer problem. ,  again, of course, you can just always choose to just throw everything into  a neural language, model a pre-trained model and see what you get. And it may be successful or not.",
    "But today I'd  to talk about a particular approach to a particular problem, which  is a bit interesting, because I can then introduce another technical approach that you can add to your toolkit. And  this technique is called integer linear programming. And it's really one instance of a broader class of methods and a more general approach, which is to think about things declaratively. How many people have heard of linear programming. a fair number of you great. it's used in Nlp as , or it can be used in Nlp as . ,  let me 1st introduce a sentence fusion task. This is a task that I've worked on myself during my Phd. Here the task is to combine information from multiple sentences in order to generate an output sentence. And then there are different reasons.",
    "You want to do this one, Major. One would be that you want to present a union of the information in the input sentences. in this example, I have Bohr studied at the University of Copenhagen and got his Phd. After graduating, he studied physics and mathematics at the University of Copenhagen. and then in the outputs you can combine parts of the 2 sentences. and what you get is something , after graduating Bohr studied physics and mathematics at the University of Copenhagen, and got his Phd. There, and the different colors here represents where you got the information from the 2 input sentences. ,  what's interesting about this is that if you think about this problem there are many possible. There are many constraints about the form of the output sentence that you should generate. You want the output sentence to be  formed and grammatically correct.",
    "There are also semantic constraints in that. The output sentence is still faithful to the inputs material. And  ,  there's a lot of constraints here. the idea, the general approach that one line of work has taken is that you represent each of the individual sentences by some structured representation  their dependency parse tree. And then you can create a sentence graph sentence graph by merging the input sentences, dependency trees at the nodes with the same words. both sentences before, if you have  2 sentences  he studied sciences with pleasure, or he studied math and physics with Bohr. Then you can merge those 2 nodes  that it's a single node for studied, and then all of the dependency, relations  subject or prepositional phrases or object, and  forth. They all exist in that sentence, graph as such. this, this part makes sense. It's  you have,  each of the parses.",
    "And then you're merging them together. And then you get this graph structure. then, assuming this made sense, then the  part is , you, then need to create an optimization problem to extract a new sentence from your larger graph structure. the idea here is that you select a subset of nodes in the sentence graph that will form a new dependency tree from which a new sentence can be generated here. The issue is that there are many things that you want from the selections, and there are also many constraints. , 1st of all, one constraint might be that the nodes must form a tree. This is how you ensure syntactic correctness. but you also want to make sure that the selected nodes contain important words, and the selected nodes should make sense with respect to each other, while also, respecting  some output length. You don't want a sentence that's too long. what we would really  is to have a method that allows us to write down all of these hard constraints and soft constraints.",
    "and then to perform the selection with respect to these constraints. And and this is why we would approach this with a type of solution such as linear programming. The idea here is that  you write down. ,  you have this optimization problem with all of these constraints. And you write down an optimization problem where you explicitly write out all of these constraints. And then this becomes an optimization problem that has a certain form that you can then pass on to a solver that does that figures out the solution for you. again, this is, this represents a very different approach to thinking about AI problems. Here's another question, how many people learned prologue? 2. , , that's more than 0.  this rep,  back in  the late eighties and early nineties that the wave of AI back then and the hype back then, was based on prologue. It was based on this idea that we can have general purpose algorithms that solve any problem as long as you can write down your problem in a form that the solver recognizes.",
    "in the case of prologue, it might be something  in a simplified or restricted  1st order logic. where you write down every all your constraints and everything  about the problem, and then you prologue finds a solution for you here. This is a similar idea. this idea, this approach, is called a declarative way of thinking about problems , say, declarative programming or declarative method to solving problems. which is that you don't tell the model how to solve the problem. and you don't give it examples and ask it to , figure out the function. It's about just writing down all of the constraints and everything  about the problem into a form such that you then ask a general solver to figure it out. in this particular setting in this particular generation setting, how that's gonna work. And we want to select nodes within this graph which correspond to words that will appear in the output sentence. that's 1st we need to define the nodes.",
    "then the nodes we can call it  Xl. for each edge in the sentence, graph from word h to word, w with label L. Oh,   ! This this node  corresponds not to a word, but  an edge relation between where it's. And  this will say that it has to be 0, or one where one is. We select this edge in the sentence graph and 0 means we don't select this edge. This is how we're gonna interpret the meaning of that particular variable. And ,  this is one variable in our optimization problem. And and then we optimize an objective where? here, this is either 0 or one. this is for all of the edges.",
    "You sum over all the edges, and then you have a grammaticality score which tells you how often this head word is generated generates a dependent with this label. and then an important score, which is  how important is the word W in this context. and then everything else you can write out as constraints. then, in this type of approach. All of the optimization problem looks  this. you're either maximizing or minimizing something. It doesn't really matter, because you can always just take the negation to flip the min to the Max and whatever. we're maximizing this objective function. which is about , , which edges do you choose to select. and then how good is each of those edge!",
    "The 1st constraint, it turns out. ensures that each word has at most one head which you need because you want this, the overall selection to correspond to a tree. And also you need the second to ensure that the selected nodes  form a connected tree. you don't just select  individual nodes. the 1st constraint ensures that each word has at most one head, and the second ensures that it's connected. Here's a question we can  write another constraints to constrain the number of words in the output as . Should be pretty simple to do. What would that look ? if the order of the words is determined by the . the outputs of the , ,  this formulation.",
    ",  you've spotted something which is good. This formulation does not specify the order of the words directly. it only specifies the tree that you select in the sentence graph. you need a separate step to linearize it, to linearize the tree into the sequence of words. But that's relatively easy to do from the dependency graph. Because then you have . after this, you have a tree structure, and then you can just do some  simple rescoring with a language model, even with  a very bad language model to linearize it, and you'll get something reasonable. And  the constraint of selecting things that are interconnected tree doesn't limit the output, and , remove good potential output sentences. the constraint that you have to select a tree it very  could it could be reduce the quality of these selected outputs. , it could , at least according to these scores.",
    "that's  the point of the. it's because you believe that there are these other concerns with that,  you, you want the output to be a  formed tree. it turns out that you can write out a constraint to we. indirectly, by counting the number of edges, I'm thinking, just taking the sum of all. because this tree, I know I didn't give you very many examples. this is all very abstract. But this tree,  each selected edge, corresponds to a word, because it's a dependency tree. You need to sum up over all of your x's and make sure the sum of all of them is less than your budget, which is a constant in the optimization problem. ,   one thing that's more interesting to talk about is , how can you get this approach to work with  a neural model, is it still? there'd be some way of passing the inputs in where the , the output of the model is whether or not to select this edge and then training for that objective?",
    "what is the order in which you do things? Do you 1st try solve this optimization problem and then pass the output to a neural model. Is that what you're saying? the input 1st 3 as something that will be passed into the neural model, and the output of the neural model would be whether or not to select the edge and the model,  by training for that objective would  automatically learn the constraints I see. you're saying to bypass the this optimization thing. take the inspiration from this, that,  there are constraints. and then feed it into a neural model, and then ask the neural model to do its thing and predict some outputs, and then hopefully, through training, it will learn to respect the constraints. That's definitely a good approach to try. ,  the downside is, you have no guarantee the constraints would be respected. But in practice it might work better.",
    "It might work very . you could also do the opposite, which is  you have a neural model, and if you have access to the internals of the neural model,  you can derive  scores, or you can take the logits or the posterior distributions from the neural model. and use that as some   goodness score. and then you feed that in as coefficients to some formulation where you have a setup  here, where you then solve this constraint optimization problem. there are things you can try and experiment with here. also I  glossed over the fact that why is this called an integer linear program? It's because all of the variables in this setting. In fact, here they're binary. And  if you've done linear programming, you  have learned that in linear programming. 1st of all, it's called linear because all of the constraints and the optimization objective, they're linear functions over the variables.",
    "And that matters, and also the fact that they are real valued matters in terms of making sure it's  efficient to solve. for real valued linear programming. There exists polynomial time algorithms for that although the most efficient ones are not. They're  in the worst case, complexity is  worse than that. But , but once you get to  the integer case, it turns out that it makes the math a lot harder because you cannot do . If it's not continuous, you cannot  do some   local search about a good solution. and then it turns out there. Then it becomes a Np-hard problem. But still the solvers are really good these days,  you can have very good ilp solvers and also  stat solvers. If you've heard of that problem where everything is expressed as  and logic is  true or false statements connected by logical connectives.",
    ", even though in the worst case it  has,  very poor complexity, results. In practice, you can still solve reasonable sized problems with, especially with  industrial strength, implementations of these solvers that are highly optimized and very, very fast. And  that is its own field. optimization, convex optimization stuff is its own field. and we can leverage those tools and those findings to apply it to natural language in certain natural language generation tasks or other Nlp tasks if we'd . just , there are declarative. This, the general idea I want to convey here is that there's a whole other approach to solving problems which is not currently that popular but has existed and was influential, was the dominant paradigm for a while. Which is this idea of doing things in a declarative way. where you specify these diverse objectives and constraints of your problem. and then you have general purpose off the shelf solvers that you can run to solve those optimization problems.",
    "And you can interpret the output back into your application contact, setting for your task. And this could be applicable even in other domains. It's not just for Nlp. if you're working on  other kinds of data where you don't have a large pre-trained model. That's just doing a lot of things for you. Then then you can consider approaches  this as . If you need  guarantees that you're respecting certain constraints. here you can really make things into a hard constraint  you must satisfy this. Otherwise you just, or you refuse to output something. that's also another reason to do this.",
    ",  I'll end with a few more trends in the energy literature in the past few years. and these also introduce interesting additional techniques which are  a bit more familiar. They're closer to  the neural settings. one trend is to think about correctness again. this is a problem that I've worked on in my lab. correctness and factuality sometimes these days. It's called the hallucination problem, although, to be clear, this terminology implies that language. Models have mental states which we don't really know if they do. But , that's what it's called these days. , , one problem we talked about just  is that if you do everything in a neural way.",
    "You have no guarantee that the outputs will respect semantic correctness or some other constraint that   a safety constraint or something, and this  happens in practice. you've  all seen examples of this in  of  hallucinations and errors of large language models. , we looked into this in my lab as  before it was cool. here we have,  some, the original output of  an abstractive, summarized neuro abstractive summarization system which identified the wrong victim of a terrorist attack. And this is  a this could be a really bad thing, ? If you have an automated news summarizer, and it gives,  the wrong basic information about an event. That's a news event that can be very terrible. And  we train a system that it doesn't fully fix the problem, but it partially fixes the problem, and that it's a post editing model to detect these factual inconsistencies and then to correct them. And we did that through artificially perturbing news articles to come up with  an automatic set of training data with factual inconsistencies and then training a model on that artificial data. And then you can apply it to some to the outputs of  existing summarization models.",
    "And here's the form of that. It's , predict, the corrected summary based on the potentially incorrect or corrupted inputs plus the source documents and how this is implemented, I'm sure by  you can , imagine this for yourself. This could be an Lstm model. It could be a transformer model and some  neural model. As long as it's you can cast this as a sequence to sequence problem. Another trend which is still ongoing, because it's not a solved problem by any means is to do controllable text generation. which is to ensure that the output has a certain style or formality, or some  certain semantic content, or avoid saying something bad. this was a while ago , but Microsoft released a chatbot called Tay. and they just released it into the wild on the Internet. these days  that would be considered very naive.",
    "But , they tried back then, and then they released it on Twitter. And they also got the model. They had this vision that people would interact with it, and the model would get gradually get better and better through its interactions from users on the Internet. And of course, people are not nice, necessarily. And then they within 24 h they've managed to get the Chatbot to further fine tune and adapt, and to say all sorts of horrible things, with lots of  racist and misogynistic content, and  forth. It was  just  a matter of  one day before Microsoft had to take down this Chatbot. And  that shows that ,  we need to have controllability of our AI systems. And we can't just release them into the wild and have them adapt to that. , they're  this, this sounds. It's funny, and it is funny, but it's still a concern, ?",
    ", it's just that this these days is happening at a larger scale, and  with a slower timeframe, and that people could be writing things on the Internet and that things that could itself be automatically generated  to try to influence the overall contents of the Internet. that if you train a large language model on the contents of the Internet, then it'll ingest all this data, and it will affect the quality and the behaviors of the large language model. and a big part of  training of large language models these days is to figure out how to find good content source, appropriate contents, and  to filter out the inappropriate content that exists on the Internet for training and then also through later through in throughout the development pipeline. you also have additional techniques and tools that you apply to try to even after you've trained the first, st underlying model,  the pre-trained model. Then you might want to do some adaptation to change the behaviors of the model after training. And  there are ways to do that. one simple way in the that people have tried in the past is to add something called a control token. The idea here is that you just prepend the special token that indicates the type of content you want to generate. suppose you have a corpus of text labeled with a property you care about   polite versus impolite , could you please do something versus? Just do this  you could prepend special tokens  polite or impolite in front of the sequences, and then train a language model with that with those annotations.",
    "and then at test time, you can control the output indirectly by prepending the token corresponding to the target property as . And you can do this is a very flexible paradigm. You can do this with all sorts of properties. You can put in other things  desired words or contents, or you can put out. People have also tried putting  a plan of what you want to generate overall into the prefix, the prompt,  of what you're gonna of the language model and then start the generation process condition on that. And ,  that's the current approach which is really popular. rather than single tokens, it started off being single tokens with special meanings. , people are just putting in whatever,  it could be  some instructions. It could be some  overall larger plan for what you're going to generate. You put it in the prompt and then condition on that generates another approach that people have tried is to do unlikelihood training.",
    "which is to tell them decoder what not to generate. Again, assuming that you're able to derive this set of negative contrast words. this is interesting because it's  the opposite of  this standard approach to neural training. the standard approach to neural training. this is the objective function of unlikelihood training, and the standard approach only has the second term here. The last term here, which is, predict the  word given all of the previous contexts. That's the that's the standard log likelihood objective. it's expressed in a slightly different form, in terms of  some  a cross entropy loss or whatever. But this is  what it is. And then, in unlikelihood training, you also have an additional term.",
    "here it's the opposite sign is one minus something which is  the C is the contrast words. It's  the set of words that you don't want the model to generate . and then you throw this into your objective, and then you have some coefficient to weight it a certain way, and then off you go. it turns out this unlikelihood training can be a little bit tricky to get it to work , and it  makes sense, because,  telling the model what not to generate at the token level isn't exactly what we want, ? really, what we want is when we want to tell the model what not to generate at some semantic level. It's just very hard to specify that. And , turn that into  a form that the language model understands. you can do this, but the results may be mixed. oh, , what's the difference between this and contrastive learning? the difference is that in contrastive learning your contrastive set, the negative set.",
    "The interpretation of the negative set is that it's just the things that are not the correct answer. in contrastive learning you have, this is the correct answer. And then we're going to  sample from the everything else to come up with a contrast set to separate the 2 here with unlikelihood training. It's  similar, but the difference is that here the contrast set, the negative set are things you. You want the model to actively, not generate. It's not just things that you think. Oh, the model shouldn't generate because it's not the correct answer. These are things that the model should actively not generate. then, how you draw this set of  Ct is different. The set Ct here is  specifically in the negative things.",
    "there's a stronger pressure here with this approach to push these things down. is, is there a possibility additional numbers to get the calls? ,  I'll try to see if I understand the question. the question is ,  there's this work in adversarial learning, and then you're interested in figuring out if there are ways for the model to itself, automatically identify things it should not generate. , by using sentiment scores to figure out there's some outlier in sentiment or polarity, or in sentiment, polarity or something else. , that's an interesting approach. , in terms of the general idea of using the models, outputs. and the characteristics of it. To determine whether it has generated something very strange is a good one. there's work on that in specific application context.",
    "Is it a widespread approach? there's 1 line of work which is  related to that, I would say, at a high level which is  this, chain of thoughts, work where you have a model, generate outputs, and then you condition on the model generator output to generate something else. And  this is more general in that the model can choose to continue what it's generating in the same directions. And  it also allows it to inspect and choose,  to correct something and fix something. But , that's what I can think of   in terms of a general approach. , that's not a question of adversarial environment. , in the previous slide, when you're conditioning the model with some  token or some  prompting context. Doesn't that mean the model is  quite responsive to certain tokens. And therefore you can  search and generate adversarial tokens that impact the models. ,  the question is, if the model is conditioning on a token to generate its outputs.",
    "Doesn't that mean it's conditioning on it's paying too much attention to that token, and it might influence the generation . Or oh, I see that. Can you generate an adversarial token that would impact the model . there's a line of work on that as . They call themselves   they call it jailbreaking. which is  usually the setup is you have a large language model. Pre-trained language model is trained on some data. and  some of it contains sensitive information, and  you have some mitigation techniques to  through adaptation, model adaptation with  reinforcement, learning or something to get it to not reveal sensitive information. And this line of work in jailbreaking. The main assumption is that since the pre trained language model has seen the sensitive information in training, it's there somewhere in the model parameters.",
    "And if you search for the  sequence of ,  fake tokens artificial tokens, or  just something on the on the inputs to prepend, you can get the model to reveal the information that it's seen that it's not supposed to. there's a line of work there. And then  the other major trend that I haven't. I didn't talk about in the slides is  reinforcement learning. And  the other major trend   is you try to fix these issues with human feedback where you sample a collection of model outputs, and you get people to decide which one they prefer, and which one is better, and that becomes a reward signal, and that reward signal can be used within this other machine, learning paradigm that we haven't talked about called reinforcement, learning to try to affect the model's behaviors and its outputs,  that the model tends to generate things that give it a higher reward. that's another way to try to control the generation. you can reduce the reward constructed loss for the model that can be used to backrot it to update the parameters. The reward signal is used within some objective function and with back propagation in order to change the model parameters. , at a high level, it's the same. The difference is that in supervised learning you have a loss that is defined in a very structured way, that each sample is associated with a label, a label or a correct label or not.",
    "whereas in reinforcement learning it's just some scalar. It's just some scalar of  good versus bad,  a positive signal versus a negative signal, and that gets propagated down to  the sequence of decisions that the language model has to make as it's doing. reinforcement learning methods typically are harder to get working and to train. , because it makes looser assumptions about  the structure of what's happening. that's all I want to say. week there are 2 lectures. One lecture will be on evaluation. I'll talk about a little bit more about evaluation of Nlp systems. and I'll also advertise the course I'm teaching  term a seminar course on evaluation, and then the other lecture will be a guest lecture by one of my postdocs, or Ernst on a topic that still to be determined  to do with natural language generation. Was 3 to 5 min."
]