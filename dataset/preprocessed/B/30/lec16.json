[
    "Jackie Cheung, Professor: Yes, , I'm recording . you haven't missed out much yet. we're in the setting of syntax-driven semantic composition. And last class, we started talking about the specifics of how this is done. We talked about nouns mostly proper nouns, and we talked about intransitive verbs and the other major high level concept from last class. Is that how this works is that each lexical item. each word at the leaf of the tree is associated with some fragment of meaning representation in the logic that we care about. and that when you do a syntactic composition by applying a rule in your context-free grammar. You also do function application in lambda calculus to build up a bigger piece of the meaning representation for the whole constituents. And  there's this   these 2 perspectives. The syntax part is  you combine things to make a bigger syntactic chunk. And semantically, you're also combining things to build a bigger meaning chunk of meaning representation, and then once he gets to the top level of the S level, then you filled out everything that you need to fill out on the semantic side in order to build up a logical sentence in the logical formalism we're working with. And in our case it's 1st order logic. that's  a reminder of what we talked about in this class. today, we're going to talk about, we're going to expand our grammar a little bit to account for several other phenomena. though by no means is this exhaustive. we're gonna talk about more kinds of verbs, say, say, transitive verbs. And then we're also going to talk about quantifiers. we're gonna look at how in logic you have these universal and existential quantifiers, and how we can use them to model quantifiers and natural language. And then something called definite descriptions. ,  , just as a , lambda calculus is there as this separate thing to help us build, meaning the meaning representations piece by piece. the Lambdas are there to help you figure out or to help you express that you're still missing information. And then, when you do more syntactic composition, then you combine more pieces of meaning representation together, and then lambda calculus will help you figure out exactly how you should combine the pieces of meaning representation. And here's the syntax driven semantic composition  a rule that we have ? each context-free grammar rule is accompanied by some expression that tells you how to combine the meaning representations of the pieces. ,  last class, we talked about proper nouns, and this is the general form of them. It's some lambda expression with a constant and  and common nouns will also be some lambda expression, but this time with a predicate. this is a predicate that eventually checks whether something is a student or not for the noun student. And then we also talked about intransitive verbs. intransitive verbs only takes the subject as an as an argument.",
    "There are no direct objects. and I recall that what we said was that with intransitive verbs, we with verbs in general. one standard way to express, that is to say that there is a event variable. There's some event that takes pre takes place, and it has a certain type which is  the types that corresponds to the verb itself. it's a rules events, and then you can express that the event variable. E is associated with some something which is the ruler? Can you explain a bit more? The events concept , is it  an action, or is it the representation of the verb  that 1st one was, I understand, the second one, and the 3rd one, when there will be but  in ruler. There is a ruler ? But the rules would be in the middle of that I don't really understand, sure. The question is , can I explain a little bit more of this event? , that it's a bit difficult to wrap your head around. ,  you remember we're building this logical representation in order to say, access some database, or make some inferences to say , did something happen? Or did something not happen, and who was involved or whatever . that's the point of all. This is to build some meaning representation in order to be able to do some inferences. with nouns and noun  things, it's  more obvious that you're creating these entities, and then you can reason about them and their relations to each other. But what about the verbs, and which often denote events? in order to be able to reason about something, you have to have some entity that exists that you can manipulate   in logic. You you always have . This is true, then that is true, but you need that this part. in this framework, a common thing people do is that they reify it. What that means is that they create a discourse entity that corresponds to that event. there is  for this event of  something rules. this abstract idea that it's  a it's an entity. and you can talk about it, and you can talk about its properties. You can talk about when it happened, and or will it happen? But   to you, need to create this event variable  that there can be a discourse entity associated with it,  you can reason with it. that's the that's the intuition here. when you say there exists E, it means that there's some you're saying that there exists some discourse entity.",
    "there always needs to be  event management where you just put it. there always needs to be some event variable every time you introduce a new events  ever . And then and then this rules E part. it's a predicate, but it's  here is function is to add a proper is to say, what's the property of this event variable. We're talking about the entity associated with this event variable, . And it's that it's it's of this type. And the ruler part is saying that it's associated with this other entity, which is the entity that rules. why are we doing things that way? Because, previously, you can imagine that a simpler version of this is just to have,  a predicate  a multi place predicate. That's this is  the simpler alternative which is just that there's a rules X where that corresponds to the events. but by reifying it makes things a lot more flexible. because then you can have optional elements,  locations and times and passive structures, and you can just all account for them in the same way by talking about properties of event variables. and you can also add information to the event variable about  a tense and modality  when it happened, or will something likely happen? Or even if you just have,  multiple events of the same type, then with the event variable version, it's much easier to deal with that. that's why we do this  complex thing of  of this is called reification, ? making something  tangible as an entity. But this is called Neo Davidsonian event semantics. the formulas will get complicated. But the concept is the same. don't get freaked out by all of these symbols. , as long as you understand the high level concepts. there's a mechanical process to derive the things with a lambda calculus and function application. But the high level concept is exactly the same. we've talked about intransitive verbs. and a transitive verb might be something  enjoys. 5, 50.  it's transitive because there's a direct object, and there's a subject. how do we derive the semantics of that? first, st we have to have a semantic attachment to the lexical rule. that means enjoys verb rewrites to enjoys, needs to be associated with something. And that's this,  long and seemingly complicated piece of thing that is in lambda calculus, with parts of 1st order, logic in it.",
    "But again, conceptually, it's exactly the same. And the way you derive this particular form is just. You have to work through it and figure out that this is the form you need in order for everything to work out and be filled in the  place . And and you won't have to do anything this complex on the midterm. But conceptually, it's the same. the additional rules that we need is that we need to have rules for the direct object to for the semantic attachment associated with  the direct object, rule ? Because for the direct object, you have something  Vp rewrites to Vnp. You remember this  with transitive verbs. you need a semantic attachment associated with that which is that we have the. You take the semantics of the verb. and you apply it to the semantics of the direct object noun phrase. And then the sentence rewrites to Npvp. Rule is still there, and it's still the same. we can work through the derivation. You can do this at home to  again, to  work through each of the steps, and it looks complicated. But conceptually it's not complicated  conceptually. first, st if you want, you can draw the entire syntax tree. And this is what the entire syntax tree looks . ,  Jackie is a proper noun, and it's a noun phrase, and then verb of enjoys. 5, 50, which is a proper noun with its noun phrase, and then it combines to a verb phrase, and it combines to the sentence. The  step is to write down the semantic attachments for all of the lexical rules. for proper noun rewrites to Jackie it looks  this lambda XX applied to Jackie or enjoys. We have this monstrosity we just introduced in the last slide, and Comp. You have lambda XX applied to Comp. And after that it's  just going bottom up in the tree and doing function application with the rules of lambda calculus. and  the order of the variables. the question is, does it matter? The different parts of the conjuncts are written? with conjunct, with,  the logical and in logical order. If there is a bunch of them together, it doesn't matter what order you write them in.",
    "that you can prove that pretty easily with , say, I don't know logic tables, or whatever. But the order of the Lambdas here. because the order of the Lambdas here that tells you when you do function application what gets plugged in to which variable there. that does matter, and that you cannot exchange. And no, you do not have to memorize this very midterm. I understand the variable V and X, but I don't understand the variable total. you don't understand the variable? And then  how it simplifies. , ,  here we have Conf 5 50.  it gets passed up from the lexical level to this noun phrase level. and it's just the same thing. the semantic attachment for that rule, you just copy it directly over. And  for Vp rewrites to Vnp. remember, from the previous slide. The rule is that you take the verb semantics and the noun semantic noun phrase semantics, and you combine them together where the noun phrase semantics is the arguments. ,  what that means is that you just copy the entire rule over here. And then the arguments is this thing. and do I do the simplification? Yes, I do the simplification here. and you can simplify you. 5, 50, and then you plug it in where the W is. and what you end up with is lambda Z. And then this thing applied to this thing. Take this thing as the arguments. and then you put it there where the Y is. and it's it's a whole mess, but then it works out, because then this whole thing is  the functor, and then Comp. 5, 50 is the arguments. and then you put the Comp. 5, 50, and you plug it in where the X is, and eventually the constant of comp. 5, 50 ends up in the  place and ends up in the place for the enjoy. the thing that is enjoyed, and that's what we were hoping for.",
    "And all of these steps is applications of lambda calculus. you really have to practice that to not make a mistake. But if you if you do that, then you'll derive this. and this will be the simplified form of the verb phrase semantics. it's still missing something which makes sense, because we still don't know what who the enjoyer is. Question, how do we go from lambda x dot x 5, 50 in the 1st line into lambda y dot y, is it because we're  switching in X dot x for y, or is that a typo? 5, 50 gets plugged into where W. Is , because the 1st lambda here is lambda W. And the argument is this entire function. then how does it get turned into? Why, though  before oh, it's just  that you can always rename things. I didn't want to put X here because it might get confused with this X.  I just renamed it? Why, just  that it's . Technically there, , technically, you're . There's a there's a separate step where you do the renaming. But you're , you're you're allowed to do that. All bound variables can be renamed. and the and they're they're . It's because,  there's a there's a whole series of reasoning steps you can derive to show that this is the way that you need to make to make all the representations look more similar to each other in form and to have function application workout across multiple syntactic constructions. there could have been a simpler form that works with this specific sentence. But if you want the same approach to work across multiple semantic phenomena, then you need it to be a little bit more complicated. But you don't have to worry about that. The , you understand, the concept of each lexical rule comes with a semantic attachment. and then each production also comes with a semantic attachment, and you use those to  work out what the meaning representation is for each constituent. 5, 50 is substituted for X, the way I'm reading it, I thought it would be substituted breeze. ,  you mean, why this chunk ends up here? Comp, 5, 50 ends up in the position of enjoy. X. ,  from this step to this step. , ,  from this step. this entire thing gets plugged in to where y is. this whole thing gets plugged into where Y is  then, when you do the rewriting,  you still have lambda Z, and then this whole thing becomes the why. 5, 50 is  the argument.",
    "But same thing , aren't we supposed to go left to ? why is it being substituted for  and , why aren't we looking for it as ? We're going left to , but here it's lambda Z, and then 2 things within it. It's not  there's 1 chunk, a second chunk, and a 3rd chunk. There are only 2 chunks. and then there's a second chunk for this whole thing. And then and then the last step to get to the sentence level is the same. ,  for the subject, you pass things up. and then the subjects, semantics is Lambda XX. Applied to the constant Jackie. And then it's the argument is the verb phrase semantics which we just arrived, and then you can simplify. You can plug it in and simplify it here. And in the end you get what we want, which is that we've created this enjoying events variable, this event variable, that corresponds to a type of enjoying events where the enjoyer is this constant that points to Jackie and the enjoyee is this constant that points to something  something that represents Comp. if there were 2 verbs in the sentence, would we expect it to be 2 event variables? the question is, if there are 2 verbs in the sentence, do we expect there to be 2 event variables. , that's what you would expect. We've done intransitive verbs and transitive verbs. it turns out that language is full of quantifiers. And  the ones that most clearly map onto logical quantifiers are these words  all and every which map to universal quantifiers. 5, 50 would be for all. Student X implies,  x. Comp. 550,  technically here to be consistent, I should really do. There exists an event, E such that E is in liking event, and the liker of E, and the liker of E is student. No  is X, and the  key of E is comp. But here, I just for the sake of clarity, I just switch back to  the simpler predicates way of expressing events. Because  , what we're focusing on is the bonification part. all students  Comp, 5, 50, it's for all. X student X implies something. And then there are also existential quantifiers. when we do model indefinite articles and also quantifiers  sum is that some student, a student, likes comp.",
    "550 is expressed by an existential quantifier. Such that X is a student, and then X likes comp. However, you want to represent that  just as a reminder. the universal quantifier is almost always accompanied by this implication. logical implication, whereas the existential one is accompanied by the conjunction. Do you remember, have you? I'm hoping you've seen this  . Cause cause what happens if you have for all X student X and X likes com, 5, 50, what would that mean? Cause if it's a conjunct. What it means is that it's asserting that everything is a student, and everything likes Comp. Whereas here what we want is that we want only the students to  Comp. 5, 50, not the not the instructors, and not the tas, and not  anything that's not a person, . here this is a condition ? Such student X implies X likes. You're saying that there exists a student, and there's something that makes Comp. But we're no longer checking that X is stupid. that's that's  that's almost that's almost it. No, no, that's the correct meaning, ? the correct meaning is, as long as there's a student who likes. Conf 5, 50, this thing should evaluate to true. if this was an implication arrow, as long as you have anything that is not a student. It evaluates the whole thing evaluates to true. the implication is just very weird. And it's just not . , what about for the universal one? If you include parentheses  for all x. and then open the parentheses that X is a student. And they  convoluted 50 where the X is the same as the one outside,  you would enclose the inner part in brackets, forcing that X to be the same one as the student and them liking. the question , ,  are you talking about all students or some student. If you add extra parentheses and you replace this with an end, it still doesn't work. It's still the same problem.",
    "I, , you can work through this. the basic idea here is that for universal, it's usually a condition. it's a universal only for , according to some condition which here is  all the students, that's the condition for existential. You need both to apply. there's some something that is both a student. And they , Comp, 5, 50. ? for our purposes, , I'm gonna skip to the lexical rules and then come back to talk about definiteness. this is what the form of the rule would look  you have. And this can be all, it's the same thing. you have a determiner and then rewrites to the lexical item every or all. And then it's gonna take this general form where you're looking for 2 things, lambda, P. Lambda, Q. Which corresponds to the 2 parts of the implication, and then you introduce the universal quantifier here. and it'll look very similar for the existential. It'll just be debt rewrites to sum. And then lambda, p. Lambda. There exists  such that P. Of x and Q of X, and then you can check that within the derivation in a tree, which we'll  in an example soon. , but  the other major thing which it turns out, you can model with quantifiers. And this is quite interesting linguistically, which is definiteness,  the. we've modeled indefinites  with existentials. The definite case as . luckily, in English and in French. We it's it's I don't have to . Justify what definiteness is to you, because, , they clearly exist as words  B or A, it turns out that many languages don't have these things  they don't mark definiteness  this. this is also historically interesting. if the linguists were Chinese, they would not have focused on this  much, because in Chinese you don't mark definiteness, you do mark definiteness, but using a bunch of other means, and not with  these words, ,  B or A, . and many other languages also do not mark definiteness with articles. and, in fact, , if you're a second language speaker of English,  when you learn English, if you came from learning a language that doesn't mark definiteness with articles. It might have been tricky, ? how do we express the student in 1st order? I'll present to you an early theory for this which works within our framework.",
    "which is, it's from Russell in 19 0, 5. We're learning something from  the last millennium. ,  it's the Russell's theory of definite descriptions. when you say the student, as in the student took comp. You're really asserting 3 things. First, st you're asserting that there is an entity who is the student. and then you're asserting that there is at most one thing being referred to who is a student. And you're also asserting that the student participates in some predicate which here would be took comp. This is according to Bertone Russell. ,  in this analysis, then in you can express all of this in 1st order logic. , yes, you have a question. on one of the metrics, there's an example where it's  the apple is in the yard. This would have the 3 properties enforced, but the yard wouldn't, because it's not followed by a predicate. the question is, if you have, the apple is in the yard, what happens? all 3 things still apply for the yard. It applies to the apple and applies to the yard. because the yard is still participating in the predicate. It's just participating in a different position. It's not participating in the in  the semantic, . It's just it's participating in  the , more  the place position. But it's still participating in that predicate. you have to assert uniqueness for both of them. ,  ,  why these 3 properties? and also in particular, why property one, if you consider something  the King of Francis Bald. then this is weird, ? if you say the King of France is bald, if  anything about French politics. France currently has no king. if you say the King of France is bald, according to this analysis, that sentence should evaluate to false. and it evaluates to false because there is no King of France. Other people are saying, Don't don't think that it's you should say that the King of Francis Bald is false.",
    "They should just say that it. It's neither true or false for other reasons. You can come to ask me about this in office hours. You can also imagine defining a new constant for King of France, just  for proper nouns. and then the 1st order, meaning representation. 1st order, logic, meaning representation, might be asserting something  bald King of France. But this doesn't work because King of France has to point to something. And  then this already presupposes that it points to something which is the King of France. then, rather than doing this, according to Bertrand Russell, then you should just the King of Francis Bald asserts that there is an entity that is the King of France. then,  ,  we need to translate these 3 properties. There's an entity that's a student. There's at most one thing that is a student, and the student participates in this predicate. And  the way that you do this is with this relatively complex formula in 1st order, logic. there exists in X, such that X is a student, that's property one. And it's a unique student. for all y student Y implies y equals x, that's property. 2, and took X, comp. Again I reverted back to the simple form of  the event. And that's how you model the meaning of the student took Comp 550. the question is when we say that there is at most one thing being referred to. Are we talking about  everywhere in the entire domain. Or are we talking about within the context of where that sentence is uttered? , technically, this is  in terms of how we've defined logic  far. It's  in the entire domain of discourse. But that's why it's called the domain of discourse, because within the context of a particular sentence, you can define that domain of discourse, not as the whole world, but as  the world of  the shared conversational state between the speaker and the listener. and then with  within that narrowly scoped domain of discourse, then there should only be one student is what this is saying. ,  dealing with definiteness and  forth. is really interesting to me linguistically, but also , this is one thing. I claim that  language models  don't do   with quantifiers and things  this. And one  one argument is that they don't really do reasoning and logic   and  they often don't do   when it comes to  thinking about how many entities and how many things there are in a particular context, because they don't build these logical representations.",
    "I would say that they  do quite  in stringing together sentences that seem to use quantifiers correctly, in a grammatically fluent way. But if you ask them to reason about things, and if you ask them to  reason about oh, I said, , there's a student. And the student has  these properties and got these grades. They might not reason   because they don't connect the information expressed about the student back to  when it's introduced. they don't keep, do  a perfect job and keeping track of how many entities have been introduced in our. And we are talking about and associating the  pieces of information with them. arguably, that's because they don't  think about things logically. They it's all through word co-occurrences. you can  design a bunch of tests to trick chat, gpt into getting things wrong when it comes with reasoning with quantifiers. , we can't see it in isolation, ? And  it  , it is defined with respect to the 1st rule, because,  there's at most one thing being referred to. That's a student  you have to say that everything that's a student is the same as X.  , and that. this second part is in the scope of the 1st quantifier. And also, if you want to ask me about this. this was the analysis presented by Bertrand Russell in 19 0 5, there are  different analyses of these things. if you're interested you can come and ask me about an office hours, and I'd be happy to chat about what are some other approaches to handling quantifiers and definiteness. for our purposes, then we want to integrate all of this into our general paradigm of syntax driven semantic composition,  we already did it with the rule. Every we can do the same thing with all of the other quantifiers  A and B, ,  we can do. Comp, 5, 50 with the same rules as before. with the likes and Npvp and Vnp, and  forth. And again, in the rules, I introduced explicit event variables. this is what this would look . ,  let's do every student. for every student, this is the part that we haven't seen before. every is the this rule. Of x implies Q of x, and then, student, you can get from the previous slide. X, student X.  then the noun phrase semantics is, you just do function application on the 2 of them. And  then this function of lambda X student X gets put in where the P. Is. I also renamed the X to the Y before doing that. For all x lambda y state of y student of y applied to X implies Q of x. and then you further simplify, and you take the X and you plug it in where the Y is.",
    "Q of x.  this is the this is what we want, because it's plugging things, plugging the student predicate in into the correct location. And then there's going to be a Q of X that is still to come, which is where we plug in the part about  likes. And then you can, you can do this for the rest of the sentence and work through all of those function applications very carefully. and to show that you come up with the correct semantic representation for the whole sentence. , but we can do this part together. what are the lexical rules with semantic attachments for a and for D, ,  for I'll give you the syntactic part of this. ,  this is the syntactic part. what would be the semantic attachment for this and also for , what would this look ? M. Dot lambda queue dot the exist symbol. And then what was there exists. And what about for the ? almost not quite  the beginning. It'll the beginning will look the same. ,  let me do the M, that key and the queue first.st . , you have to take this whole thing from before. and you need all the 3 parts ? There exists an X such that p of x, and . An x such that p of x. and for all. Implies y equals x , P of y implies that y equals x and the predicates . and you might want to , close this off in a parentheses. And Q of X.  that's the 3 parts. And sometimes because this comes up  often, this uniqueness. Sometimes people simplify this with  some. something  exist with a exclamation mark. then, that's the simplification for this whole thing. It means that there's a there exists a unique X such that . How did we come up with this rule? we came up with it because Bertran Russell said   intuitively. And then we need to write it what he said. he said that  it's exists a unique thing.",
    "to exist, a unique thing. First, st it has to exist. And if it's unique, that means everything else that has that predicate must be that thing. And yes, in the back. for the P. And Q, we want something that takes more than one argument. How do we deal with that? It  still works with this exact same form. Because how that would be expressed would be  the P. And the queue themselves would introduce those other things. you don't have to worry about that. if you have,  a transitive verb, intransitive verb, whatever it doesn't matter, they both apply. They both will be stuffed into the queue itself, and they'll be introduced by the other parts of the queue. and then the X will just be talking about the current noun phrase. a becomes P. And Q. Pnq,  the A is the existential. According to this type of analysis there exists something, and when, whenever you have, there exists, it's usually paired with a conjunction. because you're usually asserting that there exists some X that has multiple properties. and if you want to get to a deeper level of explanation, then you should write out the truth tables for conjunction, and then check that this maps to your intuitive understanding of what it means to say that there exists a student who has this property? to do adjectives as . ,  let me say that this is what we're aiming for. ,  what we're aiming for is that we have lambda X student X's student. If we want to say that there are smart students, then  they are lambda X, smart X and student X, that's the form that we want to get for a smart student. the question is, what is gonna be the rule for smart, the adjective smart. syntactically, it will be something  adjective rewrites to smart. , this is the syntactic. my question is, what is the semantic attachment for that. And we figure this out assuming that there's some other rule that combines nouns with adjectives. You take the adjective semantics, and you apply it to the noun semantics. Anyone wanna guess or try? say, lamb, something  lambda X, and then specify that there is the existence of some X satisfy us. Oh,  we also need , something  that.",
    "Go ahead just to say that there exists something that can be smart. land why is it not absolutely yep. say, a lambda X student of X to P, then it gets plugged in there. , let's check, because I'm not sure if this we might be slightly off. then we have this applied to that, I'm going to rename this Y, and then, if we simplify that. because then this X  gets plugged into where the Y is. you might want to ask, do all adjectives work  this are all adjectives, adjectives about adding conditions to  additional conditions,  additional predicates or properties. it seems to make sense ,  a student can be smart, or they can be tall, or they can be short, or they can be young and old doesn't matter . And  you think that all adjectives might be  adding these conditions that you can express as predicates with a conjunction. But it turns out that this doesn't work for all adjectives. It works for,  the majority class of adjectives. But there are other adjectives  fake, or former, or false, or  things  that. Also  dead,  that where, , you cannot model them with  a conjunction  that. that's an another interesting thing to think about. Would it be  to explain why for that for faith? why doesn't this approach work for a fake? Can other people see the issue. suppose you model fake as  fake X and Student X, why doesn't that work? Would order matter  a smart big student versus a fake smart student. , I have to think about that. normally, the order the adjective order matters syntactically in that there's a rule in English, for,  the order of adjectives. but semantically, it should not matter, for if all the adjectives are  the majority class of  these are called subsective adjectives. But  the I'm claiming that fake works in a different way. But it's a different reason. I'm saying that fake X and Student X is not the correct way to model the semantics of a fake student. And you're on the  track. That,  something about fake X is really weird. There was some hand in the back. , in the back office. Fake by itself doesn't mean anything.",
    "Its definition relies one student as , exactly. , ,  there are 2 senses of fake. You can say someone is very fake in the sense that they're not sincere. I don't mean that sense. the sense of  a fake student  it might be  someone pretending to be a student. , but they're not  a student. you can't really check whether something is fake or not in that sense. You can only check it with respect to the property of the thing. it's not , they're . with smart and student,  that there are a set of things in the world that are smart. And there's a set of things in the world that are students, and a smart student is  at the intersection of them. Even that is  arguable, . But , but for fake, this is clearly not the  way to model it, because it's not  there's a set of fake things in the world. Only when you're talking, saying, talking about a fake student. it's it's a real person. The person is not fake. but it's that they're faking with respect to the specific property of studenthood studentness. And  for that reason, semantically, you cannot take this approach of modeling as a conjunction of multiple predicates. it'll be something , they say they're a student. But they're not  a student, ? They say they're a student. But they're not  a student. yes,  , would we use not relevant specific,  base adjective. how would you model instead? But a fake student is also not just anything that is not a student. you need to rethink this whole enterprise. you to model the meaning of something  fake student with  non. These are called non subjective adjectives. You have to , define it in terms of , you have a function that maps between students from students to fake students. you have to , rethink this whole thing.",
    "Or if you talk about  Presidents and former Presidents, it's ,  that's also another case that you can more clearly see. former Presidents are not all of the entities which are not currently Presidents ? There are lots of things that are neither Presidents nor for former Presidents,  instead, you have to . remap that function of Presidents to another function which is  the function for former Presidents. , there are lots of this is one reason why I really  language and linguistics. There are lots of  phenomena that if you think about it a little bit more, you realize that they're , really complex. But we just don't think about it. We just can process language, because we've learned it somehow. I want to talk about another common property of natural language, involving modification that is interesting, and it involves quantifiers. which is a scope, ambiguity. what are the possible readings for the sentence, every student took a course. Can you help me with this one? any course we have one course on there program, or they, every student took one specific course. can do you all get both readings is either every student took some course, a different course, or it can be. Every student took the same course. how do we represent that using 1st order logic? the way you can think about it is, you can think about it as the quantifiers can be rearranged and they can follow. They they can outscope one another, and they. This gives rise to different readings. the 1st reading is for every students there exists a course such that they took it  here the universal quantifier outscopes the existential quantifier. And for in this reading it can be a different course each time, because you create this existential Y for every student X,  it can be a different course. Every student took a course. It would be the opposite. It would be the existential quantifier outscopes the universal quantifier. there exists, of course, y such that every student takes it. here we would get a conundrum with our current approach. our current approach with the lexical rules and semantic attachments  far would not get us both of these readings . If you think about it, it will only get us the 1st reading. the syntactic structure matches the semantic structure. because the syntactic structure has,  every students, being in the subject position, being on the outside.",
    "whereas the existential quantifier is in the object position, it's on the inside. And  if you, if you dutifully work through all of the syntactic compositions with the semantic attachments. With the rules we described, you will get only the 1st reading, and you would not get the second reading. that's a problem with our current approach. we would  to have a way to derive both of these readings from the syntax. this is an illustration of this general idea, which is that we need a representation that is under specified with respect to some properties that we cannot no, until we have more contacts or more information. we want an underspecified representation that is compatible with both readings. or in general with all possible readings. and ideally, we would  that without having to explicitly enumerate all of them. there are many cases where you might want this . You might just genuinely have some missing information  the tense or something, or you just choose not to encode some information in your meaning representation. you'd  to have a way to do this. you have a meaning representation that is under specified with respect to things you don't know yet. ,  I'll introduce approach called Cooper Storage. The general idea is that everything that you don't know yet you store it away. You have  a lambda abstraction over it, and then you store the relevant information away  that you wait until you have,  some more information later on. and when once you do have that extra information, then you can take things out of storage and , put them in the  place and gets the correct interpretation after all. , , in our case. you saw the expression, every student took a course. and it's within some  syllabus describing courses and students overall. And then, once you've read the entire syllabus, you can figure out intuitively, you can figure out  which was the intended interpretation. After you've read the whole syllabus, and then you can go back to retrieve and derive the corrects disambiguated meaning representation. ,  how does that work. Every student took a course. And what's going to happen is that we're going to express it using something  this. here we have our event variable, and we have a taker and take key. And we're gonna say that s 1 and S 2 are, gonna be these  special here. And they're associated with some entry in the storage which represents  things that  we're not sure what order to do things in. But we know the specific relations that matter. here we're saying that s. 1 here is associated with for all students, because it's the students who are taking the courses.",
    "because it's every student took a course. And the Takei, that's a thing being taken. There exists a Y course Y, and that's associated with S. 2 with the second entry in your storage. this is going to be the underspecified representation associated with the sentence. and then, when you have the extra information, you can take things out of storage, and then recombine  recombine them with the meaning representations to get the correct sentence level representation. When we said the aim was to have this underspecified representation that embodies all readings without explicitly enumerating them, it meant , we will have 1st order logic for every possibility. But we won't capture  every possible explicit sentence. when I say, what does it mean to have some representation compatible with all possible readings without explicitly enumerating them. this, this is the an example of that. this fits that definition, because I'll show that you can derive both possible meaning representations from this storage from this underspecified representation. It's not enumerating just saying this and this, and this is possible. It's just saying that here's here, there's some taker and some takey, and then there's some things in storage which corresponds to the whether it's the student doing the taking or the course, doing the taking, and  forth. this is compatible with all possible readings. But it's not just listing them up. And  the index variables here, the index indices here are important because they point to the things in the storage. when you do how know which order which reading you want. you want to be able to recover them. And in cooper storage how this works is. first, st you select the order in which to incorporate the quantifiers. and then for each quantifier you introduce a lambda abstraction over the appropriate index variable. And then you do beta reduction. a function application to simplify. ,  suppose that we want to 1st incorporate entry one and then entry 2.  you pick an ordering. Then what you do is you retrieve thing from you, retrieve things from storage. then you have your You have the piece from storage. and then you have the meaning representation where you've added this lambda. s. 1.    s. 1 is a bound, variable . and if we do the simplification. then you can put the taker and the correct place. if you do the simplification, this lambda.",
    "And then  it becomes for all. Student X implies the events and the and the X gets put into the correct place with the taker. and then you do the same trick where you take entry 2 out of storage, and then you introduce a lambda abstraction over s. 2 to make it a bound variable. then you can then do the simplification. and you end up with one of the 2 readings. which is the existential outscoping the universal. If you want the other reading. it's the same idea, except that you extract 2 first, st and then you do the one. you extract the second the second entry from your storage first, st and then you introduce Lambda, s. 2 1st and simplify, and then you do it with the universal second, and then you have the universal, then outscoping the existential. You can also write it formally within this idea of syntax driven semantic composition by changing slightly the format of the semantic attachments,  that you talk about whether you're introducing. You're adding an entry into your storage or you're retrieving. And then , you can't retrieve when you're doing the composition, because during the composition part, you're just building up your undespecified representation. you need to specify when you're composing a quantifier with a noun, you're  modifying the inside part of a storage and then  the Np introduces a new index variable which is wrapped in some lambda expression. ,  this is what it would look . , when you have a course. course still looks  what it does from before a still looks  what it did from before. and when you compose them syntactically. this is what happens semantically, is that you want to introduce a new lambda UU. Of s. 1 which is associated with some entry in your storage of and inside. Here is where you do the composition that we had from before, but before it was outside. Of s. 1 lets you to continue to derive the rest of the meaning representation on the outside of the noun phrase. ,  I will, and I'll post this the answer to this on Ed. But you can derive this yourself, work through and derive the representation. The under specified representation for every student took a course with these rules, and with the this rule for the transitive verb. and you can check and make sure that it all works out for to get the under specified representation, and afterwards I encourage you to also , do the derivation, for,  both sides of this,  do the one, and then 2, and following this example, and then do the other one of 2, and then one to get the other reading. ,  if there are no more questions, we'll end there, and I'll see you at the midterm or in office hours."
]