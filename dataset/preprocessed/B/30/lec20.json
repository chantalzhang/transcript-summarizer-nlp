[
    "Jackie Cheung, Professor: Hi, everybody welcome back. people can online should be able to hear me. We're gonna talk about discourse and co-reference resolution. last week you had an enjoyable week talking about machine translation and multilinguality with David ? And  today, we're going to move on to a new topic which is to think about processing language beyond the sentence level. And I'm glad you all decided to show up, because today's lecture also relates to the reading assignment the 4th reading assignment which has been posted  hopefully, this will help with that as . we're 1st going to talk a little bit about discourse and think about and talk about some basic distinctions in the field of discourse. And  we're going to focus on one particular phenomenon related to discourse, which is co-reference resolution. and I'll explain what that is as . And then I will discuss and present some basic algorithms related to co-reference resolution. this might be a surprise given  what we've been talking about in the course  far, but it turns out that natural language doesn't occur as individual sentences or individual utterances  one at a time. ,  all of our models  this might be a surprise, because,  all of the models we have had  far, or many of them. We only look at the sentence level or below. you  process an entire paragraph, and you extract the features from them and  forth. but  but in many of the other settings, in  the past few weeks to do with  semantics, , we looked at sentence level semantics ? And in machine translation, often in many evaluation setups they assume sentence level machine translation as . And  they do  sentence to sentence translation and then evaluate that way. But but , it turns out that's  language typically occurs in bigger chunks than that. We can also analyze the structure that is there at the level of the whole discourse. not just individual sentences, but relationships between sentences and also phenomena that cut across sentences that we want to think about. then by this force here. Oh, the , the screen quality is not good. Oh, ,  by discourse here. ,  a passage on some topic. And  we can talk about some basic distinctions  the difference between a monologue versus a dialogue. in a monologue, there's a 1 way flow of information and communication  currently what's happening is a monologue, because I'm just saying things at you, and hopefully you're absorbing it. On the other hand, there could also be dialogues which involve multiple participants. And then there are additional interesting phenomena there that we could analyze or to get create a model of  turn taking , when is it that? You're allowed to cut in and say something. , when is it the end of a turn of one discourse participant, and then another?",
    "One will start talking also in dialogue there are more diverse sets of communicative acts,  there can be more instances of asking and answering questions, making corrections to what other people said, negotiating disagreements, and  forth. there are additional phenomena there to think about as . for our purposes we won't have time to get into all that, but we will try to cover some basic distinctions. one basic distinction, one basic concept when modeling discourse is this idea of coherence. Coherence is What makes a discourse a discourse  . The fact that there are relations between different sentences or utterances. In a discourse , that type, the relation that logical relation between them. That's what makes a discourse coherence. , there's some logical structure in, or in the meaning of a of a whole passage, and  then And that can be analyzed. , , here is a coherence. 2 sentence passage, indoor climbing is a good form of exercise. It gives you a whole body workout. and that's coherent, because the 2 sentences have something to do with each other. and you can even define a set of relations. They're called discourse relations between clauses and sentences and passages. here the second sentence is some  explanation for the 1st sentence, ? the 1st sentence claims indoor climbing is a good form of exercise, and the second sentence is an explanation of , why is it a good form of exercise. And  there exists data sets out there where passages have been broken down into these chunks of discourse called elementary discourse units, and then people have also come up with different schemes to annotate or different kinds of relations between these edus, between these chunks. explanation is one of those relations. It can be  cause as . It can just be a list. There are a whole bunch of relations people have come up with. and we can contrast this against. Here is another 2 sentence discourse that is not coherence. Indoor climbing is a good form of exercise. Rabbits are cute and fluffy. There's no clear relationship between the 2 sentences. one of the ways in which we can computationally estimate whether a passage is coherent or not is to check if there are devices that link, or there are linguistic devices that link together different parts of sentences. And  the use of these linguistic devices to tie together text units is known as cohesion. it's important to understand that there's a difference between coherence and cohesion.",
    "Coherence is defined at the level of, say, meaning at the level of  these logical relationships between sentences or smaller chunks, whereas cohesion is  the observable mechanisms that you can identify that link together these chunks of text. even within the very simple,  2 sentence example, here. There are some cohesive devices  here, indoor climbing. And it's that's a that's a there's. There's a link there, ? It refers to indoor climbing. and also,  exercise and workout. They're related to each other. Those words are highly related to each other. whereas in the incoherent passage there's nothing really . There's no clear link that we can observe, even in terms of  the linguistic devices that are used. And the this, this passage is also incoherent. ,  here is a passage from a news article that I extracted a few years ago about some Liberal government proposing new regulations to ban the random stopping of citizens by police and whatever. we can think about what are some cohesive devices, some links between elements of this passage? What are some ways in which the sent these 3 sentences contain some  links in between them? , , see here, citizens and citizen. Fairly similarities in the embeddings between. Can we compare the similarities and embeddings between each sentence? That's a great idea, too. that is not directly observable from the words. they occur together  coherents and cohesion. The other sentences, then, could be what was mandate. , sir, thank you, guys. If you have coherent passages, will you always find cohesive devices between them? I'd say most of the time. but it might be that you can very carefully think about it and construct some cases where you can't identify anything obvious. But I'd say that in naturally occurring tests, almost certainly. , you'll find cohesive links between. But  the reverse, though, is  not true. You can have  passages with lots of cohesive links.",
    "But then it makes no sense  logically, I'm sure we've all read things  that. And  we've all written things  that ourselves. you've identified some of  the key features that are used in the field to model coherence by using these cohesive devices. ,  one was a lexical cohesion. related words in a passage. we talked about words that directly overlap. But you can also just have words that are similar to each other. are related to each other with, , say, high cosine similarity. , , citizen and government are arguably part of the same chain, because they're highly related to each other, , and also regulations and rules, even though they're not directly synonyms. They're highly related, and also ban, and also  stopping and stop and stop and  walk as  as  an antonym of stop. These are examples of lexical chains. And that's what we're going to talk about more today. lexical chains is just about relatedness. And you can compute that using,  their word vectors, or something co-reference chains, or are about the direct directly pointing to the same real world entity. here new regulations and new rules they are. They're co-reference in the sense that the new rules are exactly the new regulations that were mentioned in the previous sentence. And then police and police officers,  an officer's here. You can say they're part of the same co-reference chains. , arguably, you could , you can  argue that the 1st occurrence here of police is about the general organization or whatever. And here police officers is about specific individuals. But let's set that aside  you can always argue those nuances, but we can say that they're they're likely to be co-reference. And also here, citizens, citizens, a citizen, and then they that could be argued to be a co-reference chain. they're pointing the same hypothetical citizens. these are called anaphoric devices. But Anaphore means something where you have a word, and its interpretation depends on something else in the passage. The interpretation of they depends on  the fact that it co-refers with citizen. Oh, here's another one there's although there. There are also discourse markers that we use to help structure a passage. And  these discourse markers help us explicitly mark what are the discourse relations between different parts of that discourse. the ones that I see here are the also, and  also usually means that,  there is a additional elaboration that is somehow related to what was said before.",
    "officers must also inform a citizen    they have it adds one requirement, and then it adds another requirement. and similar with similar to. And there might be some other ones where you're drawing, creating, and drawing a contrast  by contrast, or in contrast, or but or yet . those are some discourse markers that help indicate that there's some contrast, and that what comes after is different from what comes before. Or  it's different from expectations. And a lot of these discourse markers have. They tend to mark whether something that's happening or being described. conforms with  typical expectations about how these situations tend to play out, or whether they are in conflict with typical expectations. ,  that was a high, level introduction of discourse and some of the basic notions and discourse. we're going to zoom in a bit and focus on one particular phenomenon and issue in discourse, because we can't cover everything. and that has to do with co-reference. first, st let's take a step back and think about what the term co-reference means and how it's related to  a reference and  forth. remember when we 1st started talking about semantics. we talked about  a form versus content or sense versus reference. And this is   that  thing. , the main idea is, there is some  dichotomy or opposition between language  things that you can . speak or say, or write down and hear, and  see and read, and  forth. versus  things in the world, or in some hypothetical world that they point to which is at in some  more, at some  more abstract level. the 1st thing the former. it's usually denoted with, , with  form. It's it's you call that form in our current setting. Specifically, we're gonna talk about referring expressions. these are things in language that will point to something else. in this, in the literature, on core reference resolution, you can call them referring expressions. or they're also called mentions just for short. there are things in language. And then the thing that it  points to either . usually, some are some, some   mental or mental abstraction of that thing in the world. That would be the reference. that would be the content.",
    "then, there's this, this relation, then, between the referring expressions and the reference and that pointing process, the thing that links the 2 of them. That is, reference, the phenomenon of reference. the fact that you have something in language, and it points to something abstract, which is a mental representation of that entity in the world and the link between them. the link between them is called reference. ,  it's really hard to model this. We try to do this a bit with  the module and semantics, ? But it's hard to model this and do this  for impractical settings, because, . we all  have different mental representations of things that are going on in the world. there's it's not , there's a agreed upon standardized format, for what content should look  and what  the and how to structure the reference. it's quite difficult to do. But we all seem to do it in our minds. But to turn it into a computational problem. One thing that you could do that is still useful. which is not exactly about reference is to think about co-reference. Co-reference is when you have multiple mentions or referring expressions that all points to the same thing in the world. ,  here in this example, I have that cat or whiskers, or something furry, or it. and they all point to the same cat. They're just referring to the same cat with  different linguistic expressions. And  then these linguistic expressions are said to co-refer. And  that's the phenomenon of co-reference. this is  a practical tasks that you might want to solve in its own . But also it's convenient, because  we don't have to create an explicit representation of  the content which is really difficult to do , because  we're just reasoning about different spans and language. And  then, we can solve this co-reference problem. Without needing to posit what the mental, these mental abstractions of  entities in the world should look what form they should take. ,  ,  then there are other related terms. that cat is Maru, the cat. I hope it's still alive. ,  this is a cat. And then it's a anaphor. Maru is a male Scottish straight cat in Japan who has become popular on Youtube, his owner is rarely seen in the videos.",
    "then, this phenomenon, where one linguistic expressions interpretation depends on another linguistic expression. This is called an anaphore. This is just another term. here, just to be clear, Maru and his are co-reference, because they point to the same entity in the real world, and his is an anaphore. because the interpretation of his depends on the interpretation of something else in the passage. And  this phenomenon is called Anephra. The fact that linguistic expressions their interpretation depends on other linguistic expressions. And here Maru is called the antecedent. because it's something that happened that came before, and the interpretation of his depends on something that came before. There's also this term of Cataphore, and these are anaphores that point to cats. , , when he's grumpy whiskers refuses to eat. ,  here, because he is a cat, whiskers is a cat. this is called a cataphor. But the term is real, though. But , I'm glad you caught me. this  you have a module, for  a real world knowledge in your mind. , a cataphor is just a term where there's something that points to an antecedent that follows it. It's just the reason is wrong. It's not because Whiskers is a cat. It's because whiskers comes later in the sentence. But how was my deadpan delivery? I'm working on that good, excellent. Here are the types of referring expressions that you might encounter. you can have,  a proper names or a  referring expression  Mcgill University points to something . It points to either the abstract notion of this entity of a university, or  to the physical location whiskers is a name that points to ,  some cat. And then Montreal  points to the city. And  proper names they're all different kind. They're all these are referring expressions. This is one  referring expression. Pronouns are also referring expressions, a lot of the time , if I say I that points to  the speaker.",
    "You can also have possessives. But these are also referring expressions. there points to  a group of people. 3rd person noun phrases can be referring expressions  it can be indefinite  some water, a deer. and or it can be definite,  the cat or the election. , this is ambiguous in English,  this can either be a demonstrative which is  a which says that you're you're you're  indicating,  a location relative to the speaker and the listener. Or it can just be  a indefinite article that this random dude is just introducing a new random dude to the discourse context. And this notion of pointing to is different from the other notion of pointing to. I've been talking about  far. we have at least 3 notions of pointing to discuss  far in this lecture. The 1st is the relation between a referring expression and its reference. The second is between 2 different mentions in the passage. and then here, when I say point to I  some relation between the speaker and the listener when you're presenting an entity. These are all different from each other. just, I always  to  motivate things, not just using English examples, but also using other languages that you may speak. There are other phenomena that appear at different levels of frequencies across languages. one of these is one of this is called 0 Anafera, and this is interesting. many languages allow you to omit pronouns in certain contexts. and they're often called pro drop languages. ,  pro over pronoun and then dropping them. And  this creates an interesting computational task, because that means that  you need to . in English, when you have pronouns, and it's clear, you have to figure out what they point to. That could be a task. But in these languages you have an additional step before that which is to figure out when a pronoun has been dropped. cause you need to figure that out before you then figure out  what they point to ? , does anyone speak Spanish here? Cool or Italian or Russian, or many other languages? in this 1st class of prodrop languages. You're allowed to drop the pronoun, but then there's usually morphology to indicate what the dropped pronoun was. in this example from Spanish.",
    "I don't speak Spanish, but oh, that's also the example sentence,  it says, not speak Spanish. here  that the pronoun that was dropped, was I? Because it's indicated by morphology on the verb. because aglo here is  1st person singular for a speak. Italian also works this way, and Russian and others. But, unfortunately for in terms of examples, English doesn't work this way, and French doesn't work this way. if you only speak English and or French. You you'll just have to  trust me, . But there are other languages where you drop even more, and you can't really tell from the morphology. you just have to figure it out based on context. Japanese is  on the more extreme scale of this. There's a sentence in Japanese, and it just means  somebody loves somebody. it's  I love you, because when you say that to somebody, then obviously based on context, you can interpret and figure out who the subject and objects are. But  there are other contexts where It might be different. , if you add a question marker  I still didn't know. you're asking, do you love me? But then you don't have to say the I or the U, you just figure it out using context. Japanese is  this, Korean is  this. Chinese is  this to a lesser extent. I know you said they don't really belong. But there could be sentences . and can't do that  sometimes you don't use the eye or can't do  people would be able to interpret that as. , , that's a good point. this is what I was trying to get at with the last point here, which is that occasionally this happens in English, too. it's just much less common and much less systematized. But , but we also use context to figure out what was dropped. the example that was given was , Oh, I can't do that, or something  that, ? Or here I had attended a dope. There's more there, there's more I won't be exhaustive in all the different reference and co-reference phenomena. But here's another cool one which is bridging reference.",
    "which is that you can refer to entities that are not directly introduced, but that you can figure out based on background knowledge. it's a similar issue to  the previous phenomenon. here it's , you figure out, based on context, what's happening. And here you're also using context and world knowledge to figure out what's happening. the example is, I  my office. The windows are large, and the table is made of mahogany. , here the bridging reference is between windows and table versus office. the fact that we understand what an office usually looks  means that we can just say office. And then that implicitly introduces all of these other things  windows and tables, and  pens and pencils and chairs, and  forth. then you can refer to them using a definite article, because usually definite articles is about things that already introducing the discourse. here, there's no explicit introduction. But we still say it's  because of our expectations about the world. This one, the second example, is a bit trickier to understand. here it's you should get a cactus they are easy to care for. there's  a bridging reference here as . because in the 1st case, when you say you should get a cactus, it's introducing,  some cactus that is out there. it already exists in the world as a cactus that you can go to the store to buy. whereas in the second sentence, when you say they, you're talking about cactus as a class. technically, that's not the same thing. technically, they're not for reference, because the 1st instance is about a specific indefinite. not specific is about some cactus that's indefinite, that's out there. And the second one is about the class. But there's it's clear that the second one is pointing to the class of cactus just because of the way the conversation is flowing. But what about, , in the 1st example, when this is used  to dramatic impact . The 2 chandeliers keep things bright, and it's , not an expected object. the question is, what if it's not really typical? The 2 chandeliers are amazing. And then you don't usually have  chandeliers in offices. that's , although that's slightly against the usual expectations,  it still counts as bridging reference, and it's still a related phenomenon. what happens when you say something  that?",
    "Is that the you're forcing the listener to accommodate to what you say,  that they can infer that in that office there were 2 chandeliers, because otherwise, , the passage doesn't make any sense. , that's a good point. It's , it's slightly different, because it goes slightly against expectations. But it's still fitting the expectation that offices have lighting fixtures. And and just also to point out that not all pronouns are referential. there's something called pleognastic pronouns which are common in English and French. which is where you say something  it is raining or snap out of it. what is the it here? It's not referring to anything. , you can make up something  it is referring to,  the sky, or whatever, or higher power, or a snap out of it. You're snapping out of what  out of  your. your mental state, or something. But but usually these are analyzed as not being referential, and in English. in French, too, there are constructions where you can use to place focus or emphasis on certain parts of the sentence. You and they usually involve pronouns  it is comp. 5, 50, which is giving me headaches. and it's not clear if it is  referential , does it refer to comp. 550, or is it just some  generic it? And  there are debates about that in linguistics. And then moving beyond nouns, things get a lot more difficult once he gets to events. because you can also talk about co-reference of events  here we have Hewlett Packard is negotiating to buy some company. it could use its own stock to finance the purchase. If the deal is completed, it would be HP's biggest acquisition, since it's bought compact. Whatever in 2,002.  here all of these verbs and also nouns. Oh,  only the 1st one is a verb, the rest are nouns. These are all referring to the same events of  a company acquisition. whereas the second bot refers to a difference. event, co-reference, resolution is also an interesting task that people work on. but it's it's much trickier to define, because it turns out that you can There are lots of  unclear cases, of whether 2 events are  the same event, even in terms of the analysis, not just in terms of the resolution. And  it's a tricky problem.",
    "how do you even define it? One definition is that they happen in the same time at the same place. But I won't talk more about this. this is just too much detail. instead, I will focus on the a restricted  co-reference resolution for the rest of the lecture, which is phenomenal. just what does this mean? That those are some big words  pronominal just means. And Anafra resolution means that you're determining the antecedents of pronouns. ,  the task is given a pronoun figure out what it points to and previously in the text. And here are some basic algorithms for this using heuristics  that we can figure out what are the relevant linguistic cues and features that we might want to condition on. And I'll only introduce one of them. Hobbes Algorithm,  the very early work from the 19 seventies. And then we can talk about machine learning approaches that try to implement the same intuition idea. But in a more statistical context. , with state of the art approaches to this task currently be  foundation wells or large banks. the question is, would state of the art models with the  large language models are fine tuned. But , but let's look, look. let's look back 1st to see what are some of the relevant cues and how they are incorporated or not in more recent systems. ,  let's go back to the example from before Maru is a male Scottish straight cat. His owner is rarely seen in the videos. what are some of the relevant cues? one relevant cue is number and gender. ,  1st of all, what? what is pronounal and afro resolution. here the pronoun that we might be interested in is his. His is a pronoun, and we have to figure out what it points to. obviously, it points to Maru. How do we know that? How do we get the system to know that? , , , why doesn't his point to Youtube.",
    "Or why doesn't his point to Japan? , one import, one relevant queue has to do with  number and gender. , , in English, we have at least 2 to 3,  3 grammatical genders. there's  masculine, feminine and  neutral. And  there are more and you don't typically refer to countries or to  Youtube with as a math with a masculine pronoun. They're not considered masculine entities. it's a proper name, and  it's  a Japanese name. then it's hard for us to tell. But , Maru, I don't know. it's more coded as being associated with  a masculine pronoun versus a feminine one. that's 1 queue, and but then, at least we know that it matches because Maru is suggest that this is singular and his is also singular. that's that's a match in terms of number. A second cue that can be useful is recency. Just because of the nature of how communication goes. We tend to refer to things multiple times. , if we're going to refer to something multiple times, we tend to do  in bursts, and they tend to all happen close to each other. and you it would not be usual to , refer to, present something and then not talk about it for a while, and then  refer to it again suddenly with his. It tends to be very recent. recency is also a strong cue for predominal co-reference resolution. and finally, it turns out that the syntactic role,  the syntactic information, is also useful in different ways, and you can use that to help figure out and resolve this problem, and that's a strong signal as . let me expand a little bit more on that. It turns out that there are certain kinds of distributions for different kinds of pronouns. for where they're allowed to occur syntactically. , , if we have, the students taught themselves here themselves co-refers with the students. themselves is the students, whereas, if you say the students taught them here, them cannot co-refer with the students. there has to be some other group of people. And  this is because of how reflexives work. these are called reflexive pronouns,  when you ever have,  a self there a selves. and there, and there's a certain syntactic relation called C command, such that , when you have reflexive pronouns, they have to be C. Commanded by their antecedents, whereas,  regular personal pronouns without the cells. cannot be bound in this way.",
    "And  there's this is formalized in a theory, in linguistics by Chomsky, called binding theory. And , then, this is one example of how syntactic heuristics is useful for helping to resolve and rule out certain kinds of resolutions. But there are also other softer general tendencies about you tend to refer to things in  the subject position of the previous sentence, and  forth. ,  then, Hobbes algorithm from the seventies is a heuristic algorithm that puts together all of these cues and comes up with a method for co-reference resolution based on that. this is a traversal algorithm where you do a tree traversal  over multiple trees. And what it requires is that it requires constituent parse trees of the sentences in the discourse. and it also requires a morphological analyzer for the number and gender that's expected of entities. And the algorithm itself is  quite complex, with quite a bit of detail at a high level. What it does is that it searches the current sentence where you find the pronoun  to left, starting at the pronoun to try to find an antecedent that matches in terms of number and gender using the syntax tree. and if no antecedent is found. then it searches the previous sentences left to . In order to find a noun phrase that matches. Why does the direction go left to . the direction matters and  to left and left to  is a simplification. Really, it's about tree traversal. The order in which nodes in the in the syntax tree are searched. but  that in the current sentence. To find  say the subject of the sentence of the current sentence. But then, if you can't find something that matches. I mentioned that there are these soft cues about how you tend to refer to the subject of the previous sentence. that's a pattern that people have found. And  in English the subject comes before the object. and  then left to  works for English. it's just based on how also, there's a tendency in language to place known information before new information. , there's some  topic, comment, structure and pronouns tend to refer to the current topic because you don't when you  , when you have new information, and you have to introduce a new entity. Usually you have to say what the entity is, and  you use some  indefinite expression  it's a cake, or a pop quiz, or whatever. then, that's  a new entity, and you have to say what it is. Whereas if it's an old entity that has been shared across a longer span in the discourse, then that tends to be the topic. And  when you have a pronoun, it's more likely you're pointing to the topic than to  a new entity. here's the algorithm in a bit more detail.",
    "this is from,  the second edition of the Drafsky textbook. It's not that useful to go through the details of it, but  it sets up this way where you draw a syntax tree in a very particular style, with a particular style. and then it sets up  that it respects all the constraints from binding theory. that if it's reflexive or not reflexive, certain things happen. And it does this  traversal in this in this in order that we just described. But I'm not gonna go through each of the steps in detail, because it's not. it doesn't really add much to our discussion. , but we can  roughly go through and see how I get a flavor of how this algorithm might work. here we have 3 sentences. Alice saw a beautiful cupcake in the patisserie window. She showed it to Bob, and she devoured it  how Hobbes algorithm would work. Oh, there's a chat message for real. Alice saw a beautiful cupcake in the petty screen window. She showed it to Bob. How would this resolution work? Don't you guys know that cats rule the world? ,  this could be tricky. But  if I can do some  parse. , I'll just do a  a very rough parse. That's  it's not very syntactically correct, but here,  it would be devoured it. It is a noun phrase. and then she is  a noun ,  a noun phrase, and then,  it looks something  that ? And then showed it to Bob. this is  roughly the structure. and then the Pacific city window. , here we have a ambiguity  does in the patisserie window attached to a beautiful cupcake, or does it attach to saw. I'm just gonna make it a ternary node. I'm not sure if this is correct. ,  this is roughly the structure. And there are also a bunch of noun phrases here.",
    "can you guys identify noun phrases by ,  Alice is a noun phrase, a beautiful cupcake is a noun phrase. a beautiful cupcake in the Patchesserie windows. A noun phrase the Patricia windows a noun phrase she and it and Bob, those are noun phrases. ,  then the question is, what are we trying to resolve? some of the pronouns would be  she. ,  let's do she first.st ? the high level idea of Hobbes algorithm is, first, st you search within the current sentence  to left, but there's nothing to the left of she in the current sentence. then you would search the  sentence left to . and you would do some   traversal, and then you would find Alice. and you would see that Alice and she matches in terms of number and gender. And  then in this way the algorithm would resolve, she to Alice. , that's a great question. Do you take the 1st match or the best match? with Hobbes algorithm, you take the 1st match because they tried to design it  that you encounter the best match first.st But it's obviously not perfect. Another one would be, say another pronoun would be it. If you go through the algorithm, it will 1st propose she as  a potential antecedents. But then she and it obviously don't match in gender,  would be rejected as a candidate. and afterwards you would go to the previous sentence, and you would search. It's left to  in a tree traversal sense. But Alice also doesn't match in terms of gender. then the  noun phrase that we propose would be a beautiful cupcake in the patisserie window. and that one would match its in number and gender. And  then it ends up, being resolved to that node which corresponds to a beautiful cupcake in the patisserie window. Understand why it's gonna resolve the whole thing when we have 2 noun phrases that we have a beautiful cupcake and the magistrate window. why does it choose the whole? the question is, why does it choose the whole noun phrase, and not just a beautiful cupcake, or just the Pit Street window. it's because I simplified, I said, left to . But it's  really a tree traversal. then it would encounter the noun phrase node first.st Oh,  I put the arrow with the wrong stopping point, as I hear. it then, according to this algorithm, resolves to a beautiful cupcake in the pedestry window.",
    "They point to the it's just from the perspective of, ,  a machine. Since a beautiful cupcake is a noun phrase, but it's true, and there was a noun phrase, which one is it referring to ? I know that it's a beautiful cupcake. but  which exactly is Oh,  I may. I made a miss, did I make a mistake? here there's an there's an np node here. my, I wasn't super clear in my parse. let me try to  fix this. , let me try to make it a bit clearer. , I could put it  this. And then  if this was the parse, then it would work. then it would encounter this noun phrase first.st  with this algorithm, then, it would not ever propose a beautiful cupcake or the patisserie window on their own. then, since it encounters the 1st noun phrase that it does that matches a number and gender. But then  a sentence where it's  one word. And then,  a huge noun phrase. proceedings that could lead to problems later on. Because it just collects  everything in the second. ,  what you're suggesting is that there could be some cases where this heuristic fails, and there certainly are. But this is just  the to illustrate the some of how some of those queues are integrated into a simple algorithm. And then, later on, we'll look at machine learning algorithms that might be able to do a better job and resolution. And , the other examples are similar. and it does the same thing. There's nothing in the current sentence before it. it looks at the previous sentence, and the 1st noun phrase it encounters, which matches is the other. She  then it'll this, she will point to that she which will point to Alice. and finally, we have its and it's the same thing. in the current sentence, there's nothing. and , it'll propose she, but it doesn't match. Then they'll propose this, she in the second sentence, and it doesn't match as . And then the  noun phrase it encounters.",
    "And it matches it in number and gender. then this it will point to that. And  for this simple example, this approach works. Question what would the average accuracy of this be? It would not be that great, . first, st you have to define the evaluation metric, and you can do that. There are different ways to do that. But you can expect,  the proportion of times to get this rate to be   60%, 50, 60%. But this is my rough estimate. People have done actual studies. And you can look up numbers. these days, people tend to solve co-reference resolution using some statistical approach with a machine learning method. And one common way to decompose the task is to break it down into 2 subproblems. and then solve each of those problems separately before recombining the outputs of each of those modules. , , once a task is to do mention detection, which is just to figure out which spans of text are mentions  are referring expressions, and which are anaphoric. And this could be a separate step, or it could be  one step within an integrated end to end system. And then the second step is to  create those links to do the actual reference focal reference resolution. that we're getting towards the end of the course. you should start to have some intuitions about how you might cast this as a machine learning problem and solve them. any ideas for how you might solve these set these up as  machine learning tasks that you could  train a system to solve. How might you  cast that as a machine learning problem and solve it? the task of the , , let me just clarify what mentioned detection is in case it's not clear. here it would be to find all the mentions. Alice is a mention, a beautiful cupcake in the pit. a beautiful cupcake is also mentioned, and the pit 3 windows a mention she is a mention. It is a mention Bob is mentioned. any idea how you might do that? Yes, yes, it could be a fine-tuning approach. Can you be more specific? Or you can ask the input sensitive input and then you can add  an extra layer on the output.",
    "I'm not  sure how to design extra there, but  you could  it would output a probability there or something being mentioned or not. Then we could give it a data set where  mentioned. I've mentioned them find the ways to get better. Did did people hear that? it's  adding an extra layer on a neural network? And that layer has to output a probability? What's that probability of this being a mention. And you can fine tune on a labeled data set. We learn with hearse patterns. ,  that would mean that it would have to occur in the same  sentence. And then the other one would be  a co-reference matrix. And then you can go from there and Pmi scoring and all that to see, and then have more embedding stuff. And then course around that  a bigger. ,  you're mentioning hearse patterns and some  co-reference matrix. those could be relevant cues. I'm not sure exactly how to cast mention detection, as those  hearst patterns are usually about detecting relations between 2 noun phrases. But here we are trying to figure out which spans of text are mentions in the 1st place. But aren't you trying to get ? Which is a mention, and which one is a referring expression. instead of  hyper and hypo, they could be them soon. you're saying that Hearst patterns might give you  patterns that help you figure out co-reference links. ,  that's that makes sense. that would be more for the whole problem. it would be, it would not be for mentioned detection, it might be for the second step. Is it possible to define a loss function specific to those things  immunization for reference. Is it possible to define a loss function for these things? In fact, you have to, in order to be able to train some neural network to get better at this task. the  the question is , how will you define it? , yes,  would any sequence modeling framework work for this task. Yes, because if you think about it, you can cast.",
    "If you ignore the hierarchical structure of mentions. If you just cast it as  a chunking problem. Then it becomes a lot  ner in that you're chunking the words in your text into chunks that correspond to mentions. Yes,  you could do  Bio tagging scheme and then run any sequence model train on some labeled data to do mention detection. I'm , really work to use  a generative model,  a decoder where the input would be sequenced and the output would be  it generates all dimensions and stops. your suggestion is , just get a generative Llm. Give it a sentence and tell it to spit out all the mentions. In fact, that's something that people have done in the past year. , too bad you didn't think of that last year. written a paper on it. , just the bootstrapping method that we learned with the supervised algorithm, I know you generate a lot of data. , which you could put it, , with  a label, and then run the bootstrapping. , could you do a bootstrapping based approach? I can imagine that you could do it that way. that , I'm I'm glad to get all these responses, because  that,  the tools that we've discussed, they can apply to a new setting. And hopefully,  you're beginning to build some intuitions about which approaches to try when encountering a new problem in Nlp. And then for the co-reference resolution step. You can imagine going through a similar exercise. after mentioned detection, you have a passage. You've broken it down into a sequence of mentions. And then the co-reference resolution step could be to predict for which pairs of mentions. For  for a given pair of mentions whether they're likely to be correctant or not. And then you can pass in features that you think might be relevance. You can pass in  your just the words in the context. you can pass in the predicted gender, a number or anything else. And the and the syntactic structure surrounding those mentions and  forth. , the machine learning literature is implementing that. , it's , there have been a bunch of people who've tried different approaches and depending on  the time era. They tried whatever was available to them at that time in the machine learning landscape of the of the era. , , in the early 2 thousands soon at all to find some features for noun phrase, co-reference, resolution.",
    "And and then it's   what you might expect based on our discussions. some of the features are , . And   it's , some of them is , is this a pronoun or not. Some of them are , after discarding the determiners, the string denoting does the string match. this, since this is for noun phrases in general, and not just pronouns. If you have,  2 nouns that have,  the same words that use the same words. Then there, it's pretty likely that they're co-reference. There's  the predicted number and gender. Are they both proper nouns? There's something called positives, or whatever. They also attempt to use the structure of Wordnet, which we discussed, we discussed. and,  the they used, they encoded recency as . They looked at the distance in terms of the number of sentences between them. these are the kinds of things that you might expect. Then you can run this for reference. And they get  some reasonable score. They get  around 60 to 70 in terms of f, 1 more recently, in 2013, Durett and Klein trained a initial neural model or , a log linear model, but they have,  3 million features, and they use word level features, and they use some simple recency, heuristics and syntax. that work  found that the predicted gender and number features worked very . a lot of the heavy lifting is done by the predictor of number and gender. and then  to the neural approaches. In 2017, Lee et Al. Proposed this end-to-end system and that implements the ideas that you guys had as . they  learn train 2 functions. one function scores whether a certain span,  a span here is defined as  a sequence of contiguous words. whether a certain span is a mention or not, and they have,  one sub network in their neural network structure that predicts that. And then they have another function, another sub network they train that checks, whether span I and span J. Co-refer. whether span J is the antecedent of span I.  this could become very computationally expensive, because if you think about it  if you have  if you have a sequence of n words. how many possible spans are there, there's a quadratic number of possible spans, ? You have to pick in a starting word position, and you have to pick an ending word position. And  that means there's a quadratic number of them.",
    "just the fact that of that makes that even just computing the 1st function exhaustively is very expensive. but,  the saving grace here is that most mentions are short, ? you can make some assumptions and only compute that function, for, , say, spans of up to a certain size. or where  you do some initial syntactic parsing, and you restrict possible spans to, according to the syntax tree, or something  that. And  then you can have some heuristics to prune some of these options. you don't have to compute everything. And similarly, you there, once you have this. if there are quadratic number of spans, then the possible number of span pairs is  to the power of 4, , because it's n squared times. And  then again, you have to make some assumptions. you only consider a small number of possible pairs of spans as being potentially co-reference. , you mentioned 2 sub networks almost as if, , there are 2 parts of the network with 2 different outputs. And I'm wondering if they're  trained separately with separate loss function, or if they're unified into  one training process with one. ,  the question is, are these sub networks? Are they trained separately with different loss functions? Or are they all unified? the way that is set up in this model. It's  there's a shared set of parameters that encode some sequence. And then they have  different output heads. there's 1  output head which is for mention, scoring. for here there are different possible mentions,  General electric for this 1st head for this 1st outputs and then electric, said, these, this other outputs, and  forth. and then each of those you can score that, and then you can try. It gives you a score, for whether it's a mention or not, and you can do that, do supervised learning on this. And  there's a loss function there, and it influences the parameters of the encoder. And this is slightly older work. they use an Lstm encoder and then the co-reference resolution part. They they uses some shared parameters. then here is jointly trained, but it's the at the output step. It's  there's a separate output network for the co-reference score. then they have the span representations which is  shared. up to here it's shared up to the span representation.",
    "And then after that, they're the sub networks. They just they head towards different loss function computing computations. then, this one goes to  the objective for the mention scoring. And then here it goes to this separate thing which is  scoring the co-reference score. this is how this network works. And this gets  a much better performance. this ete model is quite highly performing  more recently than the more recent developments, as you would expect is to do something similar, but with  a transformer style, with  a pre trained large language model with  transformers. And here, in the recent literature there are 2 general kinds of models. The 1st one  follows in the footsteps of ete. , if you replace,  the Lstm part with  a transfer pre trained transformer. Then that's 1  model, and those are the encoder models. Those are encoder models because they encode the sequence, and then and then it frames  the other, the steps in the co-reference resolution. it's a classification to decide. Is this a mention, and to decide if these pairs of mentions are co-referent or not  intuitively at a high level, it's the same idea. Then the second class of new models that have been proposed is what was  mentioned earlier. these are decoder models that frames co-reference resolution as a sequence to sequence task. , , this was supposed to come later. ,  just as a comparison. one of my Phd students, Ian Parada compared encoder and decoder models. and we find that encoder models tend to be more efficient and perform better. If if you control for the size of the large language model that you use,  the pre-trained language model that you use . And if you do  the proper parameter. optimization, hyperparameter optimization of all that. But  the decoder models as , because  if they still have premise, they're interesting. here's a model from last year  Link, append. , what they do is they implement the proposal that we had from the class earlier, which is, you pass it a passage and then extracts a bunch of mentions, and it also extracts what these mentions point to previously in the context. and then the possible actions that it predicts are either a link or an append, or , or we're done processing the sentence. ,  let's take a look at the 1st action, which is append. And let's take a look at the overall setup. the overall setup is .",
    "1st you put in a sentence and then  the model predicts that here there's nothing. I don't see anything that Co refers to anything else previously. it predicts shift, which means, let's process the  sentence. and then you get the  sentence. and then here you already start to create a cluster. here it says that this I at token position 17 co-refers with this I at position at position 2. And  this is  a link action. But , this creates a cluster. And  then here with the 3rd sentence. then you pass in this updated context with 3 sentences. you pass in these 3 sentences, and you ask the model to extract all the clusters, the new clusters that it finds, and  forth. in the in its prediction. It predicts that you here of Speaker B. Co. Refers with the cluster with index, one which is,  the I from Speaker A, and  this append action is what you extract from that 1st initial prediction. , the  2 predictions by the model are link actions which create new clusters by clumping 2 spans together. then the model thinks that the apartment co-refers with your house, and it's a new cluster that it creates. And then, in the 3rd case, we have,  the one   to the apartment which co-refers with that fresh French restaurant by your house, and it creates, and it uses another link action to create another new cluster. and then it predicts the end of the sentence. then, you, you again pass in you, you update your what you've created  far in your in your context. And  you have  3 clusters. You have the I cluster and the U. Cluster with my cluster number one cluster number 2 for your house and the apartment and cluster number 3 for that fresh French restaurant by your house versus the one   to the apartment. and you incrementally process this until you reach the end of the discourse. this is how they set up the set it up as a sequence to sequence task. Oh, and shift means you're done processing the sentence all . that  gets us to the current state of the art in core reference resolution. , it reminded me of. We saw a model, that  predicted actions to do name and entity recognition with exact data structures. I'm wondering is that the same as  using a decoder to generate? Are they 2 different approaches?",
    ", that's a great point. how is this related to some of the previous work. We've seen the class about predicting  some actions for  parsing. It's inspired by the same idea. , they directly link this to that work, that type of work as . You can think of this as something  a transition based parser where you're predicting actions which create new substructures in the inputs. And  then the their particular way of creating this creating substructure is to either create a new cluster with link. or to add something new into a pre-existing cluster with append. And would it be done with the decoder? ,  this would be done with a decoder. here the input is, the encoder part. You pass it in, and that's your prompt. And then here the decoder it outputs the predictions. And  the numbers here are higher in modern per reference resolution systems. you can look at some of these papers, I would say, ,  it's  again, I didn't define the accuracy, the evaluation metric formally, but they're usually in  the eighties, or  around 90 or something  that. , that's it for this class. unless you have more questions."
]