{
    "Topic 1": [
        "That's the most flexible. which is. . . It's the study of meaning as they relate to the lexicon. . And then there are multiple words that can realize that sense. and word sense. Disambiguation, is the task of figuring out which word sense is expressed in a particular context. this sense is meant to indicate the physical hand. . And then, . really. But really you can imagine a version of this task which is called all words word census ambiguation, where you try to do make all of these decisions together. Jointly. And it's possible. . I'm going to go through some algorithms again, not state of the art algorithms. the 1st algorithm is called Lusk's algorithm. and this is definitely possible. But the downsides are pretty important there. And in particular, in this in this formulation of Wsd, I'm going to start saying Wsd, , instead of word science, disambiguation that would mean that. And  we're going to introduce a new idea there using this simple algorithm called Yarowski's algorithm. ? But first, st let's look at Lusk's algorithm. and then for each candidate sense Si of the word W. You calculate a signature of the sense by taking all of the words in the dictionary definition of Si. It'll be much clearer once you. We look in an example as usual, but the high level idea is each sense can be represented by its dictionary definition. and maybe the riverbank can be closed to the public. ? B, ,  the and high level idea is, take all of the context. and then you put, and then you find overlaps between that and B, and likewise for the other one, and you figure out which sense has a higher amount of overlap, and then you pick that one. And  each of them is a slightly different algorithm. There are all sorts of things you can do, and they each yield a slightly different algorithm. But the general high level idea remains the same. . . . That's  a very obvious initial choice. . But you can definitely check that the algorithm yourself. ? you can check this yourself. . ? . That seems to me to be a reasonable thing to try, because if something overlaps multiple times, maybe it's more important. ? this idea of  lemmatizing and counting lemmetized Lemma overlap is, is  implementing that idea. if you can go further  back we have. And . . . ? And algorithm number 2, we're going to introduce an idea called bootstrapping. I think this is a really cool idea. and that's  the idea of bootstrapping as  in general. bootstrapping appears in multiple contexts in machine learning and lp,  don't get confused between them. the sense that we're going to use today is that you're going to use some weak signal to train a weak model. and then the model is going to pull itself up by its bootstraps by using the weak signal to iteratively improve itself. . ,  here is the idea behind Yayrowski's algorithm. . Then, here you need to do something first, st which is to give it. then you repeat the following process, you train a supervised learning algorithm from the seed set. ,  let's look an example and go through the process to make sure this makes sense. let's look at our data first, st to understand what is are the possible senses. we can have the company set. here it means that plant is  some  factory ? The second sentence is, although thousands of plant and animal species. ? for the life form he picks the word life and for the factory you picked the word manufacturing. ? then, all of these cases are sense a, with  the living being plant. And all of these contacts have a sense B, because it's manufacturing plant. Is there some , or is it. the question is, to clarify, are these words life and manufacturing? you do need some  initial data. The words being used are live and manufacturing are those derived from life, form and factory or . How are the words life and manufacturing selected? Are they derived from life, form, and factory? the seed word is life in manufacturing yes, that's . The seed words here are life in manufacturing. . ? The  step is to train a classifier. you train something called a decision list classifier, which we didn't cover in detail in this class. You just need to train some  classifier. You could also train a logistic regression model. You can train whatever you'd . just train something as there are 2 requirements. ? you just need some  score to tell you how confident the classifier is. ? the reason this is really clever is that by this process lets you discover other words that co-locate  that are found near each of these senses. ,  1st of all, as you would expect all of the samples that involve the original words. Life in manufacturing should have very high confidence, according to this new classifier that we trained  because that was the cue we used to create those sets. But what is more interesting is that the classifier finds other words that co-locate with each sense. this classifier found out the word animal. then it's likely to be of sense a which makes a lot of sense, ? Because that was the life form sense. and that there are also direct diagrams that it finds that correlates with each sense. And this is great, because that means this new classifier is  useful, even for new samples that don't contain the original seed words of life and manufacturing. this classifier gives you some interpretable features that says that,  animal within certain number of words is one of the criteria, with a locked likelihood for classifying something into one sense versus the other. But, for example, in logistic regression, we wouldn't have that. . . But but you don't have to do it if you just are run, if you're just running the algorithm. . and then. . . I would say that no, because you have to add something to change the model   after one round, you have to add some new samples in order to get the  iterations model to be different from the previous iterations. That you're . this. That's . I would. in Jarofsky's algorithm. I think it's possible to define some algorithm where you look at you have more history. that's possible. But in Yaroski's algorithm they only look at the current round. and also remember, in our setting we don't have any correct answers. We don't  have any correct answers while running bootstrapping  . We don't do any annotations in the middle of an iteration to annotate for the correctness of the samples. This. . ? No? something  that. we're, only we might be inspired by it to pick our initial seed words. ? And . ? that's that was pretty impressive because it didn't need a lot of human intervention. It just needed,  one seed word per sense per word. And you're asking showed that through this bootstrapping process that was not necessary. that was very nice. . I would say that sometimes people propose this type of approach, and they call it unsupervised because it doesn't need this huge labeled corpus. if you have. If your definition of supervised is, you need a huge labeled Corpus, then this is unsupervised. then, in that sense, it's it's slightly supervised. . Whereas in that definition, unsupervised, would really be something  clustering. . By the way. . ? a rabbit, is a mammal, remember which one that was. . . ? , ? Oh, gosh! And the string instruments! including me, before I started teaching this course, probably didn't know what a Bambara and Dang is. and the bombarandang is the hypono. you don't have to , just sit down and think really hard about what are hyponyms and hypernyms of certain senses of words. Because you can use a corpus based approach to help you expand that. . ? maybe here's a quick exercise we can do together. . You can. this one. this one. Yes, hypo app out here. . . . ? ? Cool. . curse was just really smart. . who were there, and what? ? What you can do is you can have an initial seed set of words. But , and then you go into a corpus. You have an initial seed set, which is some  cheap. semi-automatic way of labeling data. I can believe it's totally possible to combine the 2 of them together. But it's just a different thing that makes sense. It's not a major part of this course. We we can. ,  the question was, what we already have these words  such as or including, and especially , why do we need to go through this process of training a classifier doing anything else. There. but we have no clue, and we have no guarantee or clue that the set of patterns is comprehensive. I might miss a lot of other pairs of nouns in that relation. it's  to do a better job than using  a static lists of patents. then, np, which is the cause, causes the Np. But then, by using that as  your seed pattern. . . By that do you mean  the smallest seed set or something? . ? . You can use that to train initial classifier. . And then you put it back. which is different from what we're talking about, which the other sample I remember it being used in machine learning as , yes,  . The other sense of bootstrapping is also used in machine learning for statistical testing. . . that's because there's a difference between the different lexical, semantic relations which change how they affect, how words appear near those words. ? We have extinct birds, such as dodos, moas, and elephant birds. . ? we here the we have. the context should be similar. ? . , is this  similar on, , I guess, slide 18. But you don't have any text there in terms of how we're using the context of 2 words and then looking at stop gap and boss? ,  you're using the context. And this idea is really powerful. ? . in a different, in a slightly different way. and then, for each word, you keep account of all of the words that appear in its context within some context window of here, let's say arbitrarily, 5 words. . either it's in the target position. And  what you end up with is something called a term context matrix. position of the ordering of the words in the context. Is there any way to incorporate the position of the and the ordering of the words? you could define your notion of context differently. Is there a reason why we're including software? Is there a reason why we're including stop words? . Is this gonna be a square matrix that's very sparse. They only keep the  the . , , the column, vector, you can consider the vector representation, the context that's . The column vector is you can consider it as the representation of a word as a context word, . And then in the back. other main targets on complex one. But, as was pointed out, this can get very expensive  often. and then they keep,  the top K. That they can afford. and then they only count words that are in the context and that fit that are within that context. That's . . . and the most common function that people computes to compare the meanings of 2 words is by computing their cosine similarity. 2 rows in this matrix. . . ? But it turns out that things are in practice some a bit more complicated than that. And the issue is that cosine similarity and word co-occurrent,  similarity of context in general. give you a lot more than synonymy. Course. But there are others. , for example, antonyms also turns out to often share similar contexts. Similarity in this sense is specifically about taxonomic relations. abstractly, similarity is only about taxonomic categorizations and hierarchies, whereas relatedness includes anything that might be associated in some more general sense. But they're not similar, because the kinds of things that are good and bad are very different from each other in any particular context. they could have high cosine similarity for any reason. ? Matrix. Maybe  comparing figure and 19 fifties where the vectors are just , there's nothing really related. . We will return to this in  10 slides or . Yes, but it  presupposes that you already have your taxonomic tree. . Whereas that approach you already have that. , we should move on. Because it turns out that, , you can think of this high dimensional space where all of these word vectors live as a vector space. And I'm not sure there is  a really great way to do this. And then we can critique this if we'd . ? ? I don't necessarily mean taxonomic similarity. And then you can tell me why I'm skeptical about this. ? I think their data set had 353 words. Hence the name. And then you can do a correlation. . . . the average is  over the different annotators that definitely makes sense. , that's . That by considering the most similar sense that they can think of. ,  word embeddings are these trained vector space representations of words to predict words in context. These days you might not consider that deep learning really, took over Nlp and show this promise, and everyone was really excited about it. You have a target word vector which is  the row vector in the term context matrix. researchers, I think Omar Levi showed that the skip ground model in particular, is  equivalent to a version of the count based model, where you apply a singular value decomposition to that. there's  these matrix compression matrix factorization algorithms that you can run in order to compress the matrices and try to preserve information in the matrix. And you can show mathematically that one version of the word 2 Vec model is equivalent to one version of the matrix factorization algorithm which I thought was a really cool result, because on the surface they seem to work very differently. ? One method seems to be about  creating this neural network architecture to predict words in context. the other is about counting words and then running some -known matrix factorization algorithm to compress that to , to compress that in order to extract some statistical information. And it turns out they're doing the same thing. that was a surprising and cool result. it turns out that thinking about things in terms of  a neural network. it exposed a lot of other hyperparameter decisions. And it was a lot more flexible. Whereas thinking about things in terms of matrix factorization, those tweaks were not obvious in the matrix factorization setup. , there were lots of things that you would have to do in the during the factorization and compression process to achieve the same high level of performance as with the Skipgram based approach. , , , I thought that was a really interesting historical , not,  historical, not historical, . but for others  synonymy and autonomy. then you cannot do that. ."
    ],
    "Topic 2": [
        "It's usually the cost center. something in our mind that holds words and their meanings, and also maybe their characteristics and behaviors. We started talking about wordsense, disambiguation. there's they have funny names   this, where you have a synset. But maybe in some kinds of genres,  poetry or something, maybe it's harder to say. to turn word, sense disambiguation into a classification task. hopefully, you can imagine how this would work. it requires a lot of work to annotate word, sense information. that's not very scalable. and you select the sense with the highest overlap score. it's just to. And then you find the overlap and find the sense that has the highest overlap. , for example. There are different choices you can make regarding how to represent the context itself. Maybe you get rid of stop words. Maybe you don't. Again, this idea of Lesk's algorithm, there are lots of variations you can play around with. Also from the definitions of all senses of the context words, how you compute, overlap. Stop words. But the simpler version just puts all of them there. And then it tells you to ignore stop words and include example words and count them overlap. how do you do overlap? Can you do partial overlap by characters, or is it always by whole? Can you do partial overlap? Maybe . But in other cases the partial overlap might be  overlap in terms of  the prefix, which might not be that meaning ? And then you see the overlap between those. it really just represents. It's an approximation of the kinds of words you should see in that situation where this word appears. here this word, this word bank appears in this context, and you need some approximation of  the  situation you're in, and what other words may appear and also, maybe there are things that are not directly mentioned, but that also might appear  money here doesn't directly appear, but may maybe it appears in the definition of check ? and the kinds of words that might appear there. then you can get a better overlap score between that and the overlaps in the definitions of each of the senses. example! Here are the overlaps. use heuristics to define some ideas about  what you want to do, and in particular, to design these overlap scores to computes and do disambiguation. The model! This is how the model pulls itself up by its own bootstraps, which is  it gradually improves itself through multiple rounds of training on automatically labeled data potentially, automatically labeled data. And finally, you use the last model as your final model. here in Jarowski's setting there are only 2 senses. Just . otherwise, you're in a completely unsupervised setting. Here you can train a naive, base model. first, st it has to produce an output  it has to say for these new samples, is it sense A or sense B, and also it has to produce some  confidence score. , for example, it might produce a likelihood score  a naive base would produce a likelihood score ? you just need to produce some  confidence, for even if you use Svm  support vector machines. If you remember how that works, you have some notion of  distance to the margin which you might be able to interpret as  a confidence score. I'll be  back. For example. How did how did we know, for example, that animal within 2 to 10 words just based on the log likelihoods works is that is that manual analysis. this is from the decision List classifier. then you can interpret it by looking at the magnitude of the feature weight, and whether it tends to correlate with one sense or the other. you take this outputs these outputs. you retrain the model. We only have the confidence scores. just keep that in mind as . we don't do. We're only looking at model confidence. Oh, , over there  last longer to look at. And then throughout the process, the iterative process of training and retraining the algorithms. when this paper came out, it was really great, because it showed a very, very high level of performance on binary word sense disambiguation. and in fact, it was achieved the same level of performance as the supervised methods of the time. And then, in modern times, though we solve harder problems , and not just the binary word sense disambiguation problem. In which case, , then, the numbers drop because it's a harder problem. or you can do something else  what you say, which people do with Svms. there are standard methods to use. what we covered then  far is worth sense disambiguation. I invite you to all  stretch and . We'll take  5 seconds, and then we'll continue, , stretch. for example. , that's great. the idea here is that we figured that out, even though presumably most of us. And that's because of this phrase, such as. that's  maybe I should have started with that. That's  one of the motivations. ,  Np, such as whatever such Np as blah, blah, blah, Np, or other. Np, np, blah and other np, np, including blah, blah or Np, especially blah. Blah. I remember, the hyponym is the smaller one, which is  the more specific one, and the hypernym is  the bigger one, which is  the more general. first, st it's probably Piper. Maybe we can just shout at me, Joseph. Oh, by the way, is it clear what the stars mean? or maybe 0 or more. star is 0 more because you can have a whole list. , how about this headbook? Great. ,  that's great. In the 1st place? Or maybe it's maybe you need more than that. No worries at all. why don't we just find the flavors, such as including instead of, we need to eventually buy. Because you just say it's Hi. I detect the keywords such as including that. why don't we just do that? and maybe these set might not even be the ones that are the most specific to that relation who knows? the idea is by using some automated procedure, we can do a better job and better get all of the taxonomic pairs that are in some data sets. , for example, using this idea. The the pattern here is Np. in general, it can be very useful if you just don't have a lot of resources or time or data. But you, if you don't have a lot of  time and resources to hire experts. And maybe the problem, the phenomenon itself is not very  understood. maybe that doesn't exist experts for the thing you're trying to solve. there,  that's 1 area where you do need data. And hopefully, it's cheaper because it's unlabeled. But it doesn't really reduce the data cost. And , meaning you have,  all the data. what you're talking about sampling with replacement. ,  we covered hyponomy and hypernomy. , for example. The synonym is between the verb phrases we have went extinct and died out. It's just that the way you're using the context is different because the problems are the structure of the problems are different. which is the idea that you shall know a word by the company that it keeps. And that's similar to the company that is kept by the phrase, Dido. ,  the general idea here is that you understand a term by the distribution of words that appear near that term. It's just that large language models do it in a much larger scale. for John, you would gather the counts of  birth was an English and maybe linguists. and then you would accumulate all of those counts. , all sorts of ways. I would say that stop. Words are useful to. They're usually useful to include , because it gives you stop words. They do still correlate with some kinds of semantic meaning. , great question. But one thing they do is they don't keep all the columns. And there are, we'll discuss ways to automatically compress this large term context matrix and do something smaller. And then we should stop. that we've counted things, this is useful, because  you can talk about. If your vectors are positive. then the similarity score. It's easy to see that the similarity scores will be between 0 and one, because the numerator here is always positive. then, one naive thing you could imagine is that, ? then, we'll just gather a large amount of text. We'll we'll find a feasible way to compute some version of that term context, matrix. And then we can compute cosine similarities between word vectors, and then we can use the ones that have high similarity scores and call those our synonyms ,  pairs of words with high similarity scores, and we'll call them our synonyms. certainly synonyms and near synonyms are one reason for words to have similar contexts. It was it could be great or it could be. It's about synonymmy and hypernomy and hyponomy. which is an a physical entity, and at that level physical entity might give you  a inanimate objects, and  man-made objects and then and then  household goods, and then furniture, and then scratching posts, or something  that, ? this is useful as a distinction to keep in mind. Maybe they don't know about this distinction? , for example. that's just about association. Are we missing some notion of the magnitude of the vectors? Are we missing some notion of the magnitude of the vectors. That's a great question. What does magnitude correspond to in this term? it's not about the magnitude of it's not about the score, whether it's 0 point 1 or 0 point 9. But what is the magnitude of the vector here represents. , , it's just about the frequency. that matters because,  frequent, more frequent words, probably have some kinds of semantic meanings which are in general different from less frequent words. But magnitude here is just about how frequent a word is, and cosine similarity is more. is this term content. Context, matrix is this   analogous to  a word, that is Aha is this term context, matrix analogous to word embeddings? one thing that people have done which has been really popular in the past is, if you already have something  a wordnet. But then it depends on your goals, ? ,  how do you  evaluate these vector space representations? we all we can do is we compute the similarity of vectors in that sense to each other, and correlate that against some gold standard. And there are many possible choices of this gold standard. But one option is to just directly ask people. what they did is they got a list of word pairs. And then they went and asked people how related these 2 words are to them and to, and they ask people to give a score between  0 and 5 or something  that. And that's  their gold standard. And then if you have a trained word vector model, you can get your word vector to also give you similarity scores with cosine similarity. any other potential issues? Did you have a different point? , I think you're getting at one of the another key issue, which is that different annotators might have different ideas of what a 3 or a 5 means  in the scale. when you just take the average across multiple annotators  it's really not clear what that's doing. how are the annotators handling that? Are they handling? And you can just check what scores you get. , , there are other methods for constructing better word vectors. Was a really famous model that did this. I would say that word 2 vec is   the moment when deep learning based methods, or at least neural network based methods. Word 2 vec. the idea behind word 2 vec. Architecture is trained to predict words and contexts just  a large language model. But this was  a simpler version. You interpret that as the representation of the word just  in the simpler count based methods. After  or 2 Vec. I lived through this, but  an interesting   a result  in the in the literature about  how the progression of the models went."
    ],
    "Topic 3": [
        "How are you do some fucking thing? , great welcome back. welcome back. And then it's named after the most common word that realizes that sense  hand, or something. here, in the 1st sentence, here. whereas the second sentence here is meant to indicate the style of handwriting  and where we left off last time was to say that in general we have this very good clue about how to disambiguate for the intended word sense by looking at the other words in the context that would help you to disambiguate it, which  makes a lot of intuitive sense. whereas in the second sentence, flowing and graceful might be words that indicate the style of handwriting. what if all the words in the sentence need context to disambiguate them? what if all of the words in the sentence will need context to disambiguate them? it's   all of the words help disambiguate each other. It's rarely the case that you really can't tell which sense it is at all you probably can figure out with maybe there might be one or 2 sentences you're not sure in between, but usually you can figure out in communication and commonly found communication. You have a word you want to disambiguate  hand. You collect a corpus involving lots of instances of the word hand, and then you ask annotators to label each of those contexts with which sense of hand is indicated there and then. you need to train one model for every word you want to disambiguate. And  the other general strategy I'll illustrate instead is something is to use a minimally supervised or sometimes it's called unsupervised machine learning methods. which I think will be generally useful in different problems that you might want to solve involving natural language or otherwise. we're going to look at that as . 1st you construct a bag of words representation of the context where you're trying to disambiguate the sense of some word. and then each context is represented by the context,  the words in the context. suppose we want to disambiguate the word bank here which is underlined and the 2 senses that we're trying to pick between is the Financial Institution Bank versus Riverbank. But that's relatively rare compared to a financial bank which is always closing before you need to get there. And   your context, then, will be represented by your contexts. or what you can also do is you can take the dictionary definitions of all senses, of all of these context words themselves as , and that gives you,  a more expanded set of words that you can plug into this formulation, and then you have an expanded set of words, and that becomes your bag of words in your context. Words extract some information from them to come up with some beg of words, representation of it. then  for each sense of the word bank. we have bank one and bank 2, maybe bank. One corresponds to the Financial Institution Bank and Bank 2 corresponds to the Riverbank Bank. You take its dictionary definition. , for example, how exactly you represents the context, and whether you use the or only the words or the words. maybe you might have explored that in assignment one ? the question is, are we looking at the definition of the deposit and seeing if bank shows up there and added to the out to the bank. You could do something  that, because maybe you want exactly the senses of the word deposit that relates to bank and not the other ones. I think it would probably make more sense to go by token. pictures to what exactly does the bundle here represent? And  by constructing B. By looking beyond the words that directly appear in this context, but also other words that may co-occur with those words, that's  what you're approximating. it's a model that is independent and can do its own thing and doesn't need help. , except at the beginning of October. once again, you have to gather a data set with the target were to be disambiguated, such as bank. A little bit of information which is to automatically label a small seed set of examples. and you repeat this step 3.  this step 3 is iterative, and this way you get. ,  we're going to disambiguate the word plant . here Plant refers to the type of living organism that photosynthesizes and all that. Either the factory sense or the living being sense car and truck plant, manufacturing plant, animal and plant life fluoride, monomer plan, blah, blah, blah. the 1st step is. we need to have a cheap automatic way to label all of these examples. probably in a very noisy fashion. by doing this you can automatically label some of your data set involving the word plants. And then most of your data is probably still unlabeled, because most of your data probably doesn't contain either of those 2 words. you have to know what are the senses you want to disambiguate in between. , once you have automatically labeled data. But , it doesn't really matter. that if it co-occurs within 2 to 10 words of the word plants. whereas if it's equipment, then it belongs to sense. In in this step? You still probably want to make sure your model is not learning something very unexpected and weird. , because you had some pre labeled samples, ? you had some pre-label samples, you use them to train the model, and then you label everything. the things that you get correctly labeled the 1st time. It's not a supervised method. the question is, are we going to use the model on all the data? Yes, we're going to use it on all of the data. But we're going to use the highly confident ones to grow the set that we pass into the training for the  round. Can you think of your Oscis algorithm as having an automatic dictionary. Maybe I think it's not direct. Then you're not explicitly constructing a dictionary definition. But you are finding other cues and other clues that help you label each sense. You want to disambiguate. It's just that you have automatic labels at the beginning. there's nothing here that is restricted to the problem being binary other than the classifier itself. refresh your mind. And it's plucked and has an individual curved neck for each string. For why you want to discover words in certain hyponym hypernym categories. Who thinks it's hypo. who thinks it's hyper. Super. You then go to your corpus, and then you do a graph, a really expensive graph. and then you get all of these pairs, and then it might be noisy,  then you might have to do some extra work to  clean them a bit. ,  in particular, we can be Spartan in a different way, and maybe use our idea of bootstrapping that we just saw from earlier this class. and you find all of the context in which those 2 words appear, and you can get the context around those, you can extract the particular context around those 2 words. And then, once you have those contacts you can find which contexts are very common. reinforcement learning is a learning paradigm for training a model where the assumption is that you have some reward signal that helps you modify the model's parameters. Learning is more  the particular machine learning, optimization, paradigm or technique that you apply in order to change the model parameters. but sometimes it's used in Nlp. We figured out these patterns. Cause. or you need data. It assumes that you have access to unlabeled samples that are relevant to your problem. And it wouldn't. It wouldn't work very  if you have a very small amount of unlabeled data  what's small there, you should just get as much as you can that you can afford. maybe he can scrape something from the Internet involving all of the sentences that contain words that are relevant to your problem. Even if you have labeled data. if you can use your even if you have a label data set, and it's only on  a thousand sentences. Sampling. and it also doesn't work very  for autonomy. we've looked at the relationships between 2 words that co-occur and their intervening words. here we have another canonical example. And  it's about the relationship between these words or noun phrases that co-occur in the same context. where the words and those relations don't tend to occur co-occur directly. and it is exactly because synonyms are supposed to be substitutes of each other. you wouldn't use both of them in the same sentence, because you just need one of them. I suppose you could say it, but it might be rare. instead, the other signal that we're going to use is  that the words that tend to occur co-occur with the target words themselves. these 2 sentences, what do they share in common? They share in common that all of the other words around the phrase that is a synonym pair are the same. , sure. that's for sure. ,   really, all of this stuff comes back to this idea of distributional semantics. that's how  that those words are related to each other. with a different machine learning architecture. ,  but we're going to go back to the basics and look at some of the earlier versions and earlier instantiations of this idea of distributional semantics to  see the progression of the field over time. You would look at the 5 words before and the 5 words after. when it's the center of your attention and you're looking at all the words around it. or it can itself serve as the context word for other words. it's the context word, in the in other words, the target. You have a higher count compared to. , if you see a word that occurs a lot with  in or at or something, maybe it's a time, word or location. No and it also correlates with syntactic properties. Is this going to be   a square in person,  a sparse radius? 5,000 or 50,000 most common words as context words, for example. how do we get the main target and context words? the target words are just the words you see in the Corpus that you want to model   every time you see a new word, you can add it to a new row for it. For the context, words, you can do the same thing. What people do is they 1st pre compute a list of the most common words that they see in that corpus, or some other corpus. Word set. you can start computing similarities and things between them. and this is defined to be  if you have 2 word vectors. and is defined to be the dot product of a dot B divided by the norms of the 2 vectors. And this gives you a range of values. ,  any words that tend to share context, words will have high cosine similarities. It was horrible. And for that reason a major problem with the approach of distributional semantics has been that it's very difficult to separate out the different reasons why words or phrases may share similar distributions of context words. however, cat is not similar to scratching post, because in the taxonomic tree they're very far apart. A cat is an animal is a living being. they're very far apart in the taxonomic tree. and  they are not similar, but they are related because you might often find context in which you see cat and scratching posts in the same context. Context? They're not related whatsoever. Problem. that's the difference. the problem is that word. I don't know how I feel about this evaluation, but I'll present it . why do you think , I'm not super fond of this evaluation. It depends on people's interpretations of the word, . you might want to , readjust and calibrate each annotator against each other. , this is not a great evaluation for many of those these reasons. but people still do it because it's once you gather this set of annotations, then you can run it. we're up to  just a decade ago word 2 vec. is that you set up a neural network architecture where the neural network. Was proposed, it made a big splash, and the key result was that,  a year later. And it also just goes to show you that,  having different views of a problem and thinking about things in different ways. can really get to  get you very far. And that's why you can find those hyper parameter decisions that give you very high levels of performance. And then this whole distributional semantics approach with  the training of these term context matrices and  neural approaches after that."
    ],
    "Topic 4": [
        "Jackie Cheung, Professor: But good evening. Vision. Oh. we are going to continue our discussion today about lexical semantics. you remember what lexical semantics is? But ,  lexical semantics and last class we talked about. where the idea is that you have a repository of words and their senses associated with them. and we talked about Wordnet in particular, which are primarily organized in terms of the word senses, in fact, which are these syn sets. here, tired, is something that is a property of some physical part of your body. today, we're looking at each word in isolation and saying, given all the other words, figure out which sense. But the reason that I'm presenting them is that they give you the flavor of how you can use knowledge about the problem and your intuitions and build them into computational algorithms. And it fits under this category that I'm going to call heuristic algorithms, which is that you design a bunch of heuristics based on your knowledge about the problem, and you directly build them into the algorithm itself. Then there's another class of algorithms which I won't discuss, because hopefully by , you can imagine how this would work which is to apply supervised machine learning. After that you feed that into some classifier. and you, then you have a word census configuration system for the word hand. Lusk's algorithm is from the 80 s. And the idea is that you use dictionary definitions of a word senses in order to help you disambiguate in context. Intuitively, the words in the context that will help us figure this out will be words  deposit and check, and closed because the chances are there. ,  then there will be some statistical correlations between all of these words. and before and close, and  forth. that's the high level intuition. And then you might want to use a development set to figure out which version is the best. , do if you, if there are multiple words, if there's  a word type that overlaps multiple times. Do you count it as  multiple overlaps do you do any waiting in terms of the rarity of the words , there's something called tf, idf waiting. I already said this, which diction also. Which dictionary do you use? I'm gonna skip this because we're slightly behind schedule in the lecture. for example, you can run less algorithm using Nltk for the dictionary definitions. a wordnet, nltk and wordnet for the dictionary definitions and for the census. And there was a question there. what is the question? If I understand, high level question is, what does B represent something  that. there might be additional context words for that particular topic that might appear. You're just approximating a and a scenario or situation. ,  that was algorithm number one, today, we're gonna cover  3, maybe 4 algorithms. And bootstrapping, I think, comes from some saying , Pull yourself up by the bootstrap, which is that you should rely on yourself to get things done. Oh, I think the example we have is with the word plant. let's go with plant. The plant is still operating. and  all of these contexts will involve the word plant in one of those 2 senses. Question just to clarify is the word selected to distinct between the 2 types manually selected? Are they manually selected? and then you can use that in order to rank all of the labeled samples and in terms of their confidence that the sample belongs in each of the senses. And I'm gonna close the door. Instead, you would have a feature weights. Are we checking? Manually, if the outcomes are ? And the question is in this step, are we checking? If the outcomes are correct manually. But in practice you don't have to do any manual checking in between the iterations. And adding them to our seat set? why can't you just take the ones that are correctly labeled in the 1st round, and then in the second round, you can take the ones that are that were unlabeled, and it predicted it correctly both times. That's the question mark to a. Oh, , , . And you might consider that in the later iterations. And someone had a question over here. ,  unless the algorithm, we're using the dictionary definitions quite directly. we're not using the dictionary definitions. , is there a way to apply this to non-binary cases by treating this ambiguity between each case as a binary decision? Is there a way to apply this to the non-binary setting by treating each pairwise thing as a binary decision among the all of your senses. you can either have a classifier that is itself non-binary. ,  2 algorithms done, and then  2 or 3 more to go for today. which is to figure out which is the intended sense of the word. But they're  a lot more tasks within lexical semantics which people have worked on, and which are popular. And  for the rest of today's class, we can switch gears, and then we can talk a little bit about detecting lexical semantic relationships overall. But the   is a short transition break. , extension. ,   remember last class, we went through all of these lexical semantic relations. Hyponym, hypernym. for the algorithms that are coming up, the goal is to figure out. how do we find hypernym pairs, or,  other words, in some lexical semantic relation. And this is called using Hearst patterns. ,  and hearst patterns. The idea is that there are certain patterns in terms of the contexts in which word pairs occur. And we can use those contexts in order to help us figure out the lexical semantic relationship between words. Oh, you do. What's a what's an instrument, , ? ,  here we can identify that there's a hyponym hypernym pair because of the phrase such as,  here the hypernym is the bolut. and that was also the picture on the title slide. Today's lecture. The idea behind Hearst patterns is that if we can identify expressions  this  such as then we can discover hyponym, hyperym pairs automatically. And that way, if you're constructing Wordnet. it relieves the effort of just trying to think about this and think about what are the taxonomic relations or other relations? these are Hurst's original patterns. for each np, can we label them as indicating the hyponym or the hypernym? ,  let's label these. is this hyper or hyponym? is this hyper or hypo? Yes, hypo this one? Yep. yep. hybrid. Oh. Lee. once you have these patterns. But this is how you can get a lot of hypernym hyponym pairs. But then a reasonable question is . How do you find these patterns? What do you guys think, how would you apply bootstrapping? Oh, that's not . maybe it's 2 words in a hyponym hyperym relation. and then you can apply those contexts more generally and extract a whole bunch of new words that could potentially be in the same semantic relation. and you can take on other questions about it or read up about it. You want to find hypoten and hypoten? the idea is  this set might be incomplete. this set was  using our expert knowledge or our hearst expert knowledge. And, in fact, you can even use the same strategy for other relations. not just hyponym and hypernym. These Hearst patterns have also been discovered and used for other relations, such as between cause-effect relations. this is Gizhou's work in 2,002.  earthquakes caused tidal waves. Which is the effect. ,  we see that we've seen  2 examples of applying the strategy of bootstrapping. And in that case you can consider using some   bootstrapping strategy where you start with a small amount of insights to derive some training examples to start the training the process. ,  that was 3 algorithms. , we're going to cover the 4th algorithm or task area for today. But you guys are troopers. you feed in something? bootstrapping reduces the annotation costs. and then you extract a much larger set of unannotated data and apply your classifier then, and then you can still do this bootstrapping in that setting as . You take a small sample, and then you use that. Oh, ,  , ,  here's . Remember. Remember how I said that there are multiple senses of bootstrapping in statistics, and that's the other one. 1st to figure out in a context whether you mean the Statistical Bootstrap, which is for statistical testing. And we  we cover  word census integration. And hyper and  flexible semantic relations of some types. But there are some lexical semantic relations, such as synony. And if that's the case, then our strategy of using Hearst patterns would be unlikely to succeed. because Hearst patterns depends on both of those words occurring in the same context. You would not be able to use Hearst patterns to extract a relation between went extinct and died out because they would not co-occur. Most likely. that is, that is a shared part. the basic idea here the simplest version of how this might work is to go through a corpus of text. And then for and you keep doing this, and for  oops for a figure. And you're accumulating the counts for that target word. And then it becomes counted in the, in the counts of the other word. here, 1st and figure and linguists and 19 fifties in English these are all target words, and the representations are the counts where each column is the context word and the numbers here are the co-occurrence counts within your corpus. there are a variety of ways that people have tried to do this and done this. here we define a symmetric context of  5 words on each side, but you can instead define a context of  5 words to the left, only, or 5 words to the . or 3, or whatever you could define your context in terms of syntactic relations. another thing people have tried is they 1st do a dependency parse of a sentence, and they consider something in context. Only if they're in, if there's a dependency edge between them. , if you see a word that correlates with B and A a lot, then maybe it's more likely to be a no. in practice, what people do, we'll get into some of that. I think there were 2 more questions, that 1, 2, , 1, 2, 3. they're the same dimension, ? we wanted to text synonyms. ,  if you have something  this bowl of soup is blank. semantic similarity is about taxonomic relations. , for example, chair is similar to furniture, because a chair is a hyponym of furniture. Any questions  far? I agree, it's difficult to interpret what counts as being close or not. Good question. Good question as . then you can use wordnet structure to define a measure of similarity by looking at where, in the wordnet, hypernym, hypernym tree the 2 concepts are, and how closely they are related to each other. there's a whole bunch of metrics there that you can use. Because,  a lot of what we're doing today is, we assume that we're trying to construct something  a wordnet or construct some  hierarchy that makes sense and defines  the relationships between concepts. That's not a question that we can answer. Here  some  computation of a function to get a score. ,  that's what Finkel Stein did in 2,002. And then they took the average. this is the average amount  this. on average, this is  people's judgments on , how close these 2 words are. Yes, it could depend on people's interpretation of the word. Yep. for example, and the average is paid for each vendor for the average before the decision from each readers to all the that's a great point. Another issue could just be  a word might have multiple senses. In that case it might depend on  which sense they happen to think of at that moment. or are they  averaging across all the senses. Today I'll just speak at a high level about that question about word embeddings. that's the interpretation. And then there's a lot of math and structure behind it, and a lot of  hyper parameters to tune, and all that. to answer the question from before the key results. ,  I, , I don't want to introduce any more today because we've gone through too much. what do we do today? today. given a word, figure out which sense was intended. and we covered the less algorithm which is  a general , which is  a heuristic strategy to do this. And we also cover Yarowski's algorithm. which introduced this very general idea of bootstrapping which is applicable across multiple contexts. And then, in the second half of the lecture we talked about how to have methods that can extract word pairs that fit some lexical semantic relation. for some of those relations  hypernomy and hyponomy, you can use the context surrounding the word pairs in order to identify that relation. And  you have to use the con. Figure out the some representation of those words. I guess that's a summary of what we covered today. And we will continue  class, and I will release the  programming assignments  hopefully by the end of today."
    ],
    "Topic 5": [
        "it's good. Hello! Can you hear me? Oh, , let me fix the lights. lexical comes from lexicon, and the lexicon is  this idea that we have some mental storage of entries related to language which typically store words, but maybe also stores, phrases sometimes, or maybe also morphemes. In fact, I would say that is typically the case. we're looking at. They don't use any neurotechnics. here are the steps of Lesk's algorithm. and then you compute an overlap between the context and the signature. , I guess you can have a deposit in a riverbank  it's in the sand deposits, but you won't have check at least . one choice is to directly use the word itself. then your contacts can directly be deposit and check. then you can use that you can filter out. Yes, I guess what I'm thinking of is, say. should we think about this in the way that we're looking at the definition of deposit? See if bank shows up there and then we add that to the bank. You have to make ? Oh, and do you lemmetize and all that I think I'm gonna for the sake of time. That's that's a choice. That's a design decision for the algorithm. , for example, you can compute the minimum number of times that a word that word appears between the minimum between in the b versus in your signature. Yes. Yes. It might make sense I don't know depends how you do it. it's a design decision as . Yes. Hello. all the little stuff. Yes, all the little dots would be words, and then the ones in color. that was algorithm number one for word, sense, disambiguation. it's gonna , keep improving itself and get becoming a better and better model. Then you apply the supervised model to the entire data set. and then you keep the highly confident classification outputs to be the new seed set. the heuristic that Jarowski proposed in his algorithm is to pick one other word, just one other word that  will correlate and co-occur with that sense with very, very high probability. Yes. Yes, they are. And then you have to apply some  word sense induction algorithm, which involves clustering and all that which we won't talk about today. Yes,  in on the . And then, based on that, you have to be clever and select a good seed word to create the seed set. in Jarowski's algorithm, this was back in the early nineties when a different set of classifiers were popular. And the  does logistic regression. I'm gonna shut the door. B, an employee also belongs to sense B, and  on, and  forth. Yes, . how do we know that this case holds. in logistic regression you would not have this directly, not in the same form. here, I'm showing this to help convince you about why bootstrapping works and why it might work. ,  then, in terms of how the algorithm goes. what you do is you then expand your the samples in your seat set to add new samples, where your model was highly confident after one round. whereas before you only have the cases involving lice. you add additional samples, because the model was confident on them. For , I think a question mark to be a I'm wondering if that should be in the second round, because  it's , if it predicts question mark to a and then a to a again, then that's a confident. But this one is, maybe it's still just a confident yes. the question is  the question mark to a are we premature? question mark here means unlabeled in iteration 0. And then a means it's it was labeled as a after one round. After one round you take your highly confident labels and you add them already into the csat. that's how it works. , I think it's something  that? yes. that's the main idea behind bootstrapping. Generation. that was algorithm number one. This is algorithm number 2, Jarowski's algorithm. directly. it's a little bit different. it got  96%. which was great, because previously people  painstakingly annotated these senses on a lot of data, and then you train a supervised model on it. Yes, is this considered an unsupervised or sending school. Great question is this considered unsupervised or semi-supervised depends who you ask? It depends who you ask. But other people, I think, in more modern times people may call it semi-supervised because the learning algorithm itself in the in the training in the loop is a supervised learning algorithm. semi-supervised. Yes. Svm for multi-class classification. mindset shift, we're no longer working on Wsd, , we're working on detecting lexical semantic relationships. Yes, that's . algorithm number 3. ,  do people know what a Bambara dang is me, neither. Yes, it's a ball loot. that means that , is this bow or bow, I guess bow, because it's  bow and arrow. What's a loot? A loot is. That was a Bambara and done . Yes, I agree. And then how about this case? Yes. Yes. Yes, and then this one? Yes. They're  from regular expression terminology. here it means . I guess one or more, maybe. , I think here, it's 0 or more. Do we need a vote? Yes. Yes. Yes. yes. does this make sense. And she thought of them. , but can we do an approach that allows us to be less smart, I guess. Whatever the models in it works together? Yes, that's exactly . to repeat in case people didn't hear. And then and that's 1 iteration. And then you can go back and forth and back and forth this way and again, that is bootstrapping. It fits in the same general pattern. And then you have some more expensive step where you do a little bit of learning, and then you redo the whole iteration. , if there was human feedback on a set of samples that came from one iteration, would that make it a reinforcement learning algorithm? If there was human feedback after one iteration, would that make it a reinforcement learning algorithm. it's it's a different thing compared to what we're talking about, because what we're talking about is the general strategy of automatically label things, labeling things in order to derive some signal to improve the algorithm itself. Reinforcement. The idea of bootstrapping with reinforcement learning. And and if you don't know what reinforcement learning is. Yes. She found other verbs that also indicate causal relations , induce or give rise to or stem from, and  forth. I know it's a lot. Yes. for the bootstrapping, what is the smallest size that you would need. I guess the smallest. Yes. in terms of bootstrapping. in fact, you can even think of this bootstrapping approach. in case other people didn't hear. Yes,  you have to run a wst on the word bootstrapping. , but that's unrelated to bootstrapping in the current sense, which is a unsupervised or semi-supervised strategy program. But it turns out that the hearse pattern strategy doesn't work very  for synony. The dodo went extinct in the 17th century versus the Dodo died out in the 17th century. it would be redundant to say the dodo went extinct and died out in the 17th century. the dodo went extinct in the 17th century. and its most general instant, , realization is  what powers large language models. the company that it keeps the company that one extinct keeps is  Dodo and 17th century, and  forth. and large language models based on predicting mass tokens in context are implicitly relying on the same notion that the context around which a word appears is useful to getting the meaning of that word. what this means is that for every word it has 2 roles. That's that means it's the target word. where each row represents the counts that are accumulated for a certain target work. Yes. Yes. You could, for example, do some   a wait waiting,  that if it's directly  to it. If you're farther away. Yes. It's a design choice again. on a big purpose. the question is on a large purpose. yes, in the original version, yes. Yes. and the way to read this, perhaps, would be in the context of English linguist, shows up 21 times. , in the context of English language shows up 21 times according to the this notion of context. You can compute some that . every word is  a point  in some high dimensional space. that means you can compute cosine similarity between them, which corresponds to the angle between them, . And ,  this corresponds to the cosine of the angle between the 2 vectors. if you have 2 vectors that are pointing in exactly the same direction, then they have a cosine similarity of one. If they are orthogonal to each other, then they have a cosine similarity of 0, and if they're pointing in the opposite directions, then they have a cosine similarity of minus one. And then these norms that they always give you positive numbers. that works to an extent. You could put hot there, but you could also put cold there. Or I saw a movie. and  that this means that we need to distinguish a little bit between the abstract idea of similarity versus the abstract idea of relatedness case. and  good is related to bad. But unfortunately, people are often very loose with their language, and in terms of how they talk about things. cosine similarity is a measure of relatedness. , it's not directly a measure of similarity. It's a measure of relatedness, because all cosine similarity gives you is the cosine of the angle between 2 vectors, and they could be. Yes. Yes, I would assume it's , if things 0 point 1 0 point 9. , I think I think the way I interpret that question is magnitude in terms of the vector magnitudes. It factors that out in its computation. Yes. students are . What are there any measures of similarity which are of similarity directly and not relatedness? this is  tricky. But I'll talk about the things that people have done. Vectors have no objective inherent value that we can evaluate  if you had 2 vectors for the word linguistics,  is point 4.3 negative point 2 better? Or is 0 point 2.5 point 1 better? All we can do is we can evaluate the similarity of vectors to each other by similarity. You can compute a correlation between them to check whether it's the case that the higher the similarity, according to your word vectors, the higher the similarity, according to people. Similarity. Or was it the same point? I think you're getting at the  things. We know that. I won't go into them, because I know I've overloaded you already with too many algorithms. this was   the beginning of this whole deep learning revolution and nlp, . I think. and there's some intermediate hidden layer in the neural network that you interpret as the word embedding. But let's summarize. the 1st half of the lecture was about word sense, disambiguation, ? Word contacts themselves is the signature to . and that introduced a whole bunch of other confounding factors involving relatedness versus similarity."
    ]
}