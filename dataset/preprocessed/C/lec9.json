{
    "Topic 1": [
        "David Ifeoluwa Adelani: Problem. , . . cool. . . All . especially for a token classification. Including beds-based models. That is based on transformers architecture. , people don't use it that much as before with the Llms. If you want to improve performance? . we have a Markov model, where we have different states  q. 1, q. 2 q. 3, q. 4, q. 5. And then we also have observed variables in this case. The States will be the different ner tax,  we examined last time. and the observed variables will be the words,  this is a generative model. And I want to emphasize in generative model. If you want to predict what would be the output of y. Thank you. Thank you bye  for the case of   again. you can also do that in this case. in the generative model to reemphasize. If you are supposed to find an output y. you can  compute Y.  that is the idea of generating model was, as , in practice, this is  not possible, because for you to compute that you have to make some assumption which is  the Markov chain, assumption or independence assumption to  be able to compute these probabilities. Some other models. They do not make this assumption because some of these assumptions may not be realistic, ? And in that case a discriminative model is more realistic. and it. And a very good example is the artificial neural networks. We're back to the . Which is a generative model. It's difficult to learn this joint probability over all the States, and therefore we make the Markov. Instead of saying that the  State depends on all previous states, we only say the  state depends on the last one. And this is a very simple example of a generative model for a diagram distribution where we see Q. 2 depends on q. 1. . all . if you remember, in the last slides. And the last time we also said, . It's also possible that you can do this when you don't have any labor, they do no label data, no problem. Even if there's no label data. and then you compute your needed parameters. All . You can use this to  have the expected count based on the it is structures. Plus one. . . You need these parameters A and B and the parameters A and B are computed from this grid that I showed you the last time. Let me stop sharing. . This is the grid. A. And then it's updated at every iteration. Initial. ? your A's are coming from the transition probabilities and your B's are your initial probabilities. Distribution. Goshen is probably not the best. . . . . And then you can  compute your gamma apps at the E step, and then for the second parameter, you can do the same thing . These are. And once you have computed all this. ? . And then you go back to your end. , if the likelihood doesn't improve . Given your initial Titaki. ? , I think this is where we stopped the last time. And we said, , there's some issues with this, because it's very sensitive with to your initial in your initial random initialization. and they are not very realistic. It's been very difficult for you to improve for the year majority. Better ways of initialization would be  using external knowledge, for example, from an external purpose where you already have more realistic counts that you can use. . I have to emphasize that. Information  the doctor's name. I can make a note that has been written by a medical practitioner. But there's a question if comma is  part of the organization, or if everything is a single organization here rather than multiple organizations. Time to. . I think the difference is In the first, st I think we're trying to address the problem. you would have if you have You  have Mcgill after Montreal as another organization without space you would all use the organization for this. 2. . . 's? And also what prefixes suffixes? But the difference between this approach is that  we are going to consider something more of a discriminative model , I said in a generative model. because, if not, if you don't make this assumption, it's not possible to  copy this ? those are the generating model. ? that depends on the previous one. We are also saying it depends on the previous value of y and Z, and we want to learn that function. . And here. Na. For the that's a modification. . And then what is. . . You are craft. . what? Mark here. it could be anything. ? it could be anything. . . ! ! Is more of a generative model. And Rss Crf is more of a discriminative model. Which I believe you are quite familiar with after seeing this for the last 2 lectures. the modification we do here is  hardened this function. In the last one we have. Times, which is the initial state probabilities. And after this modification, apart from this modification. ? Why is it? . . ,  because F of K would be one, ? Is that a 1 or 0? . each of the 3 can do. . . , . . . ? There's no d here. . it's just to make a privacy distribution. ? . you probably don't need to normalize. Bye. . If you remember. ? that's what we said, . . ? ? . And then you do this for a while. . here. And , . what if? But we can. . . here. we want to take the log or a full drop of all this. ? everything. Thank you. No. from here. Everything. 1, 2, . This could take more time. ? . But this other one. and if we take the revenue team of this one no. Here it is. bye. we still have this one because it doesn't depend. If in 2 of x,  this is  indirecting which I spare to evening. Multiply by. You can edit this here with respect to 2 x.  if you apply the channel. please. And then. . And  . . hey? this will be. commission in my old device. That's . . David Ifeoluwa Adelani: Do you have questions? Haven't seen the suck. I 2. No. . I think the last that one is  enterprise. this is all about, why? ? I think it's correct. . I think it's just the last time. . , . As predicted by the current model. If you're able to achieve this. I believe this is correct. , but apart from using graded designs,  we said in the previous slides or previous classes that you can also use stochastic gradient descent. and for each Mini batch for Sgd. The size is one. Then you compute your derivative over this Mini batch. Do you have questions? here. Odds. . what is Z of X doesn't is not over the I's . , I have to. . . , thank you. a neural network. , no. ? It's just  a weight, ? . Thank you  much. ."
    ],
    "Topic 2": [
        "Tasks  battles, please tagging, chunking. as it's popularly called. You can combine it with Crm by just appending the Crf layer to the  the last layer of your network. We  find Llms to still struggle a bit with talking classification tasks. We today we'll talk about some of the shortcomings of Ed Markov models, and then we're going to move from generative tasks to more discriminative tasks and of course, we examine the linear chain conditional fields. ,  for the Ed Markov model, this is a summary of what we have been talking about in the last 2 lectures. and if we also talk about the ner models. if you want to solve the transportation task , you want to solve for y given X, there are 2 ways of going about it. we make a Markov assumption where we  explore conditional independence assumption. we consider a couple of our guardians. When the 4 are going in the sum over all the previous States. Why, in the Viter we are guarding, you  just take the maximum. And then you do this attractively. 1st you randomly initialize the States. Why, computing the likelihood. for the expectation maximization, it boils down to 1st  computing the probability of every State given the observation. and after that you can  compute the transition probability from going from State I. Which is going from the previous state qt. you randomly share rise your A's and your B's, your A's are coming from the forward. Wait. Your alphas! I think we go to the last presentation on Hms. Yes, I have. A question is probability of O. And you can run your background as you're ready. that is Tita K, . you already have the values of Eij gathered eyes. A's and B's here will  form your new Tita. You have question. Yes. The same way we competed. And of course,  this is just a revision of what we did last time. Montreal is an example of location, name, density, recognition can be different, depending on the domain. A clinical notes. the entities you will be recognizing there will be more than just personal name, and even personal name needs to be distinguished. , depending on the domain, you can also define your set of named entities. and even for general domain you can expand these named entities, for example, you can distinguish between different kinds of location and GPS, which is geographical political entities,  you can distinguish between entities  city names, country names. continent names, and then you can distinguish it from entities  mountains. last time we also talked about the streams. You have the entities  organization. Come and you them and you need a scheme , that you can annotate this properly. But  we have many schemes. There's iob one there's iob 2, that is, I/O BA scheme, and there are many schemes. on the board you have,  3 kinds of scheme. the 1st one that was proposed is, I will be one. I will be 2, because this is the one that is mostly used in standardized data sets. But if there is an entity that's an organization that  starts after you received in Montreal, then you will use the B, the B tag. This is the 1st one. the iob. And everyone asking is the same. The 1st question is, how do we have more features to? how can we include this feature into the standard agent? , the only way a reason why we have independence assumption is  that it's tractable  to compute this joint probability. But for this community talk, it just learns everything in your daily. And in 2021, someone proposed. But what we are saying is that even while learning this function of xt going to yt. in , we are concerned with 2 things are these transition probabilities from one participant to another one. and also the emission probability for a meeting award given attack. And here we replace the product of numbers by just a linear combination of weight and feature values. which we completely simplify the what we are doing. , what is the probability? this requires a lot of feature engineering. What's the question? But there's a slight difference. We have the initial pro activities. yes. Good question. I believe that's that's the way the author has proposed it. Yes. There's no analytical emery solution. yes. We normalize in a the definition of. Yes, if you do it over everything. because that's the probability, . And at the last states, we just solve over everything. the forward algorithm isn't computing probability of y given X, it's computing Z of X,  it's computing Z of X, yes. 0 vex. which approximates using the second derivative . instead of maximizing the log likelihood. what if you take a derivative of this? This is what we're going to find after taking the derivatives. Can you see it's too tiny? and if you apply the log we are going to have some extra this time. then you are good to have summation. Bring up the submission all . But the 1st part 5.  this summation will go away because we're just concerned with one sister cake. And then we can also apply the derivative for this one. this population will stay because of derivative. And here we have to sum over all the States wide information of solution of team 5, 1, oh. And if we take derivatives for this one. Please go to the thing on Tikka here. You're going to use the chain rule. have one solution. we need to compute the derivatives of what I'm inside, and then we have. We have the solution over T, because we are only interested in one particular case. I think the only difference is this solution can  go out. This does not depend on why,  it can ring. And then you have probability of 1, 5, 3, 1 x, ? When you have the solution. Yes. Yes, I didn't understand the last step where the 2 sums become 3 sums, and it says, can rearrange in terms of local State transition. here you have , instead of having yt. if you want to interpret it, , we have 2 things. If you go back to the last slide. the F of K is  a when you talk about the overall ingredient is the difference between this one. because this one is taken estimation over every, over the over, the entire Z of x, which is the orthogonal  the idea is that when the compost likelihood is maximized the gradient is 0.  the difference is 0.  intuitively. Yes. This is the sum. it's it's in the sound for all the eyes, and then in the  line you take it out, and then we take the derivative over just one log set of exposition. It's the derivative of the sum of all of them. I will go by this again, and probably send you an updated version on it. They didn't take exit into account."
    ],
    "Topic 3": [
        "today's class lecture 9, where we'll continue on hmms, and we'll  move to conditional random fields. today, we'll consider sequence modeling with features with a focus on linear chain conditional random fields conditional rental fields. , when deep learning came around it was still very important to have conditional random fields to  improve performance. And today we're going to see how we can go from Hmms to crf. , they are not they're still very useful to today. Of course. That can do almost everything  but for token classification task. And maybe some of these methods can still be useful in practice. the last time we talked about, I think we finished off with also provides learning of Hmms. Given an input X for generative model. A very simple generative approach would be of naive base. And if you have been able to compute all the statistics needed. Can we learn this general probability? And you can also emit all one based on every single State. last time we discussed the following. Given Theta. you need to know what is the likelihood. and the likelihood is what is the probability of all given Theta. And we said last time that you can easily compute using dynamic programming, you can compute the forward. You can compute this likelihood. P of all, given theta using either forward algorithm and backward algorithm. And if you're able to compute that, you could also integrate that into the computation of What do you call it? O given theta. And for that you can use the vertebia algorithm and vertebia algorithm is very similar to the forward algorithm. You repeat for a while, and then you predict the current state sequences, using the current model. And that current model initially, just initializes randomly. The idea is that again, you repeat for a while very similar to what in the last slide you predict the current state sequences, using the current model with the vitabi algorithm. on to go more into the details. To qt. the idea is that normally you initialize what is your Sita K. Because Theta K. You don't know, because there's no data to learn it from in the unsupervised case. Algorithm. I think maybe I still have it in just a minute. this one where you have you can compute. I'm using this. , you don't know them. Given Theta K, you computed using the entire forward algorithm at that state. No, you don't. Random values for all this. and if you generate this from any probability distribution just to fill all these values randomly, initially. But the initial value you don't know. you  just want. I just want to be sure that I was showing the same thing on zoom on the class. You fill this matrix. This is the bow vash a guardian. once you re-estimate your A's and your B's, you have a new value of Theta K plus one. and then you can go back to your E step and perform the algorithm again. how do  you are making some progress? You  you're making progress when the training set likelihood , you're not making progress. The idea is that if you can estimate the likelihood given Theta K plus one, and the probability is bigger than probability of theta. Then  you're making progress. And this is the way  you're making progress. If the values you have generated in the metrics are very bad. but you cannot try to  categorize things  the  phrase, rather than only is a group. And also we describe the name density, recognition task, which  doesn't require you to annotate every single word but import. You can have something  patient name. You can have something  doctor's name. if there's no scheme here, it's very difficult to know the entity. And one of the most popular schemes is something  I will be tagging. But  we just call it Iob or BIO, and if you see bio, usually we are referring to. And then we just say, , every entity start with iod. these are   the different popular schemes that are available for any annotation. Hmms. And this might be useful for Pos tagging, for example, we can have important features of our words that , we can integrate to this. to the algorithm that makes it very easy to predict, for example, in English language. these are some of the shortcoming of standard Hmms, because  it's difficult to add new features. And the answer, today we want to talk about crf, which gives us an opportunity to have new features  to our model. You want to lend the judge probability  if you want to classify y given x. But for discriminative model, you can  learn the probability of y given x directly without learning to join partners. ,  this is more  a having a tax specific model for secrets labeling. if you learn a giant probability and it's a good one, you can  generate new examples. , there's an  have been used for a few years. I know that which is  a modification of what you already know. how do we modify the original formulation for our dhmm. for the linear chain crfs, conditional random field. we can learn the probability of Y given X using this function. the present one and the input  and we also have a normalization constant, which is all of our order in states. And I'm going to define what will be F of K. This is the new function you want to learn. remember, what we want to learn is the probability of y given X. Minus one to yt. and  we replace it by this indicator function of yt minus 1, 2 dt. This is the very simple definition. it's just going to give you either one or 0 indication function. If it's false, it gives you 0.  that means this function of Dt to n, and we either give you one or 0. ? the idea is that with this we can  add new features. We want to know if a word is capitalized. Once ending with Ed, we can add another feature  that, and  that, we can add more features to our modem. That is the idea of adding new features to Cf. Which we are unable to do directly with each of us. And there are many, many features you can add. If the 1st word is a determiner, you want to add a new feature,  there are new features that you can add. part of speed tagging, using Crm, you have to come up with a lot of features. To be honest, you have to find features yourself  you can  just a minute. the more features you get. You can improve your performance just by coming up with new features. , which makes  very easy to extend. for the forward algorithm and , we need to compute the likelihood. We are only interested in the value of Y give an X.  this is the forward I got in for Hmms. which can be user defined. based on the features we want to add. you have the exponential of this and these values here you find out that these are  just these are just indicator functions which I don't want or 0. But I don't think it's it's going to ruin anything. We're just taking the maths. , aren't we using the forward algorithm to compute Z of X. And for a gradient asset. you walk in the direction of the gradient to maximize l. Of theta. But of course you can also do gradient descents where you have a negative of that. Given the sense you minimize but of course there are other metals  the conjugate gradient, or what is called the Lbfgs. for the gradient descents. first, st you compute every other thing you need to compute using the forward algorithm  a forward algorithm. And then you can estimate new values of your data after taking the derivatives. And here we can  compute what is the gradient of the log likelihood based on the Crm formulation. I have the proof also here. But I think we can go through very quickly. we'll walk this on the board. And then the availability of why. , Alex. K. , I think this is very easy to estimate, but this will. we really have the submission of vaccine here. You will find out that everything here is very similar to the formulation we have here above. , I'll see. Claris Gu: Hey? Minus one. we just changed the expression. But let me double check my notes, but I think from the very 1st step the sum over, I we just forgot to write it  to the . No, no, because in the formulation here. in terms of the interpretation of gradient. We have the expression here. minus. We have this expression on the left side. minus the expression on the  hand side. And what is interpretation of that? because these are uncrafted features based on what you have in your compass. if you want to know if something is capitalized, you can estimate this from your journey compass. This means that finding parameter estimate by gradient descent is equivalent to telling our model to predict the features in such a way that they are found in the same distribution as in the gold standard. That's how crf is able to work based on the user defined features. If you take the derivatives with a specific Theta K, you're going to have this expression, which is Theta K divided by sigma squared. Based on the law of derivatives where the 2 above is going to cancel the 2 below, and then you have minus Theta K divided by Sigma squared. And then you find new values of Theta, and you do this over and over again over many iterations to find your ideal setup and , I guess that's it. Cool the deadline today. Think that's also a demo. , where each class is. And it's just a perceptual or no. And it  it accounts for whatever features we include. But here there'll be many more  ."
    ],
    "Topic 4": [
        "To confirm everything. and name them to recognition, and they were  some of the most important models that dominated the field for  more than 5 years. And the interesting thing here is that you can  combine conditional random fields with some other deep learning framework  Cnn Lstm. By Lstm. For the case of Patos Beach. it will be the States will be the pos tax. The idea is to  the idea is  to compute the joint probability. you are not able to compute the jump probability every time. Just give me more native model is just trying to optimize , can I get the a local minimum or the global minimum? If I optimize this loss function. And the idea is that. Then you can use em algorithm to  estimate the labels. and then you maximize in the maximization stage you try to get a better initialization. and then you can see if you're improving. just to revise what we did is that it's possible to compute this iteratively, even if there is no labor data. and the idea would be to predict. And after that you update the current parameters using the current predictions as in the supervised learning case. And after the at the maximization stage, then the idea is that, you see, can I get a better Theta K plus one. I computed the expert accounts based on initial values or randomly initialized data K, and at the maximization stage, can I get a better one. that I can have a better initialization. what we discovered is that . And then, if you apply the E step. Are coming from forward algorithm and your betas are coming from the backward algorithm while trying to compute the forward algorithm and the backward algorithm. and for the unsupervised setting you are not able to compute these alphas and the betas  but 1st you assume some initial values for the B's which is your emission probabilities, and then you assume some initial values for the ace with which are your transition probabilities. You'll be able to compute your alphas for the forward algorithm. And then you also be able to compute your betas for the backward algorithm. And once you are able to compute this, you'll be able to run your Em algorithm even for the 1st state, because you randomly initialize your A's and B's because they are known, unknown. Yes, because you can  use forward algorithm. it means you initialize the entire table as random values. Great. oh, . To be honest, you can generate this for me. They are better. better probability distribution you can use. because there is a formula to use. I guess I think I'm sh Oh. You do with some random initialized values, and then you are able to compute your Alpha highs and your better eyes. And the maximization stage is that you  want to get a better values or better initialization for A's and B's. the hard em, this is more. This is over a single tag. why the soft em, it's more. and  for the em, this is what we are doing. A small soft em soft where we belong into soft game. Oh, . And this likelihood keeps improving. Then  that you are learning a better estimation for your T. 10 k plus one. And of course, there are some additional proofs that you can check here. And today we can move to the  topic off. I forgot the last the last thing we discussed is that apart from part of speed tagging, there are also other sequence bodily tasks  chunking where you are not only classifying every token. you can use any. Our task also in the biomedical domain where you will not be identifying locations because that data, there's no location. I can give you an example of 2 applications in the biomedical domain you can be. You can have something  age. You can have different kinds of symptoms. And here the idea for any error is that you  need to detect spams of multiple words that are relevant to the entity. And here it's clearly that all of them are multiple organizations  Magu is different from you. Here you have what is called the beginning of the entity. and then you have the inside of the entity, which is the eye. the 3rd example, here you have what is called  the start of the entity. if you have,  a multi word expression, you  don't use B, you just use the start of the entity, the inside of the entity and the end of the entity. and for every other one where they are not much a word you use. B just beginning. if you can add this feature even just by writing rules, without all this fancy, according, you may be able to detect a lot of proper notes. This is what you want to classify, but for generation model. But you cannot use this to generate new samples of water pos sequences. or you can use it for data augmentation to generate new examples. the question is ,  the idea of crf, because , these are  research driven work. here you find out that we can learn a function of Fk. FF key, and then we normalize it. and for just to go back to the idea of the . we  replace what we have in the , we have a function from one part of speech which is in the YT. are you familiar with education function? you just have inequality inside, and if it's true, it gives you one. that's the idea. Oh, that's the 1st modification. That we cannot add in agent hubs. in terms of the inference. the idea is that we still use things  your forwarding. And also we need to find the States that maximize the joint probability that's for the  and for the crf, what we are doing is to  compute the Z of X, which I'm going to show you how to compute based on forward algorithm again and for the Vitambi authority. We are learning. B, and then we have, the transition for a brief space. For the Crf, we are just interested letting a function. Fk. Why is the exponential function? E to the oh. It's coming directly from the formalization which they're very sure of. , it's the topic. And our reference. But even if you have the log of exponential, the big number you can use this log sum of exponential trick that is not gonna ruin your estimation. But of course there are also other good Edison methods that can be used in terms of convexity, which many of you may be familiar with , when you have a convex function. It's going to become a convex function which I believe that. we normalize it here. why aren't we normalizing here? What are we normalizing? You'll find that you're gonna have this set of things. , it's complicated. and then you work. You work to minimize the loss function. get an ascent. And that's how you can convert a concave function back to a convex function. Yes, it's too small. Here you have the love and the exponential which we can cancel out. Go ahead. Why did you take the Derek and see of a loss function with respect to a particular? If you take the derivatives of the loss function with respect to a particular etc. because this is the submission over every PPYI give them a time. from 3rd or . you have the same expression information over here, and then we are 14  slide. one t, 1 t management. Management. oh. Why don't see 14 number one x, 2. the local state transition. There's a 3rd sum over. and the last one which will be the expected distribution of Fk. Another thing is that you can have regularize a regularizer to this. I know some of you ask about regularizer in your homework assignments depending on the model you used to. You can have L. 2 regularizer. This is an example of L 2 regularizer. And the idea is that if you do this stochastic gradient descent over many iteration you can  approximate the gradient decent category and the idea is that  you initialize what is your values of details randomly, and then you randomize or order over your samples in your training compost. That should be sum also for all the guys that should be some of our work. The  step, if you get out of that. Obviously, that's not . But this is, there are webs, ? It's  a soft Max. And what is Theta K. Is it still initialization, transition and emission? It's just  a number, ? And we are calling the which will be one the hard em, ? And we talked about both for unsupervised  we have no labels. And we're we're trying to  iteratively find,  the best labels, is there? , which algorithm, , , , when would you use the software  if you have,  an unsupervised problem?"
    ],
    "Topic 5": [
        "Awesome. We're very popular. And then you can  boost the performance by one or 2 points. Can you help shortly, Doc? It's you can   go through it with generating approach or discriminative approach. This competitive approach would be  your normal Asvm. the  is an example. Another example of the generator model. Why, as you will see in a couple of slides, crf is an example of a discriminative model. Given X, your approach is  to. I'll try to learn the joint probability between X and Y, and the assumption is that if you can learn successfully the joint probability between X and Y, then you learn everything about the model. And also we add, that is what we call the state probabilities, and for the emission probabilities, we say, if you are able to successfully learn the generative model, we will be able to also have the initial probability, which is the probability of absolute given the State. You can also emit every, all eyes based on every Q state. Because our focus is to learn this joint probability, which is the probability of Q comma O given the parameter theta. first, st for you to compute this probability of Oq. Into the computation of the entire State probability, which is probability of Q. Comma. And then you update the parameter of your current model  that you can have a  based on the current predictions. for the Zetabi algorithm. again, for the emigrating the idea is that we believe that we randomly initialize Theta K and your Theta K is all your  all your A's and B's in the, in the last formulation, you randomly initialize them, and once you have randomly initialize them. And you do this attractively over a couple of  you. You do this over a couple of times. To state J. Let me go back to. If I go to the example. let's assume you are a zoom. Maybe Goshen distribution. then the  thing is that if you have all these values, you can run your forward identity ? , let me go back. let me go back. at the E steps you already assume values for Theta K, ? your B's your, , are your A's, because these are randomly initialized values. And based on this, you can  run the maximization stage. keep your smart. This is distribution of loan books. And and this is the stock version of the em, and we can  relate this to what we have done previously. State on. And if you do this a couple of times. Accept the important entities in the sentence. And, for example, in this sentence, Maggie University is located in Montreal, Canada, and my gear University is an example of an organization. , technically, you can have location. Maybe all you need to identify will be things  disease of patients. exam. For example, let's assume you want to analyze. You can have something  disease type. and reverse and give them different kinds of entities. there are different classification for any hour that we can  use depending on the application. Let me try to give you  a 3 letter word, and I can show you the different schemes. ,  what are some of the shortcomings of the standard? if a word is capitalized, this is most likely a proper no . How can we add this feature? I was telling you. You 1st have to build or try to learn the joint probability, and once you learn the general probability, everything becomes obvious, of course, with some assumption  independence assumption to make it easier. And this is what we typically do nowadays. Multiplied by another indicator function where yt equals. indicator it will give you either one or 0.  if the value, the relationship inside is true. one example of the feature is . Then we have a feature  that. What is the indicator function that yt equals stash? When xt is capitalized, we can add a new feature  that. you can say, , if the lens is less than 5, you want to add a new feature. and the interesting thing is that when you're working on Crs. based on what you define? This is indicator function. For example, you can say yt equals a part of speech  we showed in the last slide. And then you'll say at the same time when xt is capitalized. let me show you the last one. every other thing is the same for the forward agriculum. I  the exponential. you'll be either multiplying by one or by E depending on the result of the multiplication. But the way we learn it is that, unlike you can. There's no closed formulation that you can derive that this is the mle for the crf,  you can. But we have to learn. It's using gradient descent or one example of gradient deter method is Newton methods to find where the gradient is 0. If you take the negative, or let's say when you have a concave function, if you take the negative of it. we keep moving from one state to the other. You maximize. You minimize the negative log, likely. First, st let's define? Can we start over live? and if you substitute what you have, then I think  computes. and then we have a logo. what would the left is summation of I. Submation of T, and Theta K is done, and then what you'll have will be the meanings F of K. One C y, 2 minus one. This will be equal to one over 0 of x. the entire thing, one over Z of x. and then we have the exponential of this. This call is the explanation. I'm  if you want to speak with the regulative one. The final expression on this , salvation solution over, apply. here we have y  music in the slides. but I will confirm my notes, and maybe I'll post on it here. which is on the left hand side and the  one. the one on the left hand side can be seen as the empirical distribution of the future K. In the training purpose which you can  estimate. and if you have the ultra regularizer over this you, if you take derivatives of Theta K squared, divided by 2 to I forgot this one Sigma Square. and the idea of stochastic gradient descent is when the mini winning batch size is one that's where you have stochastically resent. board line, minus log Z of X. But I'm working on that. Another feature. Or features we had in the slides. Because is it because it,  you get this exact state specifically that maximize is there? Which cases would you prefer? Let me just."
    ]
}