[
    "Hello, How are we all doing?",
    "Good.",
    "Thank you.",
    "All ,  welcome back to NLP.",
    "today it's me and then starting  week you'll have David for a few lectures.",
    "It's the mic working.",
    "OK, I think that's better.",
    "OK,  today we're going to start with a module on text classification and we're going to spend a few lectures on text classification before talking about other things.",
    "Just a few announcements.",
    "first of all, the readings for the course, you can always find them in the on the 1st slide of the lecture slides.",
    "And also this is the main announcement.",
    "Make sure that you have access to the Ed discussion platform because that's where we're going to be releasing all the materials.",
    "the lecture slides have already been posted for today's lecture and you can also ask further questions after class there and I think.",
    "We're posting office hours.",
    "I think my and David's office hours have been posted and we're going to get organized for the Tasmania and some of the Tasmania will have office hours as .",
    ".",
    "Are there any questions about course organization?",
    "far, no.",
    "OK, great.",
    "I'd  to start by reviewing what we talked about in the previous lecture.",
    "Let me turn my phone to Do not Disturb.",
    "OK,  here's here's some basic questions based on yes or last week's lecture.",
    "I know you probably forgot everything over Labor Day, but let's try.",
    "OK, first warm up question.",
    "What is the difference between computational linguistics and natural language processing?",
    "Does anybody remember from the discussion?",
    ".",
    "Yes, that's a great answer.",
    "I'm sure I'll repeat it because I'm sure a big classroom, I'm sure many people didn't hear.",
    "computational linguistics has more to do with the scientific aspects of the field.",
    "It has to do with understanding natural language as a phenomenon using computational methods, whereas NLP is about the engineering aspects, developing useful, beneficial applications.",
    "it's closer to .",
    "that's in that sense, it's closer to engineering.",
    "But remember the caveat from last class that I mentioned, which is that in practice people often use the terms interchangeably .",
    "in any particular situation, you have to think about what do people ?",
    "Mean when they say NLP?",
    "OK, here's another one.",
    "Give definitions for natural language understanding and natural language generation.",
    "let's start with an NLU.",
    "Can someone give me a definition of NLU, ideally without looking at the slides from last class.",
    ", .",
    "It's.",
    "Something  processing commands.",
    "With understanding how proper theory just  turning language into something more useful.",
    "Yes.",
    "I  the second part of your what you said, turning language into something that is useful or some other format , some  abstract format.",
    "I think the first part of your answer is given examples,  that's good too.",
    "But , NLU is about mapping.",
    "The another way to think about it is to map from the form of language to its contents in some way that can be.",
    "Used.",
    "For example, by an automated system to do further processing, or for the purposes of applications or just do some abstract representation we can analyze.",
    "What about natural language generation?",
    "What is natural language generation?",
    "Oh, there's something in the chat.",
    "Oh shoot, I forgot to unmute.",
    "for that.",
    "I forgot to unmute.",
    "You missed all of the intro, Yes.",
    ",  inferring patterns in order to produce more natural language generation, more natural language text, .",
    "I would say NLG, let's stick.",
    "To.",
    "What it is, which is the generation part,  creating natural language generation and then how we do it, we can say that's all part of NLG, but in the definition then I think the key part of the definition is producing natural language text or speech, OK. And then the inputs can either be from that format, that abstract representation that we talked about, or it can be from other texts or other language data as , or even  images or whatever, ?",
    "all of that can count as NLG.",
    "OK, great.",
    "I have more questions.",
    "Review.",
    "OK, what's the difference between phonetics and phonology?",
    "Anybody else?",
    "OK, then you'll have to review that.",
    "OK, what about the difference between morphology and syntax?",
    "If people don't answer it, then I'll just make sure to  make a note and maybe put it on the midterm or something.",
    "OK there.",
    ",  that's great.",
    "morphology is about word structure.",
    "It's about analyzing the internal word structure and how words are composed.",
    "and then syntax is about analyzing, usually about sentence structure and how words can be.",
    "Put together to form sentences.",
    "And what about semantics versus pragmatics?",
    ".",
    "Yes.",
    "semantics is about the meaning usually of say a sentence, perhaps literally, and then we can talk more about that, what that  means later on.",
    "And then pragmatics about is about meaning and context.",
    "OK, I'll come back to phonetics and phonology.",
    "that we have, maybe people are less shy .",
    "Does anybody remember the difference between phonetics and phonology?",
    "Yes.",
    "Yes, that's .",
    "thank you.",
    "phonetics is about the speech sounds themselves and how they're articulated, whereas phonology is about the sound patterns,  how those sounds are organized to.",
    "Come up with abstract categories to make up a language system, a part of a language system.",
    "OK, that's good for review.",
    "thank you for all the answers.",
    "I was trying to get you to all answers  that later on you feel more comfortable asking questions in class.",
    "And if we have class discussions, then maybe you'll feel more comfortable speaking with each other.",
    "I do encourage you to speak up.",
    "I know it's tricky in a big classroom,  thank you for everyone who volunteered their answers.",
    "OK,  I have heard this pitch repeatedly from multiple students across multiple years.",
    "maybe please, , you can decide whether you want to make the same pitch to me.",
    "But the pitch is this.",
    "We're gonna get rich by creating an NLP company that will analyze some  data in order to make stock trade decisions.",
    "OK. And  maybe you can retax  risks and uncertainties abound.",
    "Maybe it's in  some SEC filing or something or maybe not.",
    "Or is it just some news article about a company and there's some restructuring?",
    "Is this going to be good or bad for the stock price of that company?",
    "Or maybe this company has solid fundamentals and good growth prospects, etcetera, etcetera.",
    "can we analyze this textual data and make trading decisions based on that?",
    ", OK,  for today we're going to focus on the part of maybe mapping between this textual data and some output label, OK?",
    "It could just be  sentiment, is this positive or negative?",
    "Or maybe it could be a decision  buy or sell.",
    "And  then we can come back to this at the end of the class,  should you create the startup?",
    "But but for that's  the hook.",
    "for today's lecture, I  to talk about how do we  formalize this a little bit better.",
    "OK,  how do we turn texts into labels?",
    "And that's exactly text classification.",
    "But of course there's a bunch of boring definitions we have to go through to get there.",
    "OK,  , text classification.",
    "The main topic of today's lecture is to assign a label or category to a piece of text.",
    "if we were to take the previous example and talk about predicting positive versus negative sentiment, then that counts as the task of that's an example of the task of sentiment analysis.",
    "But there are many other text classification tasks, which  are a big part of our lives whether we know it or not, ?",
    "for example, one big 1 is a spam detection.",
    "deciding whether an e-mail you receive  appears in your inbox or appears in the spam folder, ?",
    "that's without that, I think e-mail would just not work because something  90% or more of all e-mail that's sent is  spam, ?",
    "But most of that you never see because it gets filtered out by the spam detector.",
    "that relies on a text classification system of some type, but there are other ones and there might be a language identification 1.  often these days you can get your phone to translate for you and maybe it's able to or.",
    "Even you just type something into .",
    "A search engine box in some other language and it can automatically, sometimes it can automatically detect what language it is in and translate it to English or French for you or whatever language you speak.",
    "Or here's the third one, authorship attribution.",
    "deciding who wrote a piece of text.",
    "This can be sometimes interesting.",
    "There have been studies.",
    "Of.",
    "Of, say, historically,  text written in the past and there might be  authorship disputes or  I think there's for a while there was this something about , did Shakespeare  write?",
    "All of his plays or something.",
    "And  then people have tried to investigate those questions computationally through computational analysis, and some versions of that can be cast as text classification problems.",
    "OK,  given a piece of text, if you have other writing samples from those authors, can you then classify a new piece of text according to its author?",
    "here are some examples of tasks that you can cast within this text classification paradigm.",
    "then, for the outline of today's lecture, what?",
    "I'd  to do is go through some machine learning basics because that will be useful and important for much of the rest of the course.",
    "And also to talk about a general experimental procedure that we can pursue in NLP and apply that to text classification.",
    "And then we can talk a little bit more about the experimental methodology within text classification.",
    "And today for we're not going to cover all of text classification in one lecture, but we'll focus today on feature extraction and some common processing that people in working with textual data do when trying to process text and pass them into a text classification system.",
    "All ,  then we should start with what is machine learning?",
    "machine learning, here's a definition.",
    "It's using data and statistical algorithms to learn patterns and then applying these patterns to new data to perform tasks.",
    "And the main way that I think about machine learning and contrast that with other approaches.",
    "Is to contrast that with maybe some classical rule based AI.",
    "for example in Rule based AI you might tell a system this is what you should do in this context.",
    "OK,  if you see a green sign, that means you can go.",
    "If you see a red sign it means you should stop.",
    "Something  that.",
    "But it's very rule based and the system designer specifies these rules to an AI system.",
    "And that was how AI has traditionally been done, especially in a symbolic form, up until say, the 80s and early 90s.",
    "to contrast that, a machine learning based approach is about telling the system how to learn what to do from the data.",
    "OK,  rather than say, do this, you give examples and then you ask a system to learn from these examples and figure out how to act in situations based on those examples.",
    ",  this is the main contrast between what to do versus how to do it.",
    "of course, real life is more complex than this.",
    "in practice, most systems in AI is going to be some combination of the two.",
    "You need usually some way of specifying.",
    "What to do in some situations, at least at an abstract level or sometimes at a in a company, it might be the last step of the system.",
    "if you notice some bad words being said, then don't.",
    "Allow a system to generate this output.",
    "there's usually going to be some mix of rule based methods in practice with machine learning, but for our purposes for , having this distinction at a high level is good enough.",
    "machine learning is about giving data and also giving the system a way to learn from this data versus rule based, which is just directly telling them what to do.",
    "And  here's a common research paradigm these days in NLP, which is first, find an.",
    "Oops.",
    "Find an interesting NLP problem that involves language data or involves some  need that has something to do with language, such as, for example, which emails are spam.",
    "Formulate the NLP problem as a machine learning problem.",
    "And  here I have a diagram  You have the input which is an e-mail.",
    "You have your.",
    "Spam classifier and the output as spam or non spam.",
    "And then you can solve this problem by using machine learning techniques.",
    "that's a very common paradigm.",
    "However, I do want to emphasize that NLP is not machine learning and machine learning is not NLP.",
    "they are two different subareas of AI.",
    "Sometimes they have different.",
    ", there's different ways of formulating problems sometimes and different perspectives on them.",
    "I would say that for our purposes, machine learning is one potential way we can or approach we can take in order to solve some NLP problem.",
    "OK,  then within machine learning, there are some further basic distinctions that we are interested in  that we can select the  tools to help us solve an NLP problem.",
    "For example, one basic distinction is between supervised learning and unsupervised learning.",
    "in supervised learning, a model has access to your input data as  as its corresponding output label for the purposes of training.",
    "abstractly you can think of it, you can write it down mathematically as we're trying to learn a function y = F of X where X is the input, Y is the output, and F is the model.",
    "And  during training time, you have access to both X&Y  that you're able to learn these patterns and these associations.",
    "And then at Test time, then you're only given access to the X.",
    "And then you have to figure out based on your learned function F what the predicted output Y is for that new.",
    "Piece of text that new situation.",
    "And we can contrast that with unsupervised learning where there are no labels,  the model only has examples X and has to find some interesting patterns in the data.",
    "OK,  for example here's some more examples.",
    "we already talked about predicting whether an e-mail is spam or non spam given examples of previous spam and non spam emails.",
    "That's a supervised learning.",
    "Problem.",
    "Another one which we'll look at later is to predict the part of speech tag of a word.",
    "for example, the word run can be a verb or a noun.",
    "Ran is probably a verb.",
    "Cat is probably a noun, although these days it can be a verb too.",
    "And the is a determiner, which I guess probably  of it as an article.",
    "a determiner is also another way of talking about that.",
    "Class of words.",
    "what's interesting about this part of speech tagging problem is that we'll see that it maybe doesn't make the most sense to think of it as a standard text classification problem.",
    "Because usually when you want to do part of speech tagging, you want to label every single word in a whole sentence or in a whole paragraph or document.",
    "it's not just one label per document, which is the assumption behind text classification, standard text classification.",
    "It's  1 label per word in a sequence.",
    "And  then that's why we have to talk about that type of approach separately in a different part of the course.",
    "what does?",
    "Learning mean.",
    "in the supervised setting, once again, it means to determine what the function F of X should be given the training data.",
    "And  usually this F, we say that it's parameterized in that F itself is complex and has some internal things you can fiddle around with in order to change what the form of that function F looks .",
    "And mathematically, what we are  doing is we're finding the parameters to the model, which by convention, people usually use Theta to denote to minimize some  loss or error function.",
    ", for example, the model should minimize the number of incorrectly classified pairs in the training data sets.",
    "And we'll come back to this.",
    "And you can also, of course, take machine learning courses to learn much more about that than you'll learn in this course.",
    "And another distinction we should make is between regression versus classification.",
    "in supervised learning, we're mapping from the input to the outputs.",
    "And depending on the form of the output Y, it can either be a regression problem or a classification problem.",
    "in the regression problem, the Y output is a continuous outcome.",
    "It's  a real value, whereas in classification it's a discrete outcome, which is.",
    "What we're going to be concerned with today.",
    "that's why it's text classification, not text regression.",
    "spam versus non spam, verb versus noun versus adjective.",
    "far  good.",
    "OK.  , we really won't talk much about regression in this course, because in NLP usually we're analyzing into some output form that is discrete, or we're generating texts and texts you can think of as a series of discrete output.",
    "Tokens  words which have been discretized by our writing system and .",
    "But here's one quick example.",
    "how many people have seen linear regression before in some other course?",
    "Great.",
    "Almost everybody, .",
    "the classic example in your statistics course has was might have been  correlating father's heights versus son's heights.",
    "This was one of the earliest applications.",
    "people found out there was a correlation.",
    "OK.  then you can talk about a line of best fit.",
    "And then you can use your father's height to predict the, the son's height.",
    "And then in the form of linear regression, the  it's still you can think of this  as  a supervised learning problem.",
    "where you're, it's because it fits ?",
    "You're you probably didn't learn it that way in your.",
    "Statistics course, but you can't think of it in that, in that sense, in that you're learning this function where the data set is  your training data is  father and sons heights,  the input is the father.",
    "'S height,  that's just One X.",
    "And then you're fitting the parameters of the model, which is the coefficients A and also the bias term B.",
    "And then the output height is the sun's height Y.  linear regression is very special in that you can solve for the best value of A&B analytically by just solving the least squares equation, which you may or may not remember.",
    "But in general in machine learning, it's very rare that you have cases  that where you can get an analytic solution.",
    "in practice, usually there is some iterative algorithm that you have to run in order to minimize your loss and unfortunately.",
    "Involves a bunch of calculus in linear algebra,  that's why you have to learn those.",
    ", they're also interesting in their own writing.",
    "All that.",
    "But OK.",
    "I said, most NLP work involves text.",
    "Involving text ends up being classification problems because things are often discrete.",
    "The linguistic units of interest are often discrete, and  we'll be talking about classification today.",
    "You don't really have to know these distinctions, but , these are the kinds of distinctions that you might be interested in an LP,  words, part of speech tags, semantic categories, or discourse relations.",
    "I'll also just quickly elaborate a little bit on unsupervised learning as , because this is super interesting.",
    "And also if you're interested in computational linguistics rather than NLP, you might be more interested in unsupervised learning in some ways.",
    "Because if you think about the problem that you all solved as  a toddler by learning your first language, , it was really a grammar induction.",
    "Problem in that I'm guessing I'm going to take a guess that your caregivers  your parents perhaps or your other caregivers did not tell you this is a verb and this is a noun.",
    "And , , they didn't give you labels for all of your, the language you produced or that they said to you when you were a toddler, presumably.",
    "OK, instead you just said things or you listen to them and they said things and then you  maybe  got fed at sometimes and you got toys or whatever.",
    "Or maybe another time you said the wrong thing, you didn't get a toy.",
    "And that's  it just, and then you language learning just happened, ?",
    "And   you can think of that as an unsupervised learning problem where you're trying to figure out some structure in your first language just based on.",
    "Exposure to it.",
    "And this is not as impossible as it seems.",
    "OK.  for example, the words B&A, they appear in similar contexts, they appear near other classes of words.",
    "Which themselves have similarities, and  you might be able to infer that they belong to the same syntactic category based on that.",
    "On the other hand, words  vary and hope don't appear in similar contexts, and  then you might be able to infer that they belong to different.",
    "Parts of speech.",
    "Also, a different way of thinking about this is  maybe learning word relatedness.",
    "we know that cat and dog are related words and maybe we learn some similarity score associated with that according to some optimization algorithm.",
    "Whereas good and bad are related words as .",
    "But maybe eventually you figure out they have the opposite meaning but you learn some similarity score related to that.",
    "these are all examples of unsupervised learning problems.",
    "Where there's no explicit.",
    "Label for training.",
    "And yet there's useful and interesting learning to be done based on the patterns in the data themselves.",
    ".",
    "Yes.",
    "By label,  an output variable.",
    "That's .",
    ".",
    ", ,  I guess for  the case of  first language acquisition and learning, maybe some people have proposed, maybe the label is .",
    "It's not language, ?",
    "At least it could be  you  get the toy or the thing that you were demanding.",
    "And  that could be, , maybe that's some  reward, .",
    ".",
    "But , it doesn't seem  it fits very  with the supervised learning setup that we talked about earlier.",
    "OK, great.",
    ", we've gone through some of the basic definitions.",
    "And  let's talk about the overall process of building our get rich quick scheme classifier.",
    "OK, ,  first we have to define the problem and collect some data set.",
    "OK.  we've defined potentially the problem OK given some input text.",
    "Predict buy or sell or.",
    "Hold or whatever.",
    "Then we need to extract features from the documents.",
    "Then we need to train a classifier on a training set and then apply the classifier on some text test data.",
    "for the rest of today's lecture, I'll focus on the major parts of each of these steps, with a focus in particular on step #2.",
    "And then  lecture, David will talk more about step numbers 3 and 4.",
    "OK,  problem definition.",
    "problem definition is  a big part of NLP.",
    "And it's something that's receiving more and more focus these days because we have  these powerful large language models and transformer models, ?",
    "that means we might be interested in figuring out what kinds of problems of practical consequences we can solve with these tools.",
    "however, because these things to do them properly, they tend to be more context specific and they tend to involve a lot of skills and.",
    "Research methodologies which are maybe less quantitative and more qualitative and might involve  more stakeholder consultation or  other kinds of analysis, we'll unfortunately cover less of that in this course, but that's not to say that this is not really critical and super.",
    "Important.",
    "It's just we haven't figured.",
    "Out how to teach it yet   we'll cover it a bit less in this course.",
    "But here are some of the basic questions that you might be interested in order to do problem definition while in NLP.",
    "first of all, what is the problem being solved?",
    "OK,  here's another point which is becoming more and more relevant.",
    "Is solving this problem  socially useful?",
    "Or maybe are there ethical concerns with attempting to automate this?",
    "you can imagine that there are lots of interactions between this and perhaps  your anticipation of how  the model works, ?",
    "There might be.",
    "For example, if there's anything involving sensitive  involving demographic variables, you have to be very careful and think about if you have a system that either it's imperfect or even if it's perfect, what if it involves demographic variables?",
    "Are there any potential harms that your system can cause?",
    "you might have to do additional thinking and consultation to work on this.",
    "And then the other part of problem definition is to just be able to map between the things you care about in that domain to the formal parts of the formalization of the problem.",
    "in our text classification case, we had the Y and the X and the F ?",
    "how do we  map between, for example, emails and spam or non spam to  the values of the X and the Y and the form of the F?",
    "And what are the output categories?",
    "That's part of that.",
    "And also how do you get annotated data out of this format?",
    "Because remember, we're in a supervised learning setting.",
    "that means we require having training data and having already a labeled set of annotations.",
    "we need to have some reliable source of that in order to be able to train our system in the 1st place.",
    "You might have the most interesting problem in the world, but if you can't get an easy or.",
    "Cheap or reliable or high quality way of getting annotated data, then you can't really apply the methods that we'll talk about today.",
    "all of these are important questions and they're all a big part of the NLP problem.",
    "But  I said, we'll unfortunately gloss over that and we'll talk instead about.",
    "Suppose that you have that done.",
    "OK,  maybe we have a set of labels of news articles associated with companies with  buy and sell signals, OK or?",
    "We have a set of emails and then we have  spam or non spam labels from the past.",
    "Then we can apply the rest of this pipeline in order to train a text classifier and then evaluate it by applying it to some new data.",
    "that's what we'll talk about .",
    "I want to reemphasize how important Step 1 is.",
    "I know that these days you can go on Kegel or some other source and get lots of data sets that have been pre annotated for you.",
    "And that's both very nice and also  scary.",
    "it's very nice in the sense that this step one is usually a lot of work and it's very difficult and costly.",
    "it's great that people have done the job for you in some sense of  gathering some data and.",
    "And annotating it for you and giving you some training data and maybe a test data to evaluate your system.",
    "But it also means that you're locked into their answers for these questions.",
    "never forget that, ?",
    "if a company releases a data set, an annotated data set.",
    "For other people to work on, then you're locked into what they're interested in and how they chose to define the labels based on their interests, their commercial interests.",
    "And you don't, it's not always easy to check whether the way they've answered these questions corresponds to how you might  to do it.",
    "OK, there might be bias in the way they collected their data.",
    "There might be bias in how they got annotated or just how they formulated the problem in the first place in the categories.",
    "the  in the current era where there are lots of data sets online that you can download and play around with, it's both great for the purpose of just  running some algorithms and optimizing, but also scary in that.",
    "Just don't forget that you're relying on other people.",
    "Always comes with some costs.",
    "OK,  back to machine learning stuff.",
    "we're going to talk about the learning problem in a little bit more detail, and especially the feature extractions.",
    "OK,  in our learning problem then we have to specify each of these, ?",
    "the Y, the F and the X.  specifying the Y is maybe the easiest in the sense that you just need to have some output.",
    "Variables.",
    "That correspond to something you care about.",
    "in I think and I'll.",
    "Switch to the spam example.",
    "OK  in the spam versus non spam example you might decide that Y can be either 0 or one and these are.",
    "This is a categorical.",
    "Output.",
    "you can't be a 0.5 or a 0.2 or whatever.",
    "OK,  you're either a non spam e-mail or you're a spam e-mail.",
    "And then that's done for that context, ?",
    "In another setting, then you have to make different decisions.",
    "Maybe you have not just two possible output labels, you might have  5 or 10, but you have to specify that.",
    "And then  we have to also talk about the inputs.",
    "we have our input document which is a text and then we have to convert it into some form.",
    "That can be used for.",
    "That we passed.",
    "On to some machine learning system that will solve some optimization step.",
    "And  here I've put it as a vector X because in practice that's what we'll do.",
    "You'll converge your input document X into a vector of numbers.",
    "And that's how you can then turn everything into math.",
    "And solve that.",
    "Problem.",
    "OK,  then in terms of the feature extraction step, feature extraction refers to taking your input textual document and then extracting features from there that you think the system designer thinks might be relevant and useful to pass on to the classifier.",
    "hence the name.",
    "OK,  extraction in the sense of extracting potentially useful cues from the inputs.",
    "for the spam setting, here are some things that are potentially spam  or might be indicative of something being spam.",
    "And  we would  to be able to  find ways to encode.",
    "This  information into numbers.",
    "OK,  then abstractly then.",
    "This is what's going on.",
    "OK, .",
    "We have document classifier, document label.",
    "We specify what the possible YS mean and then we're going to train a classifier on top of the document.",
    "you have your input document and then feature extraction means converting.",
    "Or you can think of representing that document.",
    "As a list of features.",
    "then you have a bunch of inputs, X1X2X3 up to whatever.",
    "You can have a million features if you want, and then you have some.",
    "Values which are some numbers that are filled in at each dimension and in terms of  your entire training set, then your entire training set will involve a whole.",
    "Series of these,  you can think of it as matrices and vectors  that your training set corresponds to an entire matrix, where each row represents a different sample,  each row is a difference.",
    "E-mail and then in your training set you have the output labels associated with them.",
    "each e-mail can either be a non spam 0 or a spam one.",
    "Yes.",
    "Question.",
    "each X .",
    "what is the meaning of each X?",
    "That's a great question.",
    "each X here, each column is a feature.",
    "a feature could be a word or it could be something else as we'll talk about.",
    "But the way to think about it.",
    "maybe for simplicity, think of it as a word for .",
    "X1 might correspond to the word A.",
    "And then if a appears in a document, then it might be a one, otherwise it might be a zero.",
    "OK, , further question.",
    "if each feature is a word, then yes, you lose information about the order of the words in the documents.",
    "this is one thing to note about feature extraction, which is that in practice they'll always be some abstraction of the full contents of the inputs.",
    "absolutely you will lose information.",
    "And is it acceptable?",
    "That depends.",
    "sometimes losing information might  not be a bad thing, as we'll discuss over the  series of lectures.",
    "But yes, feature extraction will involve some  loss of information.",
    "Yes, yes, yes.",
    "in this setting every input has the same number of.",
    "Features.",
    "That's a good question and there was another question over there.",
    "Great question.",
    "if we use one feature for every word, do we need as many features as the number of words?",
    "In the dictionary?",
    "Potentially, yes.",
    "In fact, it can get a lot more than that because then as we'll talk about, you might have .",
    "Sequences of words.",
    "And then the number of features will go up and up and up.",
    "I don't know who was first.",
    "How do we get to choose which word is a good feature?",
    "for , we're just saying that everything you think might be useful, you can call it a feature, and it's up to the job of the learning algorithm to  and the labeled training examples to help you decide the effects of each feature.",
    "in the past in machine learning, there was a lot of efforts to try to  predict which features are might be useful or not.",
    "But these days the trick is the strategy is to just throw everything into the learner and then use enough training data with enough labels.",
    "To have the learning algorithm.",
    "Figure out which is useful or not.",
    ".",
    "are we just looking for keywords in the setting?",
    "No, we're looking for potentially useful words.",
    "I would say that it's not a wide strategy necessarily to, , it is a strategy, but I you don't necessarily have to just focus on the keywords that you think might be useful.",
    "Instead, the whole point of learning is that we want to, maybe we want to make  fewer assumptions.",
    "And  then you can just pass in all of the words, for example.",
    "And then I think you have a question.",
    ".",
    "here the for , this is just, I want to get across the abstract idea that there are features and the features of values.",
    "And in practice maybe some of them are always  one or zeros, but it depends on your feature encoding scheme the.",
    "Values are not necessarily just zeros or ones.",
    ", .",
    "Any other questions on the general abstract formulation and idea?",
    "the specifics will vary a lot, OK.",
    "There are many, many, many different ways instead of text classification problems.",
    "Some of them don't even necessarily fit into this formulation.",
    "But this is pretty general and it covers most of the basic ones.",
    "OK. Great.",
    "OK.  then the other thing I want to emphasize is that at Test time.",
    "You will only have access to the inputs X and you won't have access to the output Y.",
    "For.",
    "Maybe obvious reasons and that , suppose you get a new e-mail and you want to  try out your spam classifier.",
    "Obviously you won't  know if it's spam or not ahead of time, ?",
    "The whole point is you're using a system in order to predict whether the new e-mail is spam or not, and hopefully it does a good job and it can filter out most of the actual spams without missing any of the legitimate non spams for you.",
    "OK,  ,  as we said, the most obvious thing we could try to do is just to think that every word in a document can be a feature because maybe words in a document are a good clue of its contents.",
    "money might involve might tilt things more towards spam perhaps and teach might tilt things more towards non spam.",
    "I don't know, but  you can imagine, you can think of associations between words and their spam status and  then each dimension of the feature vector of this matrix.",
    "each column of this matrix corresponds to the, for example the presence of some.",
    "Word in the inputs.",
    "But  we don't  just have to record words.",
    "And in fact, usually we can record or often we can try other strategies rather than just recording the word itself.",
    "instead you can record some abstraction of the word.",
    "some common choices that we'll go through include, say, recording the lemma, which I'll explain of the word or the stem, or it's part of speech.",
    "For example, there's a process called lemmatization, which involves removing certain affixes and recovering the lemma, which is the form that you would use to look up a word in the dictionary.",
    "For example, rather than foxes, you might say.",
    "if you had to look at the word foxes in the dictionary, you would look at the word, you would look it up under fox, ?",
    "Because the ES there is a plural marker.",
    "And maybe  of course there's a difference in meaning between fox and foxes, but for many purposes and many text classification systems, it doesn't matter  much.",
    "You just need to know there it's an animal of some type or it's a fox.",
    "And  then you could choose to record this more abstract form.",
    "I'm calling this more abstract because  you're categorizing multiple words into the same more abstract category.",
    "And maybe that's the category of fox, OK. Or similarly, you might have a word  flies, and you can abstract that.",
    "You can limitize that into another form, which is  fly, which is what you would use to look it up in the dictionary.",
    "Or even geese might become goose, ?",
    "Here's one of those irregular nouns in English.",
    "And  in lemmatization, what you're doing is you're recovering that the lemma, and then you're using that instead of the original word.",
    "And the motivation for this is that many of the distinctions.",
    ", it's just to  we explain what I just said, many of the distinctions that are made and required by the grammar of a language.",
    "Might not be  important a relevance to the text classification problem you're trying to solve.",
    "And  by getting rid of those distinctions and recording something more abstract, you're in some sense making better use of your data, because then you can treat all of the documents that contain foxes and foxes in a more similar.",
    "Way.",
    "this is  a trade off between how faithful and accurate you want to present your inputs documents versus maybe how much data you have and what you think might not matter  much.",
    "this is already a very early example of how losing information might  be a good thing.",
    "we're doing it on purpose.",
    "OK,  there's lemmatization and then there's a related procedure called stemming.",
    "And there's a particular stemmer called the Porter stemmer, which was very widely used in the 80s, which is.",
    "And the basic idea is to chop off some endings and maybe sometimes to glue some endings back on.",
    "And it sounds very unprincipled, and that's because it maybe was in that  you're applying a series of heuristics in order to produce a form of some input word.",
    "But , but that  glues  combines together related words in some way.",
    "And this is not perfect, but sometimes it results in a slight improvement in downstream tasks.",
    "let me give some examples.",
    "one example of a rule is to rewrite.",
    "IES into I at the end of a word.",
    "ponies becomes PONI or ational becomes ate, relational becomes relates, or if the word is long enough in terms of some other rules, you can turn revival into reviv.",
    "But because you chop off the AL ending.",
    "it's really a series of it really just is a series of heuristics that people apply in order to come up with things that are not even really English words, but they're good enough in terms of recording them as features in your big matrix.",
    "And the motivation of stemming is similar to limitization.",
    "It's less linguistically  motivated, but it's very practical.",
    ".",
    "You could apply this as  or you can record part of speech tags.",
    "Question ?",
    "why is this practical?",
    "It's because you're making fewer distinctions, and sometimes you want to make fewer distinctions.",
    "That's the main key behind both limitization and stemming.",
    "You're making fewer distinctions between things that you think might not matter.",
    "in these examples,  here, for example, relational and relate, if you  have the word relate, it might also end up being relate.",
    "then you're not distinguishing between relate and relational, for example.",
    ", by making fewer distinctions, you're losing information.",
    "But if you, especially if you have a small data set, that can lead to better performance because you're making better.",
    "Use of the limited.",
    "Amount of data that you have.",
    "OK,  then another possibility is to do part of speech tagging and record the part of speech tags as features themselves.",
    "And once again, part of speech tags are these categories that mark usually syntactic properties or that mark syntactic properties of?",
    "Words  verbs and nouns and adjectives and maybe even punctuation in text.",
    "And it's very useful for things  authorship attribution.",
    "It turns out that different people have different writing patterns that are very subtle, for example, in how we use punctuation and also how you use   function words.",
    "maybe some authors might have very long sentences and have less punctuation or they use they use lots of exclamation marks or they have lots of  parentheticals where you have  dashes and whatever.",
    "And  it turns out that punctuation is a very useful indicator in authorship attribution, but that might involve doing part of speech tagging in order to identify all the categories of the words and also the punctuation.",
    "And  this means that you need to run a separate process to preprocess the documents for their part of speech tags.",
    "And we'll come back to part of speech tagging in a few weeks, but there's a way to do that.",
    "And there's also a common tag set that people use in English, which you can check out here in this link, but it won't do that for .",
    "But , the common theme is that these are all categorizations of the individual words.",
    "And  is the actual thing you record in the cell themselves.",
    "another thing you could do is you can talk about sequences of adjacent words or lemata or stems or part of speech tags.",
    "each feature,  it might not correspond to just  one word, but it might correspond to the presence or absence of a pair of words.",
    "And  this idea is called N grams, the idea of N grams.",
    "for example, if N is 1, then these N grams are called unigrams and unigrams are just words in isolation.",
    "does this word appear in the document or not?",
    "Or how many times does it appear or something  that?",
    "But you can choose higher orders of N, You can choose n = 2, and then it's called bigrams or n = 3.",
    "And these are trigrams.",
    "it's  you have  an adjacent sequence of  two or three words.",
    "And does that sequence appear or how many times does it appear in your documents?",
    "And  a really popular basic approach for training a text classification system then is to just represent your input document as a bag of words or a bag of N grams if you're choosing some other value of N, and then throw it into some basic classifier, which we'll start talking about  class and then see what the performance of that is.",
    "And it's very easy to do this these days,  once you download and install all the packages you can do it in .",
    "Half an hour?",
    "An hour?",
    "just write some very basic code.",
    "If you have the data set, again, assuming you already have the labeled data set, you can load it up, put it into some matrix, run some function in some standard packages, and then.",
    "You can try out these basic methods and see what their performances are .",
    "OK, but  , those are some things we can try.",
    "In terms of the values record in the matrix themselves, there are also different options you can choose.",
    "You can choose to just zero or one representations.",
    "Does that feature appear in the input document or not?",
    "Or maybe you can choose to record how many times does it appear or what proportion of the total document does that feature correspond to?",
    "it's  the count divided by, say, the number of words in the length of the document.",
    "You can do that as .",
    "There are other scalings of these counts that you can run which are more sophisticated and which can sometimes give you much better results.",
    "for example, there's a very common intuition is that we might want to discount the common words  V or A because they are not very useful and discriminative.",
    "They appear in almost all documents.",
    "Whereas we might want to give higher weights to the uncommon words  Penguin or aardvark or I don't know, rare words.",
    ", that's a great question.",
    "in an N gram system does.",
    "Each N gram have to have the same length.",
    "If you want to talk about, say, a bigram, then all bigrams by definition are length 2, and all unigrams are by definition of length one.",
    "In terms of  representing putting it into that matrix of your data sets and having different columns, it's up to the system designer how they want to do it.",
    "for unigrams, usually you have enough computational capacity these days to just pass in all unigrams, although sometimes people might still decide to  remove all the rare ones for other reasons.",
    "Once you get to bigrams.",
    "suppose  someone asks a question  the size of the dictionary, ?",
    "Suppose you have  V words in your dictionary.",
    "Once you have bigrams,  you have v ^2 number of possible bigrams, ?",
    "And once you have trigrams, it becomes b ^3.",
    "even if you have a really powerful computer with lots of memory and  you have access to a supercomputer cluster or whatever, you can't really go up very high in terms of the N&N grams.",
    "maybe you can get up to three, maybe.",
    "then at that point, you have different strategies you can try.",
    "one is maybe what you're suggesting, which is to throw out a lot of the bigrams or trigrams, especially the ones that don't  appear in your data set because chances are most of them won't appear.",
    "And that might save a lot of memory and computational costs.",
    "And , ,  in terms of the features that you  choose to put into your system, no, they don't all have to have the same length.",
    "OK, OK,  here's an exercise.",
    "as part of trying to  make people more social and  maybe make connections for your final project, I would  you to maybe chat with the people who you're sitting  to and introduce yourself, whatever you feel comfortable doing.",
    "And maybe try processing the this input document by extracting the unigrams and bigrams from them.",
    "And then you can turn them into a feature vector by recording their frequencies.",
    "But you have to apply lemmatization.",
    "remember what lemmatization is.",
    "It's what is the form you would use to look up that.",
    "Word in the dictionary.",
    "OK.  then,  I'll give you 5 minutes to do this with your neighbors, and then we can come back and look at what does the feature vector look  for this input documents.",
    "And then you can also think about these questions, which we'll discuss after.",
    "I'll give you a bit of time.",
    "OK,  let's reconvene.",
    "All ,  let's.",
    "Reconvene everybody.",
    "I guess some of the unigram features and background features that we can talk about are probably.",
    ", pretty obvious.",
    "However, what I'm  more interested in is as you were going through this process, it might have seemed obvious, but then maybe you realize that wait, you have some additional decisions you have to make.",
    "that's what I'm guessing.",
    "for example, for the here are some of the unigram features you might have,  good might have a count of one, ?",
    "Or  Dave might have a count of one.",
    "But as you were chatting with your neighbors and trying to solve this problem, did you notice  what additional?",
    "Decisions you have to make that might be make this process less simple than it appears, .",
    "Exactly.",
    "for example, punctuation, do we ignore or include or how does it enter out with a monetization?",
    "for example, one strategy you could have chosen is maybe you put you just do  a space to limitation for  words, in which case you might have a word  day!",
    "That doesn't seem very clean or appropriate, but maybe that's simpler.",
    ".",
    "Did you have a oh, charges slash fees?",
    "Exactly.",
    "here's another decision.",
    "Charges slash fees one word or two also to limitize it.",
    "It should probably.",
    "The after limitization it should be charge or fee ?",
    "Or is it charge as one word plus A slash plus?",
    "Fee, .",
    "that's a decision.",
    "You have to make.",
    "What else?",
    ", in the back, , capitalization, do we normalize for that?",
    "And  here are some unigram features and  every single type of word should and punctuation if you include that should end up being its own unigram.",
    "Also there might be bigrams, .",
    "bigrams would be something  good day has a count of one and then every adjacent.",
    "Pair of words.",
    "Should have its own.",
    "Diagram.",
    ", ,  maybe we can remove articles, ?",
    "if those words are extremely common and you think they're not useful, you could imagine removing them, in which case that will affect all of your counts for unigrams and diagrams.",
    ".",
    "Another decision.",
    "Ignore politeness indicators.",
    "OK,  what?",
    "OK, finally, a good day.",
    ", that's a decision you can make.",
    "I'm not.",
    "I think you should include them though.",
    "the reason for that is I think it might be an indicator of spam versus non spam.",
    "for example, if someone writes to you with the, in our current cultural context, inappropriate level of politeness, that might indicate that it's more likely to be spam, ?",
    ", but that's an interesting thought.",
    "There might be other tasks where you should.",
    "Try to remove it, .",
    ", that's another decision you have to make.",
    "should bigrams span punctuation or  sentence boundaries ?",
    "Linguistically, it seems  it might be nicer if they don't, but maybe it's still useful, ?",
    ", one thing people do sometimes is they add  a separator token, and then you can have  day and then the separator token.",
    "then that means that the day is at the end of a sentence.",
    ".",
    "Do you want to add something?",
    "No, not.",
    "Add the second one that.",
    "We were talking about supply an application.",
    "They're very, very different.",
    "Words, .",
    "apply an application.",
    "that's a great question.",
    "apply an application.",
    "They have different lemma lemmata because you would look up apply under apply and application under application.",
    "these are different lemmas.",
    "However, a stemmer might stem application into apply.",
    "that's  the difference between stemming.",
    "And.",
    "Lemmatization.",
    "Another quick trick you can try is that if it changes the part of speech category, then it's definitely not lemmatization because lemmatization never changes the part of speech category.",
    "application here is a noun and apply is a verb.",
    "And  there are different lemmas.",
    ".",
    ".",
    "kindly and kind, that's a great point.",
    "They are also different lemmas, , but they are morphologically related to each other for sure.",
    "But , but they are different, .",
    "Would it be useful to remove prepositions  by?",
    "That's another very interesting thing.",
    "It's a common thing that people do is to remove common words, which often include prepositions, however.",
    "In my experience, often it hurts performance to remove prepositions because even though they seem  they don't do much, they .",
    "Are a key indicator of the relationships between words in a sentence, and  their distribution might  tell you something that's useful for text classification.",
    ", , that's a great question.",
    "why do people do it?",
    "If I'm saying that it usually doesn't work, are they just wrong about it?",
    "very soon, maybe  class.",
    "We're going to talk about .",
    "We've exposed here a whole bunch of different decisions we have to make, including some that I have some intuitions about, but I could be wrong in a particular, especially on a new data set.",
    "maybe what we need is we need a systematic strategy to try out these different decisions and figure out which one works best in our context.",
    "And  this is the problem of model selection.",
    "the way to think about it is that each of these different schemes that we can choose will end up resulting in a different model after training.",
    "And  we're going to have a whole bunch of different models.",
    "And how do we tell which one is  the one we want to use in deployment downstream?",
    "And there are good and bad ways to do that, and we're going to start exploring that soon.",
    "that's a great question to hold on to that, but it's a problem that we have to solve.",
    "OK, , I'll.",
    "Take two more questions and then .",
    "do we have to be consistent in how we apply our removal strategies or whatever?",
    "yes, in the sense that you need some deterministic way,  I can't think of any situation aside from maybe because of computational costs where you want a non deterministic way of processing the text.",
    "you definitely want a deterministic way.",
    "in that sense you should be consistent and also you should be consistent for sure across every sample in your data set.",
    "You want that consistency  that it gives your classifier a better chance of working .",
    "Because if you think back to, there was a sneaky assumption we made in formulating things in this y = F of X, which is that it's the same F that should apply to every single sample, and that should apply to every single sample in your training set and your test set.",
    "that's why you want consistency, is that you want as much as possible to make the environment the same,  that the patterns you learn from the current data set will be more likely to generalize and be also applicable to the test data set.",
    "And last question, yes.",
    "Aha,  what about grammatical mistakes or typos?",
    "You might end up with word categories that are not found in any dictionary.",
    ", you have to figure out how to deal with that.",
    "And there are different strategies.",
    "if you are in a domain where you don't expect typos, maybe then you just try to correct it as a preprocessing step and record what you think the word was.",
    "But if you're in a domain,  in spam detection, maybe typos matter a lot,  then you can map them to a special category of unknown words.",
    "That's another common strategy.",
    "maybe the number of unknown words is an indicator of whether something is.",
    "Likely to be a. Spam or not, you can even have multiple categories of unknown words.",
    "You can also do .",
    "We're assuming that feature extraction is happening at the word level, but you can also do character level perhaps.",
    "And at that point then there are probably very few unknown characters, but then the typos might be captured.",
    "All ,  these are all great questions, but hopefully we've gotten something out of this exercise, which is that as soon as you start working with real data, things are messy and there are lots of additional decisions you have to make.",
    "And we have to have some way of handling that.",
    "And, and a big problem that will tackle soon is the problem of model selection, which is you might, you might want to try out a whole bunch of different series of these decisions, but in a principal way.",
    "Oh .",
    "This is one thing that some of you have already proposed, which is to remove stop words, which are the common words that maybe are less discriminative.",
    "here's a partial list from a popular Python NLP package called NLTK.",
    "it can remove words  pronouns and prepositions and  forth.",
    "And also notice that NLTK assumes a very specific  tokenization where this is part of the ON apostrophe T, ?",
    "Don't.",
    "And then they, they decided to  for some reason, remove out the, the apostrophe T as a separate, as a separate word, .",
    "that's another thing that didn't come up  far.",
    "Or this is, this is also why you have an S. This is  the's marker, ,  the possessive marker or the third person contraction of  he's and she's and it's.",
    "But , again, this is yet another decision.",
    "I think sometimes you want to stop words often potentially even, but other times they're not useful.",
    "it really depends on the text classification task you're solving.",
    "And you need a way to make these decisions in a principal way.",
    "All ,  we've explored then a little bit the 1st 2 steps.",
    "defining a problem and collecting data, extracting features from a document with a whole bunch of possible decisions you can make.",
    "And then the  step is to  train that classifier to figure out what the form of that F should look .",
    "And this is where a lot of machine learning happens.",
    "And this is where  This is why there are whole courses on machine learning.",
    ".",
    "What?",
    "Form should F. Take the.",
    "You can think of it as each of these  terms.",
    "Some of them you might have heard before.",
    "You can think of them as specifying a class of possible functions F that could be learned, and the actual learning process is to select one particular F from among that class.",
    "OK,  for example, there's something called a Naive Bayes classifier, which we'll discuss.",
    "a Naive Bayes classifier has a particular form.",
    "We can write it up mathematically, but it's a whole class of models.",
    "And then when you're doing learning, you're setting the parameters, which lets you specify the particular function F that you're choosing to do this mapping from the inputs to the outputs.",
    "Similarly with all of these other things  support vector machines, logistic regression, artificial neural networks, all of that, they're all different choices for the class of functions F that you're exploring.",
    "at an abstract level, that's what we're doing.",
    "And then starting  class, you'll be exploring some of the basic ones, what the forms of them would look  in particular.",
    "And , what I encourage you to do is to take some time to install Python if you don't have it installed and also install some packages related to machine learning and NLP.",
    "in terms of machine learning, a popular one is called Skelearn.",
    "And Skelearn has implemented all of these, the basic ones  naive phase, SVMS and logistic regression.",
    "for example you can just after install you can just import the SVM package  from Skelearn import SVM.",
    "Then here is the input matrix X in the form that we talked about and the outputs vector Y for the labels.",
    "Then you can fit a support vector classifier.",
    "On that, really.",
    "Easily just by a function call and fit it and then you can predict it on  a new data instance.",
    "if you have extra time this weekend, I encourage you to play around with that.",
    "And then finally, we have the testing.",
    "And then I, I haven't forgotten, we should come back to the question of should you start create a startup based on tax classification for making trade predictions?",
    "OK, , , OK,  then in the testing step, here are some key issues that we'll discuss more in the future.",
    "1 is that we want a test set, which is different from the training set.",
    "The reason for this is, , in practice you want to apply your trained classifier on new data,  for many practical for many practical purposes, that's what we're interested in.",
    "Maybe not for many  questions related to analysis and scientific understanding perhaps, but for many practical purposes you want to classify new spam emails, not the ones you already have.",
    "that means you should try to simulate that in your development of a system by having a test set where you can test on held out samples and see the performance there.",
    "The  question you have to answer is  what metric you  use to quantify performance?",
    "And some popular ones include accuracy and position and recall an F1.",
    "we'll talk about all of these metrics, but the simplest 1 is accuracy, which is just the proportion of the percentage of cases in a test set that your classifier predicts the correct label for.",
    "But there are other issues  how do you tell if a model is really better?",
    "And then.",
    "you might want to run statistical significance tests.",
    ".",
    "Maybe there are small differences and they're  not meaningful, for example.",
    "more to do with that later.",
    "OK,  finally, let's get back to our motivating question.",
    "Should you trade stocks by building a sentiment analysis system?",
    "I think what's clear is that we can define the problem formally in the sense that assuming you have some text associated with each company, you can define the system.",
    "one question, one decision you have to make is if it's sentiment analysis that you've in which you formulate it, then it should be, is it just positive versus negative or is it  positive, neutral, negative, or is it very positive, positive, neutral, negative, very negative.",
    "you have to decide on your labels, you have to decide on how you extract features from the documents, and you have to decide which classifier you use and , make sure if you have labeled data, you can test on it.",
    "OK.",
    "But I, you can probably tell that I'm very skeptical about this whole enterprise to begin with by my tone of voice.",
    "what are some  reasons you think or , , why might this not be the best idea for a start up?",
    ", , that's a great point.",
    "there's a mismatch between  what we're solving and what we're interested in.",
    "here, if I formulated a sentiment analysis, what we're solving is a sentiment analysis problem of , what is that particular piece of text described?",
    "But what we care about might be getting rich or not getting rich or losing money.",
    "there's a mismatch there.",
    "And this is a really key point that is that is often glossed over.",
    "this is something that you can think of as a validity problem.",
    "We're solving one problem, but we're interested in  another problem which is very different.",
    ", that point, yes, yes.",
    "just to repeat for everyone.",
    "the point which is a good one, which is that there's some selection bias issue in that the text that you  see might be from sources which themselves have biases and not reliable or are  somehow biased compared to some underlying state of the world.",
    ", this is another example of a validity problem and that  the data.",
    "You're.",
    "Working with is biased in some way.",
    "And , .",
    "then, .",
    "your point is that maybe we can still fix this by expanding the set of features.",
    "Maybe we condition on where it's where the piece of text comes from and  forth.",
    "that could be that could maybe fix the problem or maybe you can even change it  that it's not predicting positive versus negative, but  buy versus hold versus sell, something more directly related to the problem we're interested in.",
    "But there's yet another issue which is maybe even a bigger one that we can't really solve.",
    ", in the back.",
    "Yes, that's another key issue where.",
    "the point is the market is not stationary.",
    "The fact that you have such a system and that maybe other people already have such systems embedded in their algorithms will influence the way that the market itself works.",
    "remember, here's another very sneaky assumption we made.",
    "It's the same sneaky assumption we made just by writing things down as Y = F of X, which is that there's a stationary F that is static and applies to everything you care about.",
    "And in practice, it's always wrong.",
    "yes, all of machine learning is based on something that is  wrong.",
    "However, in many settings, it's  it's close enough to, it's not wrong enough for us to not do it.",
    "But in this setting, it might be the case that assumption is  bad enough that it's not meaningful or useful at all.",
    ".",
    "I'm not saying that any algorithmic thing based on textual analysis would be bad for training.",
    "I'm sure these signals are used by lots of  hedge funds and  portfolio analysis people and  forth.",
    "I'm just saying that it'll be very, very difficult to do a better job than them fast enough such that you can  make money.",
    "That's all.",
    "go think of another startup idea.",
    "OK.  OK, Thanks everyone.",
    "I'll see you  class.",
    "."
]