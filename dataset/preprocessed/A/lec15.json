[
    "today, we're going to talk about compositional semantics.",
    "But first, st it'd be good, , to just quickly summarize and recap what we did last class.",
    "And even before that, just some reminders.",
    "If you have a midterm conflict, please send me email,  by the end of today.",
    "we need to figure out if we need to book a room for midterm for the makeup midterm and  forth.",
    "please do that as soon as you can.",
    ", the midterm is, ,  Wednesday, if I remember .",
    "then, there's no class during that time.",
    "But I'll I'll have extra office hours in my office during class time.",
    "Also, I assume that you've already started working on reading assignment 2, and then programming assignment 2 is out as .",
    ",  here are the algorithms from last class.",
    "last class, remember, we were still talking about lexical semantics.",
    "And we discussed Lusk's algorithm and Yourowski's algorithm.",
    "do you remember what tasks those algorithms were for?",
    "It's not about the meaning of 2 words in a sentence.",
    ", this is yes, that's .",
    ",  it's for a word that might have multiple senses and figuring out which one it is.",
    "It is intended in that context.",
    "And then we after that we talked about hearse patterns and also bootstrapping with these patterns.",
    "And that's more for figuring out.",
    "If , this is, these are the ones that are about  our 2 words, do they fit some lexical semantic relation?",
    ",  we did a lot last class.",
    "But there were a few topics that we didn't cover in enough depth.",
    "I just wanna quickly go through that a little bit more.",
    "one important concept from the second half of last class is this idea of a term context matrix where you can build up a representation of the words in a corpus by looking at their co-occurrences.",
    "this is the idea of distribution of semantics.",
    "You're using the distribution of words in order to infer something about the meanings of those words.",
    "And  here, in the term context, matrix, you have the target words which are the words whose meanings you're trying to model.",
    "And you have context words which are the words that appear in the context of those target words in the Corpus.",
    "And you can define context in any way you'd .",
    "it's about appearing within 5 words of each other or something, and then you can report the counts.",
    "one thing that I didn't really spend time on which we should talk about is , do you just record the counts?",
    "Or is there something better you do because it turns out that there is something better.",
    "And I should also say .",
    "Why do we care about this?",
    "I mentioned that , this is  the beginning.",
    "This is  the 1st  iteration of this distributional approach to modeling meaning, and which eventually led to large language models.",
    "But also, even  I would say, a lot of search engines are still based on word of co-occurrences.",
    "And  it's still based on these fundamental ideas.",
    "it's important to learn that this for that reason, too.",
    "and in particular, with search engines, , you can take this approach where you model every document and every , every documents, by looking all the words in that document, and then you can compare the similarity of documents with the query terms, as you might type into a search engine, and you can use something  cosine similarity, which, remember, is the, it's  the cosine of the angle between 2 vectors.",
    ",  here's the thing I wanted to also talk about.",
    "this has been a very important, influential technique, which is called point wise mutual information waiting.",
    "And  that rather than use raw counts.",
    "You instead record your term context, matrix.",
    "some notion of how much more likely or less likely than chance.",
    "Those 2 words co-occurring compares to observing them separately and individually.",
    "it's no longer a natural number.",
    ", it's just some   a score or some  a log ratio of ratio of likelihoods.",
    ", here  , here's the formula for point, wise and mutual information.",
    "You estimates the probability of both of those words occurring.",
    "and you divide that by estimates of the probabilities of each of the words occurring separately of each other  independently.",
    "this looks a lot  some formulas you've  seen for looking at independence  of random variables.",
    "if it turns out that w. 1 and W. 2 are totally independent of each other.",
    "then the numerator and denominator here should be the same.",
    "That's the definition of 2 random variables that are independent of each other.",
    "which that means that this ratio is one which means that the log of it is 0.  that's   the chance probability.",
    ", that's saying you have 2 words.",
    "If you see them in a corpus as much as you would expect by chance.",
    "then they're not really especially related to each other, or unrelated to each other.",
    "And , then, that you should record a score of 0, a Pmi value of 0 for that pair of words.",
    "If 2 words happen to occur with each other more commonly than you would expect by chance.",
    "that means the numerator here is greater than the denominator.",
    "then this score would be this ratio would be greater than one, and your log, the log likelihood ratio would be greater than 0.",
    "On the other hand, if 2 words co-occur with each other, less likely than you would expect by chance.",
    "then you have a negative value.",
    "rather than occur recording the raw count in the term context matrix, it records a notion of association between the target word and the context word.",
    "Suppose the word be occurs a hundred 1,000 times in a corpus of a million tokens.",
    "and then it co-occurs with the word linguistics 300 times.",
    "and the word linguistics occurs 2,500 times in total.",
    ", then, you can compute all of these numbers.",
    ",  you can compute V and linguistics.",
    "because it co-occurs with linguistics 300 times you get this joint, .",
    ", that's , because it's the probability of both of those things happening.",
    "it's 300 divided by a million for the though it's 0 point 1, because the is a very common word.",
    "it's a hundred 1,000 divided by a million.",
    "and for linguistics is 2,500, divided by a million.",
    "And  you can plug these numbers in.",
    "Oh, oh, 3, divided by the product of point one and point 0 2 5.  this gives you some Pmi score there, which is slightly greater than 0.  that means that these 2 words co-occur slightly, more often than you would expect by chance.",
    "we just ensure that somewhat normally.",
    "why are we dividing 300 by a million.",
    "It's because here it's  the probability of both events happening.",
    "it's   , this is the approximation there.",
    "it's  300 divided by a million.",
    "Because you, it's you're looking at the entire corpus, and there are a million tokens.",
    ",  that  it's not exactly the  space of events that you're considering.",
    "But  it's it's close enough that .",
    "you can just use that ratio as the probability.",
    ", does the base of the logarithm matter?",
    "Does the base of the logarithm matter?",
    "not really because if you choose a different base, that's  just multiplying all the numbers in your entire term context matrix by a constant.",
    "which doesn't matter if you're using cosine similarity.",
    "Another thing that people often do is that they often discard negative values in the Pmi.",
    ", if you get a negative Pmi, often they discard it, and they just record a 0 instead.",
    "this is called positive point wise mutual information.",
    "And  it's something you can try if you'd  to see if it helps.",
    "The reason for that is that the fact that 2 words occur Co.",
    "Occur less likely than you would expect by chance, is not very strong information of the anything of the meanings of those words.",
    ", , people often just discard them.",
    "this is one tweak to just doing the raw counts.",
    "And if you use Pmi, and there's  , slightly, there's slightly different versions of this.",
    "But you can use Pmi, and you can get pretty good levels of performance if you implement some  ir system  some  basic ir system.",
    ", another thing you can do is you can do singular value decomposition.",
    "here in this nlp, course, we have limited time,  I won't really talk much about all the math behind it.",
    "But I assume that you have, or will see this in another course.",
    ", how many people have seen singular value decomposition in some course.",
    "Yes, a lot of you, ?",
    "it's a really famous technique.",
    "It has,  3 or 4 different names, because there's slightly different versions of versions of it that have been discovered in  different contexts.",
    "But yes,  you can talk about singular value decomposition.",
    "You can also talk about principal component analysis.",
    "And as it's applied to information, retrieval sometimes called latent, semantic indexing, or something or latent semantic analysis.",
    "in truncated Svd,  that you want to creates a version of your term context matrix.",
    "which has lower rank in the linear algebra sense.",
    "And  the way they do that is, you can apply this Svd method.",
    "there's a standard method to do that lets you factorize the original term context matrix into the product of 3 matrices.",
    "And these are the dimensions of the matrices.",
    "you have your original term context matrix, which has dimensions of the size of your vocabulary by the number of context words.",
    "I'm indicating the size of your vocabulary.",
    "number of target words here as the size of B, and I'm indicating the context word size, the number of context words as C, and then you can factorize it into the product of these 3 matrices.",
    "And here this Sigma K here is a special, because there it's a diagonal matrix that contains the singular values of this original matrix which you can think of as some  characteristic way of looking at the properties of that matrix.",
    "And it turns out that you can throw out some of the values of the in the singular , in this, in, in this, in this matrix, and also throughout the corresponding rows and columns in the other matrices to come up with an approximation of the original term context matrix.",
    "And here, this is  a dimensionality reduction technique.",
    "You're  taking the dimensions of the original term context matrix which explain the least amount of variance.",
    "And you're just getting rid of those dimensions and projecting your matrix to the remaining dimensions.",
    "the idea here is that  suppose M is the original rank of the term context matrix.",
    "What you do is you pick a K which is much smaller than it.",
    "And that's how you can get an approximation.",
    "you're getting in A, you're getting a smaller.",
    ", you're getting a matrix with lower rank than the original.",
    "And in practice doing this truncated Svd often improves performance, because you're removing some noise and preventing some overfitting of the model, because you can think about overfitting in this context, as  you observe, some counts co-occurrence counts which are just, random, and not predictive of the future, and  truncated.",
    "Is a method to help you get rid of some of those.",
    "You can also prove that this view of truncated Svd is optimal in a technical sense, in this very particular sense, which  suppose X was your original term context, matrix and xk, is your approximate term context, matrix of rank.",
    "K, you can prove that the matrix you get by applying this as truncated.",
    "Svd procedure has the lowest amount of error.",
    "you're preserving as much as the most information you can.",
    "This is an L 2 norm.",
    "you're looking at, how much is the difference between your original matrix and the approximate matrix.",
    "And you can show that this is the best possible approximation among any matrix of this rank.",
    "this is just to say, this second point here is just to say that it corresponds to something else called principal component analysis.",
    "it'll be helpful to look at this graphical intuition of what truncating, truncated Svd does, or principal component analysis.",
    "suppose you have just 2 context words.",
    "your original term context, matrix has 2 dimensions.",
    "And then you plot all of your word vectors in this two-dimensional plane.",
    "What truncated Svd or Pca does is that it finds all of the vectors.",
    "It finds,  some axes that best explains the variance of the points with respect to each other,  the points here are the closest, as close as you can get to the axis, to the axes as you have.",
    "and then, when you are truncating, when you're removing some of the singular values and removing some of the dimensions, you're  squashing everything into just a lower dimensional space.",
    "graphically, this is what's happening when you're doing this approximation and this one dimensional approximation of the original 2 dimensional make.",
    "A space is this is the this is the squashing.",
    "This is the approximation that preserves the most information.",
    "I don't have time to do this topic justice.",
    "But there's a lot of math and linear algebra and algorithms and people have come up ways to do this very quickly.",
    "you should look into that if you're interested in this and this idea of Svd.",
    "And truncation and principal analysis, you find that all over the place.",
    "For in many applications  this block.",
    "And finally, the other thing, of course, is that people also train neural models of word embeddings for lexical semantic for lexical semantics.",
    "And I mentioned last class that word 2 vec.",
    "Is a famous model that does this from 2013.",
    "I thought I would just briefly show the neural network figures for word 2 vec.",
    "the original model  proposed 2 versions of word 2 vec.",
    "In the 1st version called the continuous bag of words model.",
    "You look at representations of.",
    "1st you sample a particular position within your training corpus.",
    "and then you look at the words, say 2 words before and 2 words after, and you take the rep.",
    "The the embeddings associated with those words which are parameters of the model.",
    "Then you sum them up.",
    "and then you use that to predict the middle word that's missing.",
    "that's how the that model is trained.",
    "And this latent representation of what you predict.",
    "That's  the representation of the word.",
    "That's how you get a representation of the word  that's the continuous bag of words model.",
    "the more,  more popular one is the skip ground model, which is that you take the middle again.",
    "You sample a position in your training corpus.",
    "You take the middle word, and it's embedding.",
    "and you use that to predict one of the one or more of the words in the surrounding context.",
    "these are by modern standards.",
    "These are relatively simple architectures and ideas.",
    "But but , sometimes they still use word 2 vec,  word 2 vec, although ,  they're not popular anymore for English.",
    "If you have,  a highly specialized corpus where you don't have a lot of data to train a transformer model.",
    "Or if you're working with a language where you don't have enough data to train  Lstm or transformer model.",
    "Sometimes people still use word embeddings of this time.",
    ", does the skipgram have a lot fewer parameters?",
    "Or is the just the embedding of the word.",
    "Longer does the script skip ground have a lot fewer parameters?",
    "I would have to think about that.",
    "I don't think , because, , it's  because the parameters are shared and the sibo.",
    "it's not  you have a parameter.",
    "You have a set of parameters for a word, 2 positions before, or something  that.",
    "It's it's still the same.",
    "you just have one set of.",
    "suppose your representations are size 100 or whatever.",
    "Then you have 100 parameters for each word in your vocabulary in both cases, .",
    "all this to say, this is  been.",
    "This has been how distributional semantics has evolved.",
    "you start off with  some  count-based approach.",
    "And then people have used linear algebra to try to  reformulate that and do a little bit better.",
    "And then there'll also be neural approaches, and, as I also mentioned last class, it turns out that you can prove that the Skipgram model and the Svd based model.",
    "You can prove that they're equivalent to each other .",
    "any questions about my school sematics?",
    "With Sv, do we need to ?",
    "Is it good enough just to know,  the high level idea that we're  suppressing it, and only keeping the relevant information or the ones that don't.",
    ", only keeping the information that does affect variance.",
    ",  that's the high level intuition.",
    "we don't have time to , get into any more depth.",
    "for, say, for the midterm, , it's enough to know that it's about that.",
    "That's the high level intuition.",
    "And it does this by applying this matrix factorization algorithm.",
    "distribution of semantics and lexical semantics done.",
    "The  topic is the, , the final major topic for the midterm.",
    "And it's about compositional semantics.",
    "the thing with lexical semantics is, it's only about the meaning of words, or  small phrases.",
    "remember, what does Lexical refer to?",
    "It's something to do with your lexicon, which is this idea that you have some abstract  list of  almost  a dictionary in your mind that lists out all of the words and phrases that you should know for knowing a language.",
    "But language doesn't just happen as individual, flexible items.",
    "Language happens in  spoken language happens in utterances.",
    "Written language happens in sentences and in even bigger chunks, which  if we have time to talk about later.",
    "in compositional semantics, what we  to do is we  to talk about, say the sentence level where sentences have meanings that you can derive by looking at the parts of the sentences.",
    ",  we have to talk, then, about the principle of compositionality.",
    "Compositionality is exactly this idea that the meanings of sentences is not just some.",
    "It's not arbitrary, and you can derive the meanings of a sentence by looking at the meanings of the subparts of the sentence.",
    "in particular, the meanings of all the phrases within it.",
    ",  that and or just or, more broadly speaking, the meaning of a phrase depends on the meanings of its parts.",
    "if I say to you, you may disagree, but comp.",
    "550 is a fantastically awesome class.",
    "then that sentence has a meaning.",
    "Again, this meaning could be true or false.",
    "but we understand that by looking at and breaking down  the meanings of  .",
    "And it's how all of these words work together that you get the meaning of the whole sentence.",
    "whereas lexical semantics might give you the meanings and behaviors of each of the individual words.",
    "We still need some procedure to build up the meaning of the entire sentence through composition.",
    "And  this is really important.",
    "This idea of compositionality is really important, because you could argue that this is what lets language be really, really flexible and useful, and you can use language to talk about new situations and  forth.",
    ",  people make a big deal of compositionality for good reason.",
    "And  if you if we encounter a new situation where we discover,  previously extinct yellow dinosaurs that have been revived, or whatever I can talk about that, and  that has never happened before, but because  the meanings of each of the words, you can combine them in new ways, and we can talk about new ideas and new events that happen.",
    "we should also talk a little bit about some other properties of the meaning representations of a sentence.",
    "and within this module what counts as a good meaning representation.",
    "If you think about it.",
    "In the last lecture or 2, when we were talking about lexical semantics.",
    "We  talked about 2 different views of it.",
    "We talked about the relationships of words to each other, ?",
    "The relationship of words to each other  with all these  somatic relations,  synony and autonomy, and some autonomy, and  forth.",
    "And we also talked about relating the meanings of each word to the things in the world,   to the references, and also  to the sense of the word.",
    "that's 2, or  3 different views of meaning.",
    "what about at the sentence level?",
    "you can still talk about the meanings of the sentences with respect to each other.",
    "But what about the aspect of the meanings of sentences with respect to the world?",
    "how do we think about that.",
    "one way to do this is to really use some  ideas from logic.",
    "And just look at how they do things and then apply it to natural language.",
    ", , to relates the linguistic expression to the world, one thing you can do is that you can assert that a proposition.",
    "this is a term from logic is either true or false relative to the world.",
    "Here's another potentially new sentence.",
    "Pandas are purple and yellow.",
    "what is the meaning of pandas are purple and yellow.",
    "to figure that out, you have to take the sense of that, whatever that means and evaluate it against a world.",
    "in our current world, in this particular universe, with this particular earth, with this particular  pandas.",
    "it evaluates to false ?",
    ", unless you , die a poor panda or something.",
    "But but the point here is that you're able to do that evaluation?",
    "the meaning of the sentence is, the is the thing that lets you perform that evaluation to check.",
    "If it's true or false.",
    "With respect to the current world.",
    "that's 1 potential view of .",
    "of sentence meaning another is to convey information about the world.",
    "I don't think this is  true thankfully.",
    "But suppose I say it will snow tomorrow.",
    "Then what that's saying is that it's conveying something about the world.",
    "and how the world is or will be .",
    "that's another way to connect the language to the world.",
    "or it could be a query, as  , What is the weather  in Montreal  week?",
    "You turn this into some logical form, and then you can evaluate it against  a database that's connected to some meteorological service, and then you can return.",
    "You can retrieve the weather for Montreal  week and then give you an answer.",
    "it's this  a sense of meaning that we're going to be talking about.",
    "It's about relating linguistic expressions to the world with these sample tasks of how we might want to do that.",
    "we talked about compositionality  just very quickly.",
    "There here is also a very high profile violation of compositionality.",
    "language is compositional, but it's also not perfectly compositional.",
    "in particular idioms or expressions whose meanings cannot be predicted from their parts.",
    ",  , , you might, you may or may not know that kick.",
    "The bucket means to die.",
    ", but that has that is not really derived.",
    "You can't derive that from kick the bucket.",
    "or if you see something, it's the last straw 99% of the time you're not  talking about the last straw.",
    "This is the final thing that really set someone over the edge, and they get really mad, or something  that.",
    "Likewise, piece of cake is not always literally about the piece of cake it could just mean something is very easy hit.",
    "The sack means to sleep, and  forth.",
    "these are clear violations of compositionality, because there's no regular  function.",
    "There's no function that you can apply here to derive the overall meaning from the meanings of each of the parts.",
    "Interestingly, though it's not  arbitrary , there are still some commonalities in the meanings of  each of these parts, and the overall meaning.",
    ", , the type of events is usually preserved  kick.",
    "The bucket is  a thing that happens.",
    "and then it's kinda over  , which is, , the same as  to die.",
    "it's and it would be very unusual if there was an idiom where the event type is something  I don't know relaxing at home, and then it means to die, because then one of them is  a it's  a state of being , whereas  die is  an event that just it's  a point in time.",
    "usually there are still aspects of meaning that are shared between the idioms and the overall meaning.",
    "But it's still a composition is a violation of compositionality of root.",
    "And here's another more subtle violation of compositionality or arguable violation of compositionality.",
    "which is that things are often relative to each other and not strictly about.",
    "The meetings internal to each of the parts.",
    ",   this is the idea of co-compositionality, which is that this is still  compositionality in the sense that the meaning of the whole is derived from the meaning of the parts.",
    "It's just that the function that you use to compose and get the overall meaning is complex and is dependent on the parts themselves.",
    "Imagine in your mind what the meaning of red is  on its own , , just think about Red!",
    "What does Red mean to you.",
    "For most people it might be  some very vivid   red.",
    "the RGB value of  2 55 0 or something  that, ?",
    "Might be your prototypical red.",
    "But  think about red in the context of all of these words,  a red rose.",
    "It's  may  that very visa red, or  it's something slightly darker and more purpley ?",
    "And red wine is red wine.",
    "Really the same  red wine is very dark, ?",
    "That color I don't know what to call it.",
    "but is that it's not magenta violet?",
    "Purp again, some  purpley red.",
    "or  red cheeks,  red cheeks.",
    "If you  analyze the RGB value of someone who's blushing.",
    ", it depends on their skin tone, but it's almost certainly not red.",
    "If you just look at it in isolation.",
    "but you can still talk about somebody's cheeks being red, ?",
    "People who are said to have red hair are also, , it's not exactly red, either it might be there's variation, but it might be more orangey, or whatever, or brownish.",
    "then the idea here is that the meaning of red  is influenced by what you're composing it with.",
    "it's not just that there is  a fixed, static red redness that gets added to the noun that you're composing it with.",
    "And and when you put words together, their meanings  affect each other as .",
    "the tradition that we're going to discuss today and  class is to use logic to model sentence meaning.",
    "And this was a tradition that started in 1970 with Montague.",
    "And hence the this approach is called Montegovian cement.",
    "and it's the idea of using a logical formalism to represent the meaning of a sentence with a tight connection to syntax.",
    "Montague says, there's no, in my opinion, no important theoretical difference between natural languages and artificial languages of magicians.",
    "Indeed, I consider it possible to comprehend the syntax and semantics of both kinds of languages, with a single natural and mathematically precise theory.",
    ", these days, with  neural networks and large language models, you may or may not have thoughts about this.",
    ", after reading this quote.",
    "but this is the assumption and the approach behind Montegovian semantics a dash we can use that natural language can be made as precise as  logic, logical languages of our logic.",
    "and you can model the former with the latter.",
    "at least in at least the meetings.",
    "there is an advantage of doing things this way.",
    "which is that you can then talk about natural language inference as applying logical rules of inference.",
    "if you pick a particular logic as we will, then, whatever inference procedures are defined by that logic, you can also apply them to natural language after you've converted natural language to that logical form.",
    "And I would also say that,  the other reason to pay attention to this stuff is that we can never get away from something symbolic and logical, at least not completely.",
    "because we still have lots of observations that are non linguistic again, , say, weather data, , or  other, in sources of information from natural processes that people gather and put in some database.",
    "and you have to access it through some database.",
    "you have to write some SQL.",
    "Query to access it, and all of that involves  manipulating logical forms and logical queries.",
    "and  that means at some point.",
    "You you're you still need.",
    "You're still going to have to translate between that and natural language.",
    "If you want to have a natural language interface to all of that information.",
    ",  then, what is inference?",
    "Inference is to make something explicit that was implicit before in language.",
    ",  if you say something , I want to visit the capital of Italy.",
    "and the capital of Italy is in Rome.",
    "Then you can make an inference, which is, I want to visit Rome.",
    "If you say all wugs are blorks and all blorks are cute, then you can conclude that all wugs are cute.",
    "and  these are cases of semantic inference.",
    "unlike in your previous logic classes.",
    ", it's , in terms of natural language sentences.",
    "this is  natural language inference.",
    "But we're gonna still turn this problem into  a problem of logical inference by defining a procedure to convert the natural language sentences to some logical form.",
    ",   the logic we're going to pick is 1st order, logic or 1st order predicate calculus.",
    "how many people have seen?",
    "I was expecting most people to have seen it.",
    "this means you should ask me questions.",
    "because chances are, it'll be confusing for most of the rest of the class, too.",
    "1st order, logic has these components, and  we need to define them,  that we can talk about translating natural language to 1st order logic.",
    "first, st order logic can be defined as having a domain of discourse, which is a set of entities that we care about.",
    "this is the side that is more  a semantic.",
    "It's about , say, the students in the class or the topics that we study.",
    "or the classrooms and courses that might be one Mini scenario we want to model.",
    "there's a domain of discourse of entities.",
    "Logic also has variables which are by convention denoted with lowercase letters, and they stand for potential elements of the domain of discourse.",
    "It has predicates which map elements of the domain of discourse to truth values.",
    "and you can have different valences which means different numbers of arguments.",
    ", , I can define the predicate in course XY, which takes in 2 elements of the domain and returns.",
    "True, if X is a student that is in the course Y and false.",
    ", should we think of a pedicut as   an identity function in a way that as predicate and identity function, what do you mean by identity function  if it takes  or an example in the case, , in course, Xy  it just checks the identity of X and returns  yes or no  predicates.",
    "if it's a predicate that has a single argument, often it does give you  the category, it checks the category.",
    "if you have,  a student X, it's usually in natural language, it's  checking whether X is a student or not.",
    ", it gives you some information about the properties of that out element.",
    "If you have something that takes in multiple arguments  this, then it's usually about some relation.",
    "here, in course, is about a relationship between the student and the course.",
    "And the student being in, enrolled in the course.",
    "functions, map elements to other elements of the discourse.",
    "And, ,  you have an instructor of function that takes X and returns and other elements which corresponds to the instructor of the course.",
    "And  the difference between predicates and functions is what they return.",
    "Predicates give you a truth, value  true or false.",
    "In 1st order, logic functions give you,  a elements  other elements of the domain of discourse and a valence, 0 function would be a constant.",
    ", , I can say, , I can create a function called Montreal, which takes no arguments, and it just returns an element of your domain of discourse which corresponds to the city of Montreal.",
    "The the idea of city, the city of Montreal.",
    "And then you have logical connectives.",
    "please tell me you've seen these .",
    "you've seen  not, and or and implies and bi-directional entailment.",
    "And also, , how about quantifiers?",
    "Have you have people seen quantifiers?",
    ",  you have seen 1st order.",
    ",  then there's an existential quantifier and the universal quantifier.",
    "the  , these are the basic elements of  1st order predicate calculus.",
    "it might be easier and more concrete  more examples.",
    "we might want to define some procedure that converts a sentence  the capital of Italy is Rome into some logical formulation.",
    "here I have capital of which is a function.",
    "and then Italy is also a function.",
    "It's a constant and then equals.",
    "It's a is a predicate.",
    "this sentence and this formulation is asserting that there's a something called Rome.",
    "and then you can have a function to get the capital, from Italy, from the from Italy to some other entity, and the other entity is the entity denoted by Rome.",
    "Just think of them as  names.",
    "And then there's also this abstract entity which is  the entity of Rome and the abstract entity of Italy.",
    "and then the capital of converts that Italy entity into the Rome entity.",
    "Or here's another logical sentence that all wugs are blorks.",
    "We can convert it to this form, for all X log.",
    "And  here, wug and blog are these are predicates.",
    "If it's a log, then it should be a port.",
    "And this X here is a variable.",
    "This X ranges over all of the elements of discourse.",
    "Yes, , for the second sentence are we  saying for every X, then applying the predicate of , the one thing is also a floor.",
    "you're for all X means that you're .",
    "The way to think about this is usually you're modeling some situation in some situation   10 critters or whatever.",
    "And then, when you're doing for all x, you're  checking for all 10 critters and for all 10 critters.",
    "You're asking, is this a Wug?",
    "And that's what Wugex is doing.",
    "then it should also be the case, that if you ask, is it also a blurb?",
    "But if it's not a bug, then you don't care then.",
    "and then it can be a block or not.",
    "And and the implies arrow here.",
    "It's a it's a logical connective, ?",
    "it takes in 2 arguments, 2, 2.",
    "Truth values, the one thing before and the thing after.",
    "And then you can draw a truth table for that  hopefully.",
    "if the left hand side is true.",
    "then the  hand side has to be true.",
    "In order for the whole thing to evaluate to true.",
    "If the left hand side is false, the whole thing evaluates to true.",
    "these all have precise meanings.",
    "And you  to review logical connectives.",
    "or Boolean connectives, if you prefer to remember what they mean.",
    "And there was another question, .",
    "Or we create this function just because we want to analyze the simplest of the capital of Italian.",
    ", that's a great question.",
    "the question is , where does this function of capital out come from?",
    "here is just an example.",
    "It's just, I'm just defining that this could take the form of a function to represents capital of.",
    "but in general there will be.",
    "There are conventions and procedures,  that every word in English you can associate it with some piece of logic which might involve defining functions or might involve defining predicates and  forth.",
    "And then we'll also define a procedure to combine those pieces of logic together in order to form the overall meaning of the sentence.",
    "Is there any order of the old?",
    "Is there an order to it.",
    "Yes, there, there is an order to which you apply things,  that this whole thing is within the scope of that universal quantifier.",
    "But if it's ever unclear, you can add parentheses to make clear the scope.",
    "this part is really confusing.",
    "because it's not intuitive, and the 1st time you see it is confusing.",
    "But  the reason, remember that the reason we're using a logic ultimately is to relate language to the world.",
    "And  that means that to interpret a 1st order logic.",
    "you have to interpret it and evaluate it against some world in the end.",
    ",  a particular instance of a 1st order.",
    "Logic consists of the predicates and function names and arity.",
    "as  as a set of sentences.",
    "In 1st order logic using those predicates and functions.",
    "and then an interpretation of it, or a model of it, is to apply it to an actual scenario to check the truth and false values of all of those logical sentences, or anything else that you might care about.",
    ",  , and your interpretation involves specifying the domain of this course.",
    "and it also means specifying the functions of predicates.",
    "how do the functions  map entities to other entities?",
    "And how do the predicates  map entities to true or false?",
    ",  think about it this way,  the just, the logic and the sentences themselves, although that's what you spend most of your time  working out.",
    "That's just  general statements or constraints about  things that may or may not be true.",
    "Whereas an interpretation is where you  interpret it in a particular scenario.",
    "to see if that if those sentences are true or false.",
    ",  I'm we should do this exercise together.",
    "Because  it's this is, this can be difficult.",
    ",  we're going to come up with a 1st order.",
    "Logic, characterization of the following students who study and do homework will get an a students who only do.",
    "One of them will get A, B and students who do 90 will get a C.  we should list the predicates and functions that are necessary, and make constants for the grades.",
    "and then we'll come up with an interpretation of this 1st order.",
    "where you and 2 of your friends are the elements in the domain of discourse, such that the above 1st order, logic formulas are true.",
    ",  let's do this together.",
    "before we get started, I'm going to close the door.",
    "Oh, , sure, that'd be great.",
    "students who study and do homework will get an a.  what do you think?",
    "because we're talking about students.",
    "what  quantifier do you think we need?",
    ", because we're talking about some general property that should apply.",
    "think there's a way to have equations.",
    ",  for all x for all students, how we do that is we write.",
    ", why did it create a new text box here?",
    "for all x. if X is a student.",
    ", students who study and do homework.",
    ",  they also have to study.",
    "And they'll get an A, how about we do sometimes it just.",
    "And to be pretty, to be more clear, we can add a parentheses.",
    ", are we  with this?",
    "students who study and do homework.",
    "They're great as 8. .",
    "Do we need the.do we need?",
    "Oh, you mean this dot?",
    "technically, yes, but it's not a big deal.",
    "Do you think of wedge as  union?",
    "No wedge is closer to intersection.",
    "this, the wedge is just  Powerpoint.",
    "This is just the and symbol.",
    "I can add another one, too, to make it clear.",
    "I just want to make it clear is that the conjunction of these 3, which is in the conditions for the implication.",
    "the students study and do homework.",
    "Those are all credit between the grade up as a function.",
    "then I'm wondering, can you just do  rolex students?",
    "And the homework goes to just say, , you need the greater touch.",
    ", that's a great question.",
    "We have  3 predicates, and we have grade of X is equal to a why can't we just have 8 here.",
    "the reason is because the types don't work out.",
    ",   this is a logical, this is a Boolean connective ?",
    "It takes 2 truth values and returns another truth value.",
    "on the left hand side here, this is  a logical expression, and it gives you a truth value in the end.",
    "But just a is a constant,  it gives you an element in your domain of discourse.",
    "it gives you just  that just the constant.",
    "A, by itself gives you the abstract idea of a.",
    "It doesn't give you a truth value.",
    "you need to , you need to  Ref.",
    "You need to have that relates to the X to the student .",
    "the way that I'm doing it here is to say that grade of is a function that gives you the grade of the student, the X entity.",
    "and that's equivalent to a.",
    "And then this is  a predicate in disguise.",
    "And it gives you a truth value  great of X equals 8 gives you a truth value.",
    "Do we have to bracket the entire thing.",
    "I'm thinking of for every x, then we apply the if condition to the X, and then if that, if condition is satisfied, then we get the grade.",
    "I don't understand the question.",
    "Oh, , do we  need the brackets at  in front of students and ending at a Oh,  technically you don't.",
    "But just for clarity, I'm adding.",
    "and the reason you don't is because , the quantifier takes precedence.",
    "No  this implication takes precedence over  the quantifier, or something  that.",
    "But if you want to be just super clear, you can just add the parentheses.",
    "And it wasn't worried about it was  82. .",
    "you're asking about the interpretation.",
    "This is just saying that this is just an assertion that all students who study and do homework get an a.",
    "But since we haven't applied it to a particular group of students and their results.",
    "Yet we can't tell if it's true or false yet.",
    ",  the second sentence to translate is students who only do.",
    "One of them will get a B  you can do it as  2 separate sentences if you want.",
    "And  students who don't study and do homework at A B students who study and don't do homework at A B.",
    "You can also combine these 2 and have  a more complex expression here.",
    ", that would be really interesting.",
    "If we had an or  students who study or do homework.",
    "wouldn't that contradict the 1st statement that students who do both get an a .",
    "you have to be careful how you write the or  the or has to be over those, both the conjuncts, the con, the conjunct of both.",
    ",   the wrong thing to do.",
    "this would be wrong even if you add a parentheses here.",
    "Because or is in logic is always inclusive or  it's 1 or the other, or both.",
    ",  I'm gonna delete it.",
    "it's not defined by the set of logical symbols that I put earlier,  logical connectives that had earlier.",
    "But if you define it with a truth table.",
    "Then, , you could use Xor.",
    "But , Xr would be correct.",
    "You just have to define what it means.",
    "And the students who do neither get a seat any questions about this.",
    "once again, to illustrate the difference between just having these logical expressions and truth , we don't know if these evaluate to true or false these sentences.",
    "because we haven't applied it to any particular situation or scenario.",
    "That's when you need to talk about interpretations.",
    "how do we interpret this logic within a particular context?",
    ",  then,  ,  then come up with an interpretation where you and your 2 of your friends are elements in the domain of discourse, such that these 1st order logic, formulas evaluate to true.",
    ",  this is, you need a domain of discourse which involves you and friend one and friend 2.",
    "And we also need the abstract concepts of  the grades.",
    "we also need the abstract concept of the grade of A, the abstract concept of the grade of B and C, ,  this is  going to be your domain of this.",
    "This is  the minimal domain of discourse that you can have to get this to work and satisfy all of those requirements.",
    "But once again, , it's important to , distinguish between  these 3 and the names of A, B and C here.",
    "whereas,  A, B and C, here are the abstract notions of those grades.",
    ",  year Mcgill decides to change the names of all the grades.",
    "you get  Unicorn and , I don't know goose, and I don't know duckling instead of A, B and C, in which case,  you can change the names of the constants to  Unicorn and goose, and duckling, or whatever.",
    "but the abstract notion of  having grades that are better or worse.",
    "Is this the domain of all variable factors.",
    "This is the domain of all variables.",
    ",  technically, you can have student a student.",
    "C, yes, you can have student A, you can have student, and you can pass in A and B and C, it's just that they'll evaluate too false.",
    "You can have , .",
    "we have to , specify the meanings of everything.",
    "I'm gonna put that you and friend one and friend 2 will be the ones where, if you pass it to students, you evaluate student of that re values to true and otherwise it values to false.",
    "And  And you're a very good student.",
    "you study, and   does friend one.",
    "And again, you're a very good student.",
    "And but  your friends don't.",
    "And , and then creative.",
    ", Grena, this is a function.",
    "you define it  that it turns out that you got an A and then, friend, one gets a B, and then, friend, 2 gets a seat is something  this.",
    "this would be an example of a possible situation or world where all of those logical formulas evaluates to true.",
    "And you can check ?",
    "You can check,  for all X student and study and do.",
    "Homework means that the grade of X is a you can check.",
    "you it applies for you ?",
    "Because you study and do homework, and you get an a oh, .",
    "This should be lowercase and then your friend, the condition doesn't apply, because, your friend doesn't do, friend, one doesn't do homework.",
    "the condition this condition doesn't apply.",
    "And same with friend 2.",
    "And for all the abstract notions of  grades that also doesn't apply, because,  they're not students.",
    "and you can do the same thing to check for  this sentence and this sentence, and this sentence, this sentence.",
    "A is  true if it's the grade of a rather than  a lowercase a.  the uppercase a is just a name.",
    "And and  it's a constant that gives you a name.",
    "It's  ,  you have a name, and  you have a nickname.",
    "But both of those points to the same.",
    "then, you have this abstract idea of  you as a entity, and then you have different names for it.",
    "C are just names of the abstract notions of  those grades.",
    "I, B returns B, and see returns, see and equals is  a special predicate, and if you pass in  the same element of the domain of discourse.",
    ", that was my question.",
    "Is there a way to define functions  that , if that are defined beyond this input gives this output.",
    "Are there ways to define functions that are not just  this input, gives this outputs.",
    "in order to not confuse things.",
    "For  just think of it that way that you can define functions.",
    "You define functions as this input gives this output.",
    "in some other cases there'll be some regularity in the data or in the in the patterns, such that you can check with in through some other means.",
    "but just for the sake of not confusing us.",
    "For  the function is some arbitrary function that takes in elements of the domain of discourse and gives you elements of the domain of discourse.",
    ",  what would be an interpretation such that the these sentences don't evaluate to true.",
    ", we change the grade of any student.",
    ", we change any of the grades.",
    ", if your friend somehow gets an A does, despite not doing homework, , then this will be, then the one of those formulas would evaluate to false.",
    ",  does this idea make sense.",
    "You almost never go to this level of thinking about particular scenarios and defining the particular scenarios.",
    "But it's important to understand that fundamentally, this is how truth works in 1st order, logic and interpretations work in 1st order.",
    "You apply to some scenario with this interpretation, and then you check what's going on in.",
    "You don't have to do that because you can.",
    "You can look at logical rules of inference and derive conclusions by using logical rules of inference.",
    ", that would still be useful without having to go through this layer.",
    "The other main piece that we need is we need to have some.",
    ", we need to have some algorithm for constructing these logical formulas at the sentence level from the its parts.",
    ",  we need to build these meaning representations compositionally as because that's   the goal of today and  class.",
    "in order to do that, we need to use another tool from computer science and whatever.",
    "we need to use lambda calculus.",
    "and that will help us to define a precise algorithm to do .",
    "lambda calculus again,  seen this in another course.",
    "allows you to describe computation, using mathematical functions and the computations that we're going to be doing is we're going to be building up a 1st  logic sentence as the as the meaning representation of the sentence by using fragments of logic in the subparts of the sentence.",
    "and lambda calculus can also be formally defined, and it can be defined recursively.",
    "This is a different notion of variable compared to the notion of variable in 1st Square logic.",
    "But there's a variable there X, which represents some piece of lambda calculus.",
    "Then there's lambda X of T, where t is a lambda term.",
    "and then there's Ts, where T. And S are both lambda terms.",
    "And then there's functional application.",
    "But we need this because we need to be able to store partial computations as we're building up the meeting representation.",
    "function application also known as Beta reduction takes this form.",
    "you have some lambda, X some lambda expression lambda, X of T, and then you apply it to some expression.",
    "S, and what it does express.",
    ", what it does is it replaces all instances of x within t with the expression s. , , lambda x of x plus y apply to 2 simplifies to 2 plus y, because you're replacing everything that's X here with X with the with the 2, you can even take lambda expressions and plug them in as  as  arguments within the body.",
    "if you have lambda, XX, lambda XX, you can simplify that.",
    "Here there are 2 copies of X.  the argument here is this identity function.",
    "this means that you have 2 copies of the identity function.",
    "And then you can further reduce this by taking one identity function and passing it to the other identity function.",
    "And you end up with  one identity function.",
    "If this was confusing one thing you can do is you can rename the variables.",
    "You can rename one of them, say, rename the 1st one to be lambda.",
    "something that takes in a Y and returns 2 copies of it.",
    "That's  what this 1st function says.",
    "and what you're returning 2 copies of here is the is the identity function.",
    "one thing to note is that function, application is left associative.",
    "if you have,  4 lambda terms A, BC, and D, you 1st simplify a B, and then you take the result, and then you  do Beta reduction with Z, and then you take that result.",
    "And then you do beta reduction with D,  we only really, we're not really using,  the a full power of lambda calculus, that much we really only needed to store partial computations.",
    "I've only defined this these terms a little bit loosely and intuitively, but you can go and be more precise about it, and can read up on work in that.",
    ",  why do we care about partial computations?",
    "Why do we need lambda calculus?",
    "It's  that we can look at each of the subparts of the syntax tree.",
    "and we can look at the syntax tree and build up the meaning representations bit by bit, until we get to the sentence level.",
    "When we have the entire logical expression.",
    ", , suppose you want to measure you want to produce the representation of whiskers, disdain, catnip.",
    "The general idea that we're going to pursue is that each of these words.",
    "each of these lexical items.",
    "we'll have some fragment of the meaning representation with things that need to be filled in.",
    ", , for the verb disdained.",
    "And the predicate takes in 2 arguments, Y and x. because you need something that is disdained.",
    "And you need, , you need to have something that's disdaining something else.",
    "And when you compose distained with catnip.",
    "then what happens is that you take that expression which you think of as a lambda term.",
    "and then you take whatever representation of catnip that you have as the argument, and then you can do beta reduction.",
    "then you can make sure that catnip goes into the  place  that it's the thing being disdained.",
    "And then it's still missing the semantic agents is the thing doing the disdaining.",
    "And then later, when you see whiskers, then whiskers becomes the argument, and then it gets plugged in into the Y, and you get  something that's but here it's  some  semantic representation of Whisker's disdained cabinet.",
    "this is the high level idea, which is that you have these words.",
    "They have pieces of logical representations with things to be filled in, and then you, you express those things to be done using lambda expressions.",
    "And then you use lambda calculus, and you do composition up the syntax tree to get everything to go into the  place to get the logical representation of the whole sentence any questions about the high level idea?",
    "Is this  to assign things different words .",
    ", , cabinet being disdained by whiskers.",
    "And this lambda stuff is  that we say, , what object is applying to something else.",
    "it's it's to have some regularity and structure,  that,  ideally, you want all transitive verbs to look similar.",
    "they all have this form where they need.",
    "They're looking for 2 things within some predicate.",
    "And then and the lambda terms, let you express that  it's missing 2 things, and then you're going to find it somewhere else in the sentence.",
    "And then the procedure of  finding it is by doing composition.",
    "using the syntax tree as your guide   a placeholder until we reassign.",
    ", it's  a placeholder until you have .",
    "Found it and resigned, reassigned it.",
    ", that's a good way to think about.",
    "I'm going to post the answer to these exercises.",
    "then what we'd  to do is we're assuming that the syntax tree will be useful for helping us derive these meaning representations.",
    "what we're doing is we're doing syntax driven semantic composition.",
    "what that means is, we have to go back to Cfgs.",
    "and we have to augment them with lambda expressions with the idea that every time you're doing a syntactic composition.",
    "you're putting 2 things, 2 or more things together, using a production in a context, free grammar.",
    "You're also correspondingly doing some function application in lambda calculus, in order to simplify in order to in order to take these pieces of meaning representations, and  merge them together to make a larger, a meaning representation of a larger bit.",
    "then, syntactic composition goes hand in hand with this,  semantic composition.",
    "According to this theory, this approach.",
    "and you can write it down formally, as  your semantic attachment.",
    "this is your Cfg rule.",
    "where you have,  some left hand side rewrites to N  hand sides becomes some function where you're taking the semantic representations.",
    "Here, I'm using dot sem to refer to each of those the partial the pieces of logic representation there, and you're combining them  in order to .",
    "gets the overall meaning representation of the entire constituent, the larger phrase.",
    ",  let's take a look at some examples.",
    ",  if we do this bottom up.",
    "and for the small pieces it's  for the lexical rules is pretty easy.",
    "they will be constants in 1st order, logic.",
    "Comp, 5, 50 is a constant and , for reasons we're gonna type, raise them  that they're gonna be lambda expressions apply to constants.",
    "here's gonna be what we store.",
    "Comp, 5, 50 will be lambda XX applied to the constant Comp.",
    "And then the associated rule, for,  Np.",
    "Rewrites to proper noun would just be the take the semantic representation of the proper noun, and that will  be the semantic representation of the Np.",
    "just pass it up common nouns.",
    "our predicates inside a lambda expression of type E to T. What does this mean?",
    "this means that it takes an entity   an element in your domain of discourse, and it tells you whether the entity is a member of that class.",
    ", the rule of N rewrites to the word student is associated with this semantic attachment of lambda X.",
    "Student X.  it's a predicate applied to  where X here is  a variable in the lambda expression.",
    "how are intransitive verbs handled in this framework?",
    "What you do is you create an event variable?",
    "E, and you assert that there exists a certain event associated with this verb with arguments.",
    "suppose you have the verb rules.",
    "then its semantic attachment looks  this.",
    "There is a it looks  there's an event, E such that e is an event of tight rules.",
    "and there's a ruler which is the X to be filled in.",
    "And then finally, , for  the composition rule of S. Rewrites to Npvp.",
    "Is associated with this semantic attachment of Np, dot sem apply to Vpsem.",
    ",  that was a lot.",
    "And then hopefully, it'll be a bit clearer.",
    "let's derive the representation of the sentence.",
    "And this is what it would look .",
    ",  ,  1st of all.",
    "Ignore all of the logic.",
    "We just have a syntax tree.",
    "this you can remember from before , as rewrites.",
    "Rewrites to a proper noun, and then proper noun rewrites to the word comp.",
    "Rewrites to V, and then V rewrites to the word rules.",
    "And then the semantics of it all is that you need to associate.",
    "It's you go bottom up.",
    "for each of these rules you look up.",
    "The semantic attachment associated with those rules which you can find from the previous slides will look  this.",
    "and then for each rule you then apply this  you look at the semantic attachment associated with those rules.",
    "and then  for these unary rules, you just pass up the semantics.",
    "And what we're interested in is we're interested in the logical representation you build at the S level.",
    "the rule was, Np, dot sem applied to Vp, dot, sem.",
    "that means np, dot, some would be lambda XX, comp.",
    "5, 50, because you get that from this, from its from the subject.",
    "You get from the Vp semantics.",
    "And here is where you do, beta reduction to simplify this expression.",
    ",  you take this entire.",
    "the way you do this is, you take this entire expression, you plug it into where X is.",
    "and then this is what you get.",
    "After that one step you're you end up with.",
    "E. Rules E. Ruler EX.",
    "And then you take Comp.",
    "5, 50, and you plug it in where X is within the smaller piece, and then you get this expression of there exists a. E. Events which is a rules event, and the ruler of E is whatever is denoted by the constant comp.",
    "And this is the logical representation of the sentence.",
    "then,  at a high level, the idea here is every terminal rule.",
    "every rule that results in a leaf node, , involving a terminal.",
    "you take those semantic attachments, and then afterwards is a mechanical process of looking at your augmented Cfg with those semantic attachments and then running those procedures.",
    "And then we needed lambda calculus to store these partial computations.",
    "And we need the logic, because that's what we're aiming for.",
    "which is, which is what we're aiming for in this whole exercise.",
    "it's , that's why associated population, it always applies another qualified into the inside.",
    ",  the questions are  the grammar does not have to be in Cnf.",
    "And then, in terms of the order in which you apply things.",
    "You have to look at the semantic attachment rule.",
    "that's part of designing this augmented grammar.",
    "here it says, Np, dot, some is the Punctor and Vp, dot, M is the arguments.",
    "If you have a different rule that works in a different way, you have to follow that.",
    ",  I'll stop there and we'll continue  class."
]