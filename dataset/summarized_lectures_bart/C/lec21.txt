Jackie Cheung, Professor: the captions button disappeared. please use that because this link no longer works. And we're going to look at how we got to the current state of generative AI from this line of work. And then we'll look at some simple, basic methods from the past for document summarization. Every span of whatever granularity you're interested in into a representation. If this has low average distance to all of the other points in the source, then that's located. It turns out that the beginning is the picking that the opening sentences is the best predictor of important information. The heuristic here is that a term is important or indicative of a document, if it appears many times within that document, but is relatively rare overall. The topic signature method works extremely . And again, this is based on just a very simple notion. Then it would score highly. You can ask students and to use a summary you either. or you might be interested in testing whether summaries improve the speed of doing something else. and then they either they had one condition where the people had to just look at the documents themselves alone, or they can have access to both the document and a summary of the document.

today, we're going to talk about automatic summarization. There's a different link that I posted on Ed. But for today, we'll focus on summarization and we'll look at what is the definition ofautomatic summarization tasks. I'll define what it means, what extractive summarization means. One approach is to just throw everything into a pre trained, generative model. and do some prompting or whatever, and try to get outputs. The other is to take a supervised learning approach. This is the simplest because most of the work has to do with content selection. You need to work on the ui , how do you present the summary to indicate that this is an extractive summary? People have current summarization into a knapsack problem or something from which encountered. One very basic system is appropriately named, some basic by Neiko von Vander Wendy. There is a word that's pretty important in all the documents they solving. , that's why the score increase.

An informative summary tries to be a substitute for the original source material. It tries to express as much of the important points as possible that were in the original. The 1st type of signal is the distribution patterns of X within the source text material. And then also the relation of the text with the background domain inquiry. Use discourse structure to help you find the important information in a piece of text. We have very strong intuitions about what information should be expressed in an article about a natural disaster. You can use even use those to check for comprehensiveness, , it's missing something advice for people who are affected. by their average word probabilities. And you just run this iteratively until you reach your length limit. And we can reduce the weight of that a very important for it, Solomon. of course, this was a very basic system. Then this breaks the knapsack assumption, but then you add additional constraints about the relations between sentences.

 summarization is a family of tasks with many different flavors. Indicative, that's the second possible function. A 3rd way in which summarization systems can differ can be in terms of the format of the expected output. This is more of an artifact that there's some homogeneity in the population of researchers and the tasks they work on. In news text the opening of the article acts a summary in and of itself. This was a really important and basic tool in information retrieval for the longest time. If you see the word be in an article that tells you almost nothing about the topic of that article.

This week we're gonna look a little bit at automatic summarization and text generation. We're gonna talk about some of the ideas that have been important these fields. And different techniques that you want to employ, depending on what you're trying to do. and score terms, and then, after that, you can just directly use those scores, and score each of your sentences by say, it's average, or its total tf, idf weighting. or I idf score ? and then for each term, Ti. And each term is either the term of interest. Ti, or it's not theterm of interest some other term. What you can ask, what is the probability that occurrences of Ti are distributed between R and not R in this way? this is a binomial distribution.

Jackie Cheung, Professor: the captions button disappeared. please use that because this link no longer works. And we're going to look at how we got to the current state of generative AI from this line of work. And then we'll look at some simple, basic methods from the past for document summarization. Every span of whatever granularity you're interested in into a representation. If this has low average distance to all of the other points in the source, then that's located. It turns out that the beginning is the picking that the opening sentences is the best predictor of important information. The heuristic here is that a term is important or indicative of a document, if it appears many times within that document, but is relatively rare overall. The topic signature method works extremely . And again, this is based on just a very simple notion. Then it would score highly. You can ask students and to use a summary you either. or you might be interested in testing whether summaries improve the speed of doing something else. and then they either they had one condition where the people had to just look at the documents themselves alone, or they can have access to both the document and a summary of the document.

today, we're going to talk about automatic summarization. There's a different link that I posted on Ed. But for today, we'll focus on summarization and we'll look at what is the definition ofautomatic summarization tasks. I'll define what it means, what extractive summarization means. One approach is to just throw everything into a pre trained, generative model. and do some prompting or whatever, and try to get outputs. The other is to take a supervised learning approach. This is the simplest because most of the work has to do with content selection. You need to work on the ui , how do you present the summary to indicate that this is an extractive summary? People have current summarization into a knapsack problem or something from which encountered. One very basic system is appropriately named, some basic by Neiko von Vander Wendy. There is a word that's pretty important in all the documents they solving. , that's why the score increase.

An informative summary tries to be a substitute for the original source material. It tries to express as much of the important points as possible that were in the original. The 1st type of signal is the distribution patterns of X within the source text material. And then also the relation of the text with the background domain inquiry. Use discourse structure to help you find the important information in a piece of text. We have very strong intuitions about what information should be expressed in an article about a natural disaster. You can use even use those to check for comprehensiveness, , it's missing something advice for people who are affected. by their average word probabilities. And you just run this iteratively until you reach your length limit. And we can reduce the weight of that a very important for it, Solomon. of course, this was a very basic system. Then this breaks the knapsack assumption, but then you add additional constraints about the relations between sentences.

 summarization is a family of tasks with many different flavors. Indicative, that's the second possible function. A 3rd way in which summarization systems can differ can be in terms of the format of the expected output. This is more of an artifact that there's some homogeneity in the population of researchers and the tasks they work on. In news text the opening of the article acts a summary in and of itself. This was a really important and basic tool in information retrieval for the longest time. If you see the word be in an article that tells you almost nothing about the topic of that article.

This week we're gonna look a little bit at automatic summarization and text generation. We're gonna talk about some of the ideas that have been important these fields. And different techniques that you want to employ, depending on what you're trying to do. and score terms, and then, after that, you can just directly use those scores, and score each of your sentences by say, it's average, or its total tf, idf weighting. or I idf score ? and then for each term, Ti. And each term is either the term of interest. Ti, or it's not theterm of interest some other term. What you can ask, what is the probability that occurrences of Ti are distributed between R and not R in this way? this is a binomial distribution.



