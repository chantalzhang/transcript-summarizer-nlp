Language model is a way to predict the probability of a word based on all the words in the purpose. It can also factor in the context or the previous words before the word we're trying to predict. The word that is infrequent might be around 30,000. There are many applications of language model. before we make this more complicated. I all of you are more focusing on what's the problem, what we have go to the one. after you have feed the data using parameter theta on everything on your training purpose, how do you compare? and then you can also use publicity. And there's a nice connection between cross entropy and publicity.