If you're able to estimate probabilities for your language model for every combination you have in your training set. How do you compute the unigram distribution for a particular world? How would you compute it? That would be count of every time cat appears divided by count of all the words in your couples. And we also went to an example in the last class to clarify this. for Tridram, how are you going to calculate this? The idea of smoothing is the probability distribution to shift some probability mass to cases that we haven't seen before, or we are unsure of. And then you understand, the idea of you have reserved some probability for the unknown token. The easiest way you can do is just to do what's called interpolation.