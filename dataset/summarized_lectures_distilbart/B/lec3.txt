 I didn't post it this morning, but I will post it after the class . What's the difference between supervised and unsupervised learning? What do you mean by non necessary features? You want to reduce the number of types that  We have a principle called cross validation which is also used for model selection . You can split training data into different chunks or subsets to generalize . By doing this you can aggregate the test accuracy and then try to pick your model parameters  SKLN is a very small package which you can install for basic training tasks . It's used to be very popular, 10 years ago, but it's a package that can be easily installed for basic tasks . The most important thing  Today we'll talk about how to train a classifier on a training set . But today we are focusing on linear models . You can determine the features you want to use for a particular text, and then your inputs can be a document  When you're learning a model, you need to add a parameter teeter . Teeter can be all the weights you want to learn . Theta can be your weight matrix for neural networks or a set of parameters you learn for log  Probability of X is estimating the entire probability over all the set of features . But for the naive base, typically we don't estimate this probability . The reason is because this is constant when you are trying to pick what is the best  We make an assumption that we are generating this data as a generative model . The parameters to the model Theta consist of what we call the prior class, which is probability of Y . We assume that we have very, very large  For every X&Y you pick from your data, you want to estimate what is the probability of the joint probability . If you assume this independent assumption for each data, then you are going to have the product over all the data .  Using Bayes rule, can you compute what would be the probability of Y equals grade A or not A given these three features which is review notes, does assignment and ask questions . If and that's the last one, it doesn't  The internal answer is this. Probability of y = A and probability of Y equals not a given X, ? This is what you want to compute. What you're supposed to compute is probability of. It doesn't review notes and  P.P of X of the vector. is even wrong. here you have, I don't think my calculation is OK. one, I have two, which should be 1 / 3, one over three . 1 / 45 is  There's an important distinction between generative versus discriminative task . The only thing you care about is the parameter . You learn the parameter Theta . If you can get the Theta, you already solved the problem. If you  In practice the features depend on both the documents and the proposed class . Logistic regression is very important in NLP because it's what you use to compute things publicity of a language model . The log of the product of probability will be  Support vector machine is generative for a discriminative model . SVM can work in different tasks and settings, usually giving very little training data . It's very simple to do this in practice. What you have to do is to  Artificial neural networks are one of the most successful algorithm that we have currently in machine learning . Given enough training data, they tend to perform very well . The disadvantage of this is that training can take a very long time. Sometimes you can