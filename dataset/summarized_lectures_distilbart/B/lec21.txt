 This week we're gonna look a little bit at automatic summarization and text generation . We're going to look at how we got to the current state of generative AI from this line of work . We'll look at what is the  There are technologies out there for a summarization that claim to do a good job in summarizing clinical notes . This is a system by nuance called dax copilot . Microsoft owns nuance, but this goes to show summarization is in  An indicative summary provides a link to the source text to help users decide whether or not to read it . Indicative, that's the second possible function . Critical summary provides an opinion of the text . A summary doesn't have to serve  One way in which systems can differ is whether you're doing single document or multi document summarization . In multi-document summarization there are additional issues you have to handle . If the multiple documents are by different authors, then chances are  Some domains require the exact wording to be preserved, such as quoting research . But abstractive summaries can get into trouble if they don't preserve the context . In medical space there is a corpus called up to date, not a corpus  The idea behind up to date is that it's a resource where they have reference, except it's not a wiki. It's a encyclopedia for doctors, and that they have, a documentation of all of the common things that can happen  We have to try to model importance in a different way in text, using other heuristics or other cues . The basic idea is that we can approximate importance by looking at a notion that I'm going to call centrality . Central  If it's very far, then it's not . we want to remove stop words? Quite , , assignment one . You can make arguments either way that you can, if it's some notion some ways of modeling content would be .  The queue that I claim is often used in summarization systems is discourse structure . And what by discourse structure? Is that the way that we write passages? And there are expectations that we have about how a piece of writing is written .  The more important stuff tends to be at the beginning . The most important clue is the headline . The opening sentences is the best predictor of important information . Even today, even today, that still makes sense as a strategy, even if things  The last sentence, because that's where the post original poster asks the question after giving a lot of context . The conclusion, , that's . In academic writing, you don't read it from beginning to end in scientific articles . Usually  What do you expect to see in an article about a natural disaster? Or the doctor kilometer range? I'm also gonna put costs. Where to donate for relief. What to do if you're affected suggestions and advice for those affected  All summarization systems need to perform these steps in some form or another . These days, one strategy, is to just throw everything into a pre trained, generative model. and do some prompting or whatever, and try to get outputs  This depends on the nature of the supervised learning system, but for simpler kinds of machine learning and . simpler . kinds of supervised machine learning systems . you have a very direct relationship between the input features with the output decision of is this sentence  People tried this very early in the fifties and sixties . Lynn and Hobie did something similar in the nineties . They trained us to a supervised method as . Where the input was the source text plus some human written abstract  In news text the opening of the article acts a summary in and of itself . The baseline method in this style of in this genre of text should be just to select the 1st sentences . Another approach that people have taken is to try  The idea here is that you can take this approach or other approaches. and reweight and score terms, and then, after that, you can just directly use those scores, and score each of your sentences by say, it's average  This is a binomial distribution, because it's a you can think about the some theta which is you model . Then you have to use combinatorics to account for all of the ways in which the appearance or non-app  redundancy is both good and bad, but redundancy is good because it helps, but it's bad in the sense that you have to be careful when you're selecting sentences to include in your summary . One basic system is appropriately named, some  In 2,006, we were able to achieve this as a community using these simpler methods on some tasks in summarization . And in fact, there's all this talk about AI systems are better than people and taking over the world .  In 2,006, Conroy et Al. used the topic signature idea introduced with a sophisticated non redundancy, module, and some rules just to eliminate some parts of sentences deterministically . There's something called Gerund clauses that this  The reward signal is how good your estimation of how good it would be to select the sentence, and then you have to define it a certain way . If you have not seen reinforcement. Don't worry about it, but it's not  You cannot interpret the scale the same between cities, or even between neighborhoods . An alternative to this is something I mentioned a bit earlier called rouge scores . You compute some notion of overlap between the reference summary and the system generated . rou  This comes after and they called it rouge. The difference between blue and rouge is that you, the denominator, is mostly defined in terms of the number of words or n-grams in the system generated translation . For