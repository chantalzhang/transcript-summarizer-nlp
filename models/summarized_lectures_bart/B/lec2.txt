All , welcome back to NLP. and then starting week you'll have David for a few lectures. OK, today we're going to start with a module on text classification. And also this is the main announcement. to the Ed discussion platform because that's where we'll be releasing all the materials. the for today's lecture. The another way to think about it is to map from the form of language to its contents that can be. , by an automated system to do further processing, or for the purposes of applications or just do some abstract representation we can analyze. Does anybody remember the difference between phonetics and phonology? semantics is about the meaning usually of say a sentence, literally, and then we can talk more about that, what that means later on. The main topic of today's lecture is to assign a label or category to a piece of text. If we were to take the previous example and talk about predicting positive versus negative sentiment, then that's an example of the task of sentiment analysis. But there are many other text classification tasks, which are a big part of our lives. In this lecture we'll focus on feature extraction and some common processing that people in working with textual data do when trying to process text. And then we can talk a little bit more about the experimental methodology within text classification. All , then we should start with what is machine learning? machine learning, here's a definition. It's using data and statistical algorithms to learn patterns. Machine learning is about giving data and also giving the system a way to learn from this data. NLP is not machine learning and machine learning is not NLP. They are two different subareas of AI. There's different ways of formulating problems sometimes and different perspectives on them. Cat is a noun, although these days it can be a verb too. And the is a determiner, which of it as an article. What we're going to be concerned with today is text classification, not text regression. In supervised learning, we're mapping from the input to the outputs. Most NLP work involves text. Involving text ends up being classification problems. The linguistic units of interest are often discrete. You don't really have to know these distinctions, but , these are the kinds of distinctions that you might be interested in an LP, words, part of speech tags, semantic categories. In NLP, we have to define the problem and collect some data set. We then need to extract features from the documents. Then we need to train a classifier on a training set and then apply the classifiers on some text test data. And then lecture, David will talk more about step numbers 3 and 4. In supervised learning setting, we require having training data and having already a labeled set of annotations. We need to have some reliable source of that in order to be able to train our system in the 1st place. If you can't get an easy or Cheap or reliable or high quality way of getting annotated data, then you canâ€™t really apply the methods that we'll talk about today. In the current era where there are lots of data sets online that you can download and play around with, it's both great for the purpose of just running some algorithms and optimizing, but also scary in that. Just don't forget that you're relying on other people. We have document classifier, document label. We specify what the possible YS mean and then we're going to train a classifier on top of the document. you have your input document and then feature extraction means converting. As a list of features. then you have a bunch of inputs, X1X2X3 up to whatever. In machine learning, there was a lot of efforts to try to predict which features are might be useful or not. But these days the trick is the strategy is to just throw everything into the learner and then use enough training data with enough labels. instead you can record some abstraction of the word. Some common choices that we'll go through include, say, recording the lemma, which I'll explain. There's a process called lemmatization, which involves removing certain affixes. And there's a related procedure called stemming. IES into I at the end of a word. ponies becomes PONI or ational becomes ate, relational becomes relates. If the word is long enough in terms of some other rules, you can turn revival into reviv. It's because you're making fewer distinctions, and sometimes you want to make fewer distinctions. That's the main key behind both limitization and stemming. , if N is 1, then these N grams are called unigrams. Unigrams are just words in isolation. But you can choose higher orders of N, You can choose n = 2, and then it's called bigrams or n = 3. And does that sequence appear or how many times does it appear in your documents? Suppose you have V words in your dictionary. Once you have bigrams, you have v ^2 number of possible bigrams. And once you have trigrams, it becomes b ^3. even if you have a really powerful computer with lots of memory and you have access to a supercomputer cluster or whatever, you can't really go up very high in terms of the N&N grams. you can get up to three, . then at that point, there are different strategies you can try. Every single type of word should and punctuation if you include that should end up being its own unigram. Also there might be bigrams, . bigrams would be something good day has a count of one. If someone writes to you with the inappropriate level of politeness, that might indicate that it's more likely to be spam. In my experience, often it hurts performance to remove prepositions. Are a key indicator of the relationships between words in a sentence. Their distribution might tell you something that's useful for text classification. Do we have to be consistent in how we apply our removal strategies or whatever? If you are in a domain where you don't expect typos, then you just try to correct it as a preprocessing step and record what you think the word was. But if you're in a domains, in spam detection, typos matter a lot, and then you can map them to a special category of unknown words. And at that point then there are very few unknown characters, but then the typos might be captured. You can think of them as specifying a class of possible functions F that could be learned, and the actual learning process is to select one particular F from among that class. OK, , there's something called a Naive Bayes classifier, which we'll discuss. If you have extra time this weekend, I encourage you to play around with that. And then finally, we have the testing. There's a mismatch between what we're solving and what we are interested in. What we care about might be getting rich or not getting rich. The market is not stationary. The fact that you have such a system and that other people already have such systems embedded in their algorithms will influence the way that the market works. In many settings, it's it's not wrong enough for us to not do it. But in this setting, it might be the case that assumption is bad enough. I'm not saying that any algorithmic thing based on textual analysis would be bad for training.