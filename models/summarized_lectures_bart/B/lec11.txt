This week is Thanksgiving, plus the fall reading break. That means there are no classes or office hours or lectures. The reading assignments are not meant to take a long time there, but they are there. Also, we're gonna be releasing the final project description hopefully by the end of the week. Language is not just a linear sequence of tokens. It's a discrete approximation also of speech, the speech modality of language. The pronunciation of words that are to each other will often affect each other some of the most of the time. The most natural way to think about them and characterize them and describe them and model them is not to justThink about them as a sequence of. tokens. If you're from the Uk. , chances are quite high. You speak that a version of English that. doesn't pronounce r's at the end of syllables. French pronunciation is famous for having these effects. It's a really difficult thing for learners of French to grasp. In this lecture, we're going to talk about how structures in a sentence can be formed and assembled to create larger units, larger structures. And you can combine those structures with other bigger structures to form ever bigger structures until you get to the level of a sentence. And then, what we're gonna talk about today is syntax. This idea of syntax and that languages have structure is not a new idea. It's not even an idea from last millennium. The earliest people to have thought about this that we are still aware of are grammarians from, say, from South Asia. And they come up with descriptions of the languages that they speak. , it doesn't tell you how a language is as and how it occurs. It tells you that it's some normative standard about how they think you should write in order to have something be correct. in this course, we're only going to be concerned with descriptive grammars. I that here's another common misconception, which is that things that are non standard or informal or casual somehow have no grammar. And that's simply not true. There are many different kinds of constituents. then the question is , How is it that what does it mean for these words to form a unit? And the answer is, they share some similar distributional properties that we can test for. And I'll go through a bunch of tests to check whether something a group of words is a constituent or not. There's not really a universal list of syntactic categories, because. as you might expect, linguists don't agree. Different formalisms and different languages might have different syntac categories that seem to make sense for them. But here are some of the most common ones that are in most grammar formalisms. When you define a constituent such as a noun phrase, is there a definition, or is it defined through the tests? It depends on your theoretical perspective, and where you come from. For our purposes, we can define them operationally through their distributional behaviors. subject is the most common one, the , most at least in English. The most common is direct object. adjectives, can also require certain arguments, and you can talk about the relations between a determiner the versus its noun, the ball or something. , that in that case it would be a transitive verb that takes on both the subject and a direct object. There are 3 things there often those require 3 elements, and then they're called ditransitive verbs. Other languages have different role, different operations and things that as . Do you mind to give an example of that? A prepositional phrase has to appear in a certain syntactic environment which can be called subject or object, or something else. And that's part of what helps you figure out if this the sentence is grammatical or not. Can somebody identify what the preposition is in the following sentence? prepositions are these words that help indicate relations between things in a sentence, and they appear before a phase. In English, it's overwhelmingly propositions. There are some post positions, and other languages prefer to have post positions. You can move the whole thing to the beginning of a sentence. on Saturday, October 12.th The assignment is due. A formal understanding helps us to develop appropriate algorithms for handling and dealing with hierarchical structures and syntax plus? there are implications for cognitive sciences and language learning. We're not just linguists, we're computational. what is the formal model of grammar that we're going to use to account for these and other syntactic concerns. Free grammars can be used for tasks such as stemming and lemmatization and morphological analysis. They are used in Nlp as . they're very practical because they tend to be much faster to compile and run and process. In natural language you can talk about. Oh, we might have a sentence which we'll denote with some symbol S. And a sentence should be rewritten into a noun phrase plus a verb phrase. and you apply the rules of a Csg. to keep rewriting until you end up with a sequence of words. There are other classes of grammars. There's 1 called context Sensitive grammar or you can add conditions. You can be , I'm allowed to rewrite an S. To an Mpp. In the context of something else or Np. Can be rewritten to something in thecontext of something other. a Cfg is a four-tuple. We love those they have a N. And Sigma and R. And S. Where N is a set of non-terminal symbols. Sigma is aSet of terminal symbols. R is set of rules also called productions. and the star here means you can have 0 or more of them. This is a grammar that describes the possible sentences that can be accepted. For any questions far about the example, we also have to draw a tree. You want to work with an actual sentence a real sentence? That's , that's not what the question asked for. this describes all of the possible sentences that could be accepted. But it doesn't work with any particular sentence. If you want to work with a particular sentence this, this steals this, then you would have to draw the tree. and we can do that. I'm going to attempt to use the drawing mechanism. this is a noun phrase, ? this is an Np steals is v, 2. and then B 2 Np. Gives us a Vp and Npvp gives us an S. English grammar can be modified to account for more phenomena, and to fix issues with over and under generation. To add adverbs to our grammar, we need to add the adverbs. This also makes sense, because adverbs, as their name suggests, are associated with verbs. question can you have an empty element inside? From the good question, can you has an empty elements inside. It depends on who you ask. If you're thinking about this formally in the from the Cfg perspective, yes, you're allowed to do it by my definition. These are 6 different rules just for the sake of saving space and using the vertical bar, that's all. But literally, it's just a safe space. It's these are, think of these as six different rules. And the question also asks for prepositional phrases. But I'll let you do that on your own. English has a very limited amount of subject-verb agreements in the present tense, . The only thing we really have to fix is, we need to ensure that if you have a singular 3rd person then the verb also has an affix of s or es, depending on the verb. We need 2 versions of this rule. We need one rule, which is Mps Vps, and one role. And for I, you can have debt n and also I. And there are 2 different kinds of noun phrases, the ones that are 3rd person singular. And then you have to ensure that the 3 third person, singular nouns agree with the 3th person. is that we want to. Every time we create a distinction we have to think about , , is it? How do we incorporate that into the grammar? Usually it means that you have to split up a category into multiple categories. And then you must think about where that information needs to go, because if it if it affects something that's very far away in the syntax tree. In a dependency grammar, you draw arrows directed directed edges to connect and describe this relation. Grammars are just a different view of the hierarchical structure of language. But it shares this basic property and assumption that it that it's hierarchical. , you're solving some information extraction task. dependency trees can be converted into constituent trees. if the dependency edges don't cross each other. constituent trees can also be also converted into dependency. Trees, if what the head of the constituent is ? , let me do this example. , the students study for the exam. You can have dependencies, graphs where the edges cross each other. This is an example from German. It's he has me tried to reach, or he has tried mean to reach. and they're both pretty natural, , and accepted. and you can draw the arrows using how the syntax of German works.