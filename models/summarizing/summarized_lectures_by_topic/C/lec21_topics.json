{
    "Topic 1": " There are multiple purposes you can have for a summarization system . One is to be informative or just . you, you want to read things. A short version of things to understand . Another is to provide a critical summary of some material . But in multi-document summarization there are additional issues you have to handle . In those situations you might not want to automate .  The opening sentences are the best predictor of important information, he says . The idea of centrality is super important, because all information retrieval systems are equally equally important . It's dependent on the specific type of newspaper corpus, and then it's dependent upon the type of paper corpus .  The heuristic here is that a term is important or indicative of a document, if it appears many times within that document, but is relatively rare overall . An Idf is a little bit more complicated? Here's another method again by Lynnon Hovey, which is very successful .  You can ask students and to use a summary you either . or you might be interested in testing whether summaries improve the speed of doing something else . and then they either they had one condition where the people had . to just look at the documents themselves alone, or they can have access to both the document and a summary of the document .",
    "Topic 2": " Today, we're going to look at what is the definition of automatic summarization tasks? What extractive summarization means is the task of turning some source text into a summary . An indicative summary provides a link to the source text to help users decide whether or not to read it . And then, a critical summary which provides an opinion of the source .  One approach is to just throw everything into a pre trained, generative model and do some prompting or whatever, and try to get outputs the specific words you're going to use . Another is to look at how many documents does there exist within some reference corpus. and then you divide that by the number of documents with some term T, you add one to avoid it, or take the log of the computation for it . Then the computation will be a very small computation . If you had to pick one and just one, which class of features would be more successful?  One basic system is appropriately named, some basic by Neiko von Vander Wendy . They compute relative frequencies for all words, divide it by the length of the article, and then of all the articles . This means you're less likely to select a very similar sentence in the future, because the new average probability of the words in similar sentences has been decreased .",
    "Topic 3": " An informative summary tries to be a substitute for the original source material . If the multiple documents are by different authors, then chances are that there may be conflicting information or contradictory information between them . In abstractive summaries that you need to synthesize the contents and then produce some potentially novel text for the outputs which requires more advanced semantic analysis and natural language generation .  In academic writing, you use the general way in which a piece of text is expected to be written in order to help you find it and locate the important information . We have very strong intuitions about what information should be expressed in an article about a natural disaster, you can expect that the summary should also contain this information . And you can use even use those to check for comprehensiveness, , it's missing something advice for people who are affected that's really important .  Solomon: It's the grammaticality of the individual sentences and the coherence of the output overall . The overall process for this approach is that you ask human experts ideally, or you somehow automatically construct a reference summary. This came after and they called it rouge. Here the denominator is defined in terms of the length of the .",
    "Topic 4": " There are many different possible contexts in which you might want to do that . All summarization systems need to perform these steps in some form of some form or another . The queue that I claim is often used in summarization is discourse structure . The more important stuff tends to be at the beginning, the most important clue .  In news text the opening of the article acts a summary in and of itself . In different kinds of corpora, usually the title is the most important sentence with the highest overlap with the human abstract . And then for each of these you can just fit what's the best parameter that maximizes that likelihood .",
    "Topic 5": " This week we're gonna look a little bit at automatic summarization and text generation . And we're looking at some of the ideas that have been important these fields . And different techniques that you want to employ, depending on what you're trying to do . We can approximate importance by looking at a notion that I'm going to call centrality . In unsupervised systems, systems are different based based on different systems .  In class, we can talk a little bit about approaches to neural abstractive summarization . And then we need to bring in this idea of natural language generation . There's a metric called rouge, which I'll introduce in a bit, and then their particular system ."
}